# The Definitive Linux Guide to Wifano.ai: From Installation to Production Mastery

## Introduction to Wifano.ai

Wifano.ai represents a paradigm shift in artificial intelligence deployment for enterprise environments. As a distributed, knowledge-intensive AI system designed for PhD-level reasoning capabilities, Wifano.ai demands a robust Linux infrastructure to deliver its full potential. This guide approaches Wifano.ai from the perspective of a Linux administrator, providing comprehensive instructions for deploying, configuring, optimizing, and maintaining this sophisticated AI platform.

Wifano.ai combines several cutting-edge technologies: large language models, knowledge retrieval systems, specialized reasoning modules, and tool integration frameworks. The system is designed to operate across distributed computing environments, leveraging Kubernetes for orchestration, specialized GPU resources for inference, and a sophisticated data management layer for knowledge storage and retrieval.

As Linux administrators, our role in deploying Wifano.ai extends beyond simple installation. We must architect a system that ensures performance, security, reliability, and scalability. This guide will walk you through every aspect of Wifano.ai administration, from initial setup to advanced production configurations.

## System Architecture

Wifano.ai employs a microservices architecture consisting of several key components:

1. **Reasoning Engine**: The core AI system responsible for processing queries and generating responses. This component requires significant GPU resources and is typically deployed across multiple nodes for load balancing.
2. **Knowledge System**: A distributed database architecture that stores and indexes the vast knowledge required for PhD-level reasoning. This includes vector databases, knowledge graphs, and traditional relational databases.
3. **Tool Framework**: A service that allows Wifano.ai to interact with external systems, execute code, and perform specialized tasks.
4. **Orchestration Layer**: Manages the coordination between different components, handles request routing, and manages system resources.
5. **API Gateway**: Provides a unified interface for client applications to interact with Wifano.ai services.


From a Linux infrastructure perspective, Wifano.ai typically runs on a Kubernetes cluster with the following characteristics:

```plaintext
                                  +-------------------+
                                  |   Load Balancer   |
                                  +--------+----------+
                                           |
                +-----------------------------+-----------------------------+
                |                            |                             |
    +-----------v-----------+   +-----------v-----------+   +-------------v-----------+
    |  API Gateway Nodes    |   |  API Gateway Nodes    |   |  API Gateway Nodes      |
    | (Ubuntu 22.04 LTS)    |   | (Ubuntu 22.04 LTS)    |   | (Ubuntu 22.04 LTS)      |
    +-----------+-----------+   +-----------+-----------+   +-------------+-----------+
                |                            |                             |
                +-----------------------------+-----------------------------+
                                           |
                                  +--------v----------+
                                  | Kubernetes Master |
                                  | (Control Plane)   |
                                  +--------+----------+
                                           |
        +-------------------------------+--+--+-------------------------------+
        |                              |     |                               |
+-------v------+              +--------v-----+--+                  +--------v---------+
| Worker Nodes |              | Worker Nodes    |                  | Worker Nodes     |
| (CPU-focused)|              | (GPU-equipped)  |                  | (Storage-focused)|
| - Orchestrator|              | - Reasoning Engine|                  | - Knowledge System |
| - API Services|              | - Inference     |                  | - Databases      |
+-------+------+              +--------+--------+                  +--------+---------+
        |                              |                                    |
        +------------------------------+------------------------------------+
                                       |
                           +-----------v------------+
                           |  Persistent Storage    |
                           |  - NFS/Ceph/GlusterFS  |
                           +-----------------------+
```

This distributed architecture allows Wifano.ai to scale horizontally, with different components scaled independently based on demand. The system typically requires:

- High-performance GPU nodes (NVIDIA A100 or equivalent) for the reasoning engine
- Memory-optimized nodes for the knowledge system
- General-purpose nodes for the orchestration layer and API gateway
- Distributed storage solution for persistent data


## Prerequisites and Environment Setup

Before installing Wifano.ai, ensure your Linux environment meets the following requirements:

### Hardware Requirements

For a production deployment of Wifano.ai, you'll need:

- **Minimum of 5 nodes**: 3 for control plane (master) and 2+ worker nodes
- **GPU nodes**: At least 2 nodes with NVIDIA A100 (or equivalent) GPUs, 8 GPUs per node recommended
- **CPU nodes**: 32+ cores per node, preferably AMD EPYC or Intel Xeon Platinum
- **Memory**: 512GB+ RAM per GPU node, 256GB+ per CPU node
- **Storage**: 2TB+ NVMe storage per node for local caching
- **Network**: 100Gbps interconnect (Infiniband or equivalent)
- **Persistent Storage**: 20TB+ distributed storage system (Ceph recommended)


### Software Prerequisites

Wifano.ai runs on modern Linux distributions with the following components:

```shellscript
# Check Linux distribution (Ubuntu 22.04 LTS recommended)
lsb_release -a

# Ensure system is up to date
sudo apt update && sudo apt upgrade -y

# Install required packages
sudo apt install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release

# Install Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io
sudo systemctl enable docker
sudo systemctl start docker

# Add current user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Install NVIDIA drivers and CUDA
sudo apt install -y linux-headers-$(uname -r)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID | sed -e 's/\.//g')
wget https://developer.download.nvidia.com/compute/cuda/repos/$distribution/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt update
sudo apt install -y cuda-drivers cuda

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID | sed -e 's/\.//g')
curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo systemctl restart docker

# Install Kubernetes components
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

# Disable swap (required for Kubernetes)
sudo swapoff -a
sudo sed -i '/ swap / s/^$$.*$$$/#\1/g' /etc/fstab

# Configure system settings for Kubernetes
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
sudo sysctl --system

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### Network Configuration

Wifano.ai requires specific network configurations for optimal performance:

```shellscript
# Configure firewall to allow Kubernetes and Wifano.ai traffic
sudo ufw allow 6443/tcp  # Kubernetes API server
sudo ufw allow 2379:2380/tcp  # etcd server client API
sudo ufw allow 10250/tcp  # Kubelet API
sudo ufw allow 10251/tcp  # kube-scheduler
sudo ufw allow 10252/tcp  # kube-controller-manager
sudo ufw allow 10255/tcp  # Read-only Kubelet API
sudo ufw allow 8080/tcp   # Wifano.ai API
sudo ufw allow 9090/tcp   # Prometheus
sudo ufw allow 3000/tcp   # Grafana
sudo ufw allow 9100/tcp   # Node exporter

# Enable IP forwarding
echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# Configure DNS for Wifano.ai services
sudo tee -a /etc/hosts <<EOF
127.0.0.1 wifano-api.local
127.0.0.1 wifano-dashboard.local
127.0.0.1 wifano-monitoring.local
EOF
```

### Environment Variables

Set up the environment variables required for Wifano.ai:

```shellscript
# Create environment file
cat <<EOF > ~/.wifano-env
# Wifano.ai Configuration
export WIFANO_HOME=/opt/wifano
export WIFANO_DATA=/data/wifano
export WIFANO_LOGS=/var/log/wifano
export WIFANO_CONFIG=/etc/wifano
export WIFANO_VERSION=3.2.1
export WIFANO_API_PORT=8080
export WIFANO_MONITORING_PORT=9090
export WIFANO_DASHBOARD_PORT=3000

# Kubernetes Configuration
export KUBECONFIG=/etc/kubernetes/admin.conf

# GPU Configuration
export NVIDIA_VISIBLE_DEVICES=all
export NVIDIA_DRIVER_CAPABILITIES=compute,utility
EOF

# Add to .bashrc
echo "source ~/.wifano-env" >> ~/.bashrc
source ~/.wifano-env

# Create required directories
sudo mkdir -p $WIFANO_HOME $WIFANO_DATA $WIFANO_LOGS $WIFANO_CONFIG
sudo chown -R $(id -u):$(id -g) $WIFANO_HOME $WIFANO_DATA $WIFANO_LOGS $WIFANO_CONFIG
```

## Installation Process

With the prerequisites in place, we can now proceed with the installation of Wifano.ai. The installation process involves several steps:

### 1. Initialize Kubernetes Cluster

First, we need to set up the Kubernetes cluster that will host Wifano.ai:

```shellscript
# Initialize the control plane
sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint="control-plane.wifano.local:6443" --upload-certs

# Set up kubeconfig for the current user
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Install Calico network plugin
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# Verify the cluster is running
kubectl get nodes
```

### 2. Configure GPU Support in Kubernetes

Next, we need to enable GPU support in the Kubernetes cluster:

```shellscript
# Install NVIDIA device plugin for Kubernetes
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.12.2/nvidia-device-plugin.yml

# Verify GPU support
kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
```

### 3. Set Up Helm for Wifano.ai

Helm is used to manage Wifano.ai deployments:

```shellscript
# Download and install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Add the Wifano Helm repository (this is a fictional URL)
helm repo add wifano https://charts.wifano.ai
helm repo update

# Verify the repository was added
helm repo list
```

### 4. Set Up Persistent Storage

Configure storage classes for Kubernetes:

```shellscript
# Create a storage class for Wifano
kubectl apply -f - << EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: wifano-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: wifano-pv
spec:
  capacity:
    storage: 1000Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: wifano-storage
  local:
    path: /data/wifano
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - wifano-storage-node
EOF

# Create a PersistentVolumeClaim for Wifano
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-pvc
  namespace: wifano-system
spec:
  storageClassName: wifano-storage
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
EOF
```

### 5. Install Wifano.ai Core Components

Now we can install the core Wifano.ai components:

```shellscript
# Create namespace for Wifano.ai
kubectl create namespace wifano-system

# Create secrets for Wifano.ai
kubectl create secret generic wifano-secrets \
  --namespace wifano-system \
  --from-literal=db-password=$(openssl rand -hex 16) \
  --from-literal=api-key=$(openssl rand -hex 32) \
  --from-literal=encryption-key=$(openssl rand -hex 32)

# Install Wifano.ai using Helm
helm install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai

# Verify the installation
kubectl get pods -n wifano-system
helm status wifano -n wifano-system
```

### 6. Install Wifano.ai CLI

The Wifano.ai CLI is a powerful tool for managing the system:

```shellscript
# Download the Wifano.ai CLI
curl -Lo wifano-cli https://downloads.wifano.ai/cli/wifano-cli-linux-amd64-${WIFANO_VERSION}
chmod +x wifano-cli
sudo mv wifano-cli /usr/local/bin/

# Configure the CLI
wifano-cli config set-context wifano-prod \
  --server=https://api.wifano.ai \
  --api-key=$(kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.api-key}' | base64 --decode)

# Verify the CLI is working
wifano-cli version
wifano-cli status
```

### 7. Install Monitoring Stack

Set up monitoring for Wifano.ai:

```shellscript
# Install Prometheus and Grafana for monitoring
helm install wifano-monitoring wifano/wifano-monitoring \
  --namespace wifano-monitoring \
  --create-namespace \
  --set grafana.adminPassword=$(openssl rand -hex 8) \
  --set prometheus.retention=15d \
  --set alertmanager.enabled=true

# Verify monitoring installation
kubectl get pods -n wifano-monitoring
```

## Core Configuration

After installation, Wifano.ai requires proper configuration to function optimally. This section covers the essential configuration steps.

### System Configuration

First, let's configure the core system parameters:

```shellscript
# Create ConfigMap for Wifano.ai configuration
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-config
  namespace: wifano-system
data:
  wifano.yaml: |
    system:
      log_level: INFO
      max_concurrent_requests: 100
      request_timeout: 300
      health_check_interval: 60
    
    reasoning_engine:
      model_path: /models/wifano-reasoning-v3
      max_tokens: 16384
      temperature: 0.7
      top_p: 0.95
      cache_size: 8192
      batch_size: 4
    
    knowledge_system:
      vector_db_uri: http://wifano-vector-db:6333
      knowledge_graph_uri: http://wifano-knowledge-graph:8182
      update_interval: 86400
      cache_ttl: 3600
      max_results: 50
    
    tool_framework:
      max_tools_per_request: 10
      tool_execution_timeout: 60
      allowed_domains:
        - wifano.ai
        - github.com
        - gitlab.com
      blocked_commands:
        - rm -rf
        - shutdown
        - reboot
    
    api_gateway:
      rate_limit: 100
      token_expiration: 86400
      cors_allowed_origins:
        - https://dashboard.wifano.ai
        - https://api.wifano.ai
EOF

# Apply the configuration
kubectl rollout restart deployment -n wifano-system
```

### Database Configuration

Configure the database settings for optimal performance:

```shellscript
# Connect to the Wifano database pod
WIFANO_DB_POD=$(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $WIFANO_DB_POD -n wifano-system -- bash

# Configure PostgreSQL for Wifano.ai
cat <<EOF > /var/lib/postgresql/data/postgresql.conf.d/wifano-optimizations.conf
# Memory Configuration
shared_buffers = 8GB
effective_cache_size = 24GB
work_mem = 128MB
maintenance_work_mem = 2GB

# Checkpoint Configuration
checkpoint_completion_target = 0.9
max_wal_size = 4GB
min_wal_size = 1GB

# Query Optimization
random_page_cost = 1.1
effective_io_concurrency = 200

# Parallel Query
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_parallel_maintenance_workers = 4

# Logging
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0
EOF

# Restart PostgreSQL to apply changes
exit
kubectl rollout restart statefulset wifano-db -n wifano-system
```

### Vector Database Configuration

Configure the vector database for knowledge retrieval:

```shellscript
# Connect to the vector database pod
WIFANO_VECTOR_POD=$(kubectl get pods -n wifano-system -l app=wifano-vector-db -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $WIFANO_VECTOR_POD -n wifano-system -- bash

# Configure Milvus/Qdrant (example for Qdrant)
cat <<EOF > /qdrant/config/config.yaml
log_level: INFO

storage:
  # Storage persistence path
  storage_path: /qdrant/storage
  
  # Size of RAM allocated for MMAP
  # Default: 50% of available RAM
  mmap_size_mb: 32768
  
  # Number of parallel threads for data indexing
  # Default: number of available CPU cores
  indexing_threads: 8
  
  # Optimization options
  optimization:
    # Interval between optimizations in seconds
    interval_sec: 3600
    # Number of segments to optimize per iteration
    segments_per_iteration: 10

service:
  # Host to bind the service on
  host: 0.0.0.0
  # HTTP port to bind the service on
  http_port: 6333
  # gRPC port to bind the service on
  grpc_port: 6334

cluster:
  # Enable cluster mode
  enabled: true
  # This node address in format: http://localhost:6335
  p2p:
    port: 6335
EOF

# Restart the vector database
exit
kubectl rollout restart statefulset wifano-vector-db -n wifano-system
```

### GPU Configuration

Optimize GPU settings for the reasoning engine:

```shellscript
# Create a ConfigMap for GPU optimization
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-gpu-config
  namespace: wifano-system
data:
  gpu-optimization.sh: |
    #!/bin/bash
    # Set GPU clock speeds to maximum (requires nvidia-smi with root privileges)
    nvidia-smi -pm 1
    nvidia-smi --auto-boost-default=0
    nvidia-smi -ac 5001,1590
    
    # Configure CUDA for optimal performance
    export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
    export CUDA_CACHE_PATH=/tmp/cuda-cache
    export CUDA_AUTO_BOOST=0
    export CUDA_DEVICE_MAX_CONNECTIONS=32
    
    # TensorRT optimization settings
    export TRT_MAX_WORKSPACE_SIZE=8589934592
    export TRT_FP16_ENABLE=1
    
    # PyTorch settings
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    export TORCH_CUDNN_V8_API_ENABLED=1
    export TORCH_USE_CUDA_DSA=1
EOF

# Update the Wifano reasoning deployment to use the GPU configuration
kubectl patch deployment wifano-reasoning -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/initContainers", 
    "value": [{
      "name": "gpu-init",
      "image": "nvidia/cuda:11.8.0-base-ubuntu22.04",
      "command": ["/bin/bash", "-c"],
      "args": ["cp /configmap/gpu-optimization.sh /shared && chmod +x /shared/gpu-optimization.sh"],
      "volumeMounts": [
        {"name": "gpu-config", "mountPath": "/configmap"},
        {"name": "shared-scripts", "mountPath": "/shared"}
      ]
    }]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {"name": "shared-scripts", "mountPath": "/scripts"}
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/command",
    "value": ["/bin/bash", "-c"]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/args",
    "value": ["source /scripts/gpu-optimization.sh && exec /wifano/start.sh"]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "gpu-config", "configMap": {"name": "wifano-gpu-config"}}
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "shared-scripts", "emptyDir": {}}
  }
]'
```

## Deployment Strategies

Deploying Wifano.ai in production requires careful planning. This section covers different deployment strategies.

### Blue-Green Deployment

Blue-green deployment allows for zero-downtime updates:

```shellscript
# Create a new "green" deployment
helm upgrade --install wifano-green wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=false \
  --set version=${WIFANO_VERSION}

# Wait for the green deployment to be ready
kubectl rollout status deployment wifano-green-reasoning -n wifano-system
kubectl rollout status deployment wifano-green-api -n wifano-system

# Test the green deployment
GREEN_API_POD=$(kubectl get pods -n wifano-system -l app=wifano-green-api -o jsonpath='{.items[0].metadata.name}')
kubectl port-forward $GREEN_API_POD 8081:8080 -n wifano-system &
curl -s http://localhost:8081/health | jq

# Switch traffic to the green deployment
kubectl patch service wifano-api -n wifano-system --type=json -p='[
  {
    "op": "replace", 
    "path": "/spec/selector/app", 
    "value": "wifano-green-api"
  }
]'

# Verify the switch
kubectl get endpoints wifano-api -n wifano-system

# If everything is working, remove the old "blue" deployment
helm uninstall wifano -n wifano-system

# Rename the green deployment to be the main deployment
helm upgrade --install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai \
  --set version=${WIFANO_VERSION}

# Clean up the green deployment
helm uninstall wifano-green -n wifano-system
```

### Canary Deployment

Canary deployment allows for gradual rollout of new versions:

```shellscript
# Deploy a canary version (10% of traffic)
helm upgrade --install wifano-canary wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=false \
  --set version=${WIFANO_VERSION}-canary

# Create a canary service
kubectl apply -f - << EOF
apiVersion: v1
kind: Service
metadata:
  name: wifano-api-canary
  namespace: wifano-system
spec:
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: wifano-canary-api
EOF

# Set up Istio for traffic splitting (requires Istio to be installed)
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api
        port:
          number: 8080
      weight: 90
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 10
EOF

# Monitor the canary deployment
kubectl logs -f -l app=wifano-canary-api -n wifano-system

# If the canary is stable, gradually increase its traffic
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api
        port:
          number: 8080
      weight: 50
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 50
EOF

# Eventually, promote the canary to be the main deployment
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 100
EOF

# Update the main deployment to match the canary
helm upgrade --install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai \
  --set version=${WIFANO_VERSION}

# Clean up the canary deployment
helm uninstall wifano-canary -n wifano-system
kubectl delete service wifano-api-canary -n wifano-system
```

## Performance Optimization

Optimizing Wifano.ai for maximum performance is critical for production deployments. This section covers various optimization techniques.

### Linux Kernel Tuning

Optimize the Linux kernel parameters for AI workloads:

```shellscript
# Create a sysctl configuration file for Wifano.ai
cat <<EOF | sudo tee /etc/sysctl.d/99-wifano.conf
# Virtual Memory Settings
vm.swappiness = 10
vm.dirty_ratio = 80
vm.dirty_background_ratio = 5
vm.max_map_count = 1048576

# Network Settings
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 250000
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_max_syn_backlog = 65536
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_tw_reuse = 1
net.ipv4.ip_local_port_range = 1024 65535

# File System Settings
fs.file-max = 2097152
fs.nr_open = 2097152
fs.inotify.max_user_watches = 524288
EOF

# Apply the settings
sudo sysctl --system

# Verify the changes
sudo sysctl -a | grep -E 'vm.swappiness|vm.dirty_ratio|vm.max_map_count|net.core.somaxconn'

# Configure user limits for Wifano.ai services
cat <<EOF | sudo tee /etc/security/limits.d/wifano.conf
# Wifano.ai service user limits
wifano soft nofile 1048576
wifano hard nofile 1048576
wifano soft nproc 65535
wifano hard nproc 65535
wifano soft memlock unlimited
wifano hard memlock unlimited
EOF

# Apply the limits to current session
ulimit -n 1048576
ulimit -u 65535
```

### GPU Optimization

Optimize GPU performance for Wifano.ai:

```shellscript
# Create a script for GPU optimization
cat <<EOF > ~/gpu-optimize.sh
#!/bin/bash

# Set GPU power limits to maximum
sudo nvidia-smi -pl 300

# Set GPU persistence mode
sudo nvidia-smi -pm 1

# Disable GPU autoboost
sudo nvidia-smi --auto-boost-default=0

# Set GPU clock speeds to maximum
sudo nvidia-smi -ac 5001,1590

# Configure GPU compute mode to exclusive process
sudo nvidia-smi -c 3

# Verify settings
echo "GPU Settings:"
nvidia-smi --query-gpu=name,pstate,memory.total,power.limit --format=csv
EOF

chmod +x ~/gpu-optimize.sh
sudo ~/gpu-optimize.sh

# Create a systemd service to apply settings on boot
cat <<EOF | sudo tee /etc/systemd/system/wifano-gpu-optimize.service
[Unit]
Description=Optimize GPUs for Wifano.ai
After=nvidia-persistenced.service

[Service]
Type=oneshot
ExecStart=/home/$(whoami)/gpu-optimize.sh
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable wifano-gpu-optimize.service
sudo systemctl start wifano-gpu-optimize.service
```

### Memory Optimization

Optimize memory usage for Wifano.ai:

```shellscript
# Install and configure Transparent Huge Pages for better memory performance
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/defrag

# Create a systemd service to disable THP on boot
cat <<EOF | sudo tee /etc/systemd/system/disable-thp.service
[Unit]
Description=Disable Transparent Huge Pages (THP)
After=network.target

[Service]
Type=oneshot
ExecStart=/bin/sh -c "echo never > /sys/kernel/mm/transparent_hugepage/enabled && echo never > /sys/kernel/mm/transparent_hugepage/defrag"
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable disable-thp.service
sudo systemctl start disable-thp.service

# Configure NUMA settings for optimal memory access
cat <<EOF | sudo tee /etc/systemd/system/wifano-numa.service
[Unit]
Description=Configure NUMA for Wifano.ai
After=network.target

[Service]
Type=oneshot
ExecStart=/bin/sh -c "numactl --hardware && echo 0 | sudo tee /proc/sys/kernel/numa_balancing"
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable wifano-numa.service
sudo systemctl start wifano-numa.service
```

### Network Optimization

Optimize network performance for Wifano.ai:

```shellscript
# Install and configure network performance tools
sudo apt install -y ethtool tuned

# Configure network interface for jumbo frames and optimize settings
INTERFACE=$(ip route | grep default | awk '{print $5}')
sudo ethtool -G $INTERFACE rx 4096 tx 4096
sudo ethtool -K $INTERFACE tso on gso on gro on lro on

# Set up tuned profile for network-latency
sudo tuned-adm profile network-latency

# Configure irqbalance for better network performance
cat <<EOF | sudo tee /etc/default/irqbalance
ENABLED="1"
ONESHOT="0"
OPTIONS="--hintpolicy=prefer"
EOF

sudo systemctl restart irqbalance

# Configure network settings for Kubernetes pods
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-network-config
  namespace: wifano-system
data:
  network-optimize.sh: |
    #!/bin/bash
    # Optimize network settings within container
    sysctl -w net.core.somaxconn=65535
    sysctl -w net.ipv4.tcp_max_syn_backlog=65536
    sysctl -w net.ipv4.tcp_slow_start_after_idle=0
    sysctl -w net.ipv4.tcp_keepalive_time=600
    sysctl -w net.ipv4.tcp_keepalive_intvl=60
    sysctl -w net.ipv4.tcp_keepalive_probes=10
EOF

# Update Wifano deployments to use network optimization
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/initContainers/-", 
    "value": {
      "name": "network-init",
      "image": "alpine:3.16",
      "command": ["/bin/sh", "-c"],
      "args": ["cp /configmap/network-optimize.sh /shared && chmod +x /shared/network-optimize.sh"],
      "volumeMounts": [
        {"name": "network-config", "mountPath": "/configmap"},
        {"name": "shared-scripts", "mountPath": "/shared"}
      ],
      "securityContext": {
        "privileged": true
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "network-config", "configMap": {"name": "wifano-network-config"}}
  }
]'
```

## Monitoring and Logging

Comprehensive monitoring and logging are essential for maintaining Wifano.ai in production.

### Prometheus and Grafana Setup

Set up advanced monitoring for Wifano.ai:

```shellscript
# Create a values file for the monitoring stack
cat <<EOF > wifano-monitoring-values.yaml
prometheus:
  prometheusSpec:
    retention: 15d
    resources:
      requests:
        memory: 2Gi
        cpu: 500m
      limits:
        memory: 4Gi
        cpu: 1000m
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: wifano-storage
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    additionalScrapeConfigs:
      - job_name: 'wifano-metrics'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - wifano-system
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            regex: wifano-.*
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_name]
            regex: metrics
            action: keep

grafana:
  adminPassword: "wifano-admin"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 10Gi
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'wifano'
          orgId: 1
          folder: 'Wifano'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/wifano
  dashboards:
    wifano:
      wifano-system-dashboard:
        json: |
          {
            "annotations": {
              "list": [
                {
                  "builtIn": 1,
                  "datasource": "-- Grafana --",
                  "enable": true,
                  "hide": true,
                  "iconColor": "rgba(0, 211, 255, 1)",
                  "name": "Annotations & Alerts",
                  "type": "dashboard"
                }
              ]
            },
            "editable": true,
            "gnetId": null,
            "graphTooltip": 0,
            "id": 1,
            "links": [],
            "panels": [
              {
                "aliasColors": {},
                "bars": false,
                "dashLength": 10,
                "dashes": false,
                "datasource": "Prometheus",
                "fieldConfig": {
                  "defaults": {
                    "custom": {}
                  },
                  "overrides": []
                },
                "fill": 1,
                "fillGradient": 0,
                "gridPos": {
                  "h": 8,
                  "w": 12,
                  "x": 0,
                  "y": 0
                },
                "hiddenSeries": false,
                "id": 2,
                "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
                },
                "lines": true,
                "linewidth": 1,
                "nullPointMode": "null",
                "options": {
                  "alertThreshold": true
                },
                "percentage": false,
                "pluginVersion": "7.2.0",
                "pointradius": 2,
                "points": false,
                "renderer": "flot",
                "seriesOverrides": [],
                "spaceLength": 10,
                "stack": false,
                "steppedLine": false,
                "targets": [
                  {
                    "expr": "sum(rate(wifano_requests_total[5m])) by (service)",
                    "interval": "",
                    "legendFormat": "{{service}}",
                    "refId": "A"
                  }
                ],
                "thresholds": [],
                "timeFrom": null,
                "timeRegions": [],
                "timeShift": null,
                "title": "Request Rate",
                "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
                },
                "type": "graph",
                "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": []
                },
                "yaxes": [
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  },
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  }
                ],
                "yaxis": {
                  "align": false,
                  "alignLevel": null
                }
              }
            ],
            "schemaVersion": 26,
            "style": "dark",
            "tags": [],
            "templating": {
              "list": []
            },
            "time": {
              "from": "now-6h",
              "to": "now"
            },
            "timepicker": {},
            "timezone": "",
            "title": "Wifano System Dashboard",
            "uid": "wifano-system",
            "version": 1
          }

alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'wifano-team'
      routes:
      - match:
          severity: critical
        receiver: 'wifano-team'
    receivers:
    - name: 'wifano-team'
      email_configs:
      - to: 'alerts@wifano.ai'
        from: 'prometheus@wifano.ai'
        smarthost: 'smtp.example.com:587'
        auth_username: 'prometheus@wifano.ai'
        auth_password: 'password'
        send_resolved: true
EOF

# Install the monitoring stack with custom values
helm upgrade --install wifano-monitoring wifano/wifano-monitoring \
  --namespace wifano-monitoring \
  --create-namespace \
  -f wifano-monitoring-values.yaml

# Verify the installation
kubectl get pods -n wifano-monitoring
```

### Centralized Logging with ELK Stack

Set up centralized logging for Wifano.ai:

```shellscript
# Create a values file for the ELK stack
cat <<EOF > wifano-logging-values.yaml
elasticsearch:
  replicas: 3
  resources:
    requests:
      cpu: "1000m"
      memory: "2Gi"
    limits:
      cpu: "2000m"
      memory: "4Gi"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 100Gi
  esJavaOpts: "-Xmx2g -Xms2g"

kibana:
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 5Gi

logstash:
  enabled: true
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 20Gi
  
filebeat:
  enabled: true
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/wifano-*.log
        processors:
          - add_kubernetes_metadata:
              host: \${NODE_NAME}
              matchers:
              - logs_path:
                  logs_path: "/var/log/containers/"
      
      output.logstash:
        hosts: ["wifano-logging-logstash:5044"]
EOF

# Install the ELK stack
helm repo add elastic https://helm.elastic.co
helm repo update
helm install wifano-logging elastic/elastic-stack \
  --namespace wifano-logging \
  --create-namespace \
  -f wifano-logging-values.yaml

# Configure Wifano.ai to send logs to the ELK stack
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-logging-config
  namespace: wifano-system
data:
  log4j2.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <Configuration status="INFO">
      <Appenders>
        <Console name="Console" target="SYSTEM_OUT">
          <PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n"/>
        </Console>
        <Socket name="Logstash" host="wifano-logging-logstash.wifano-logging.svc.cluster.local" port="5044" protocol="TCP">
          <JSONLayout complete="false" compact="true" eventEol="true" properties="true" propertiesAsList="true"/>
        </Socket>
      </Appenders>
      <Loggers>
        <Root level="info">
          <AppenderRef ref="Console"/>
          <AppenderRef ref="Logstash"/>
        </Root>
      </Loggers>
    </Configuration>
EOF

# Update Wifano deployments to use the logging configuration
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "logging-config", 
      "configMap": {
        "name": "wifano-logging-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "logging-config",
      "mountPath": "/wifano/config/log4j2.xml",
      "subPath": "log4j2.xml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "LOG4J_CONFIGURATION_FILE",
      "value": "/wifano/config/log4j2.xml"
    }
  }
]'
```

### Custom Metrics and Alerts

Set up custom metrics and alerts for Wifano.ai:

```shellscript
# Create custom Prometheus rules for Wifano.ai
kubectl apply -f - << EOF
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: wifano-alerts
  namespace: wifano-monitoring
spec:
  groups:
  - name: wifano.rules
    rules:
    - alert: WifanoHighErrorRate
      expr: sum(rate(wifano_errors_total[5m])) / sum(rate(wifano_requests_total[5m])) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate in Wifano.ai"
        description: "Wifano.ai is experiencing a high error rate (> 5%) for the last 5 minutes."
    
    - alert: WifanoHighLatency
      expr: histogram_quantile(0.95, sum(rate(wifano_request_duration_seconds_bucket[5m])) by (le)) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High latency in Wifano.ai"
        description: "95th percentile of request latency is above 2 seconds for the last 5 minutes."
    
    - alert: WifanoHighGPUUsage
      expr: avg(nvidia_gpu_duty_cycle) > 90
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "High GPU usage in Wifano.ai"
        description: "Average GPU usage is above 90% for the last 15 minutes."
    
    - alert: WifanoLowDiskSpace
      expr: kubelet_volume_stats_available_bytes{namespace="wifano-system"} / kubelet_volume_stats_capacity_bytes{namespace="wifano-system"} < 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Low disk space for Wifano.ai"
        description: "Wifano.ai is running out of disk space (< 10% available)."
EOF

# Create a custom metrics exporter for Wifano.ai
cat <<EOF > wifano-metrics-exporter.py
#!/usr/bin/env python3
import time
import random
import http.server
import socketserver
from prometheus_client import start_http_server, Counter, Gauge, Histogram

# Create metrics
REQUESTS = Counter('wifano_requests_total', 'Total number of requests', ['service', 'endpoint'])
ERRORS = Counter('wifano_errors_total', 'Total number of errors', ['service', 'error_type'])
LATENCY = Histogram('wifano_request_duration_seconds', 'Request duration in seconds', ['service', 'endpoint'], buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0])
ACTIVE_REQUESTS = Gauge('wifano_active_requests', 'Number of active requests', ['service'])
KNOWLEDGE_SIZE = Gauge('wifano_knowledge_size_bytes', 'Size of knowledge base in bytes')
MODEL_MEMORY_USAGE = Gauge('wifano_model_memory_usage_bytes', 'Memory usage of AI models')

# Simulate metrics for demonstration
def simulate_metrics():
    services = ['reasoning', 'knowledge', 'api', 'orchestrator']
    endpoints = ['query', 'update', 'health', 'status']
    error_types = ['timeout', 'validation', 'internal', 'database']
    
    while True:
        # Simulate requests
        for service in services:
            for endpoint in endpoints:
                REQUESTS.labels(service=service, endpoint=endpoint).inc(random.randint(1, 10))
                
                # Simulate latency
                with LATENCY.labels(service=service, endpoint=endpoint).time():
                    time.sleep(random.uniform(0.01, 0.1))
        
        # Simulate errors
        for service in services:
            for error_type in error_types:
                if random.random() < 0.1:  # 10% chance of error
                    ERRORS.labels(service=service, error_type=error_type).inc()
        
        # Simulate active requests
        for service in services:
            ACTIVE_REQUESTS.labels(service=service).set(random.randint(1, 100))
        
        # Simulate knowledge size (growing over time)
        current_size = KNOWLEDGE_SIZE._value.get()
        if current_size is None:
            current_size = 1000000000  # Start at 1GB
        KNOWLEDGE_SIZE.set(current_size + random.randint(1000000, 10000000))  # Add 1-10MB
        
        # Simulate model memory usage
        MODEL_MEMORY_USAGE.set(random.randint(10000000000, 20000000000))  # 10-20GB
        
        time.sleep(5)

if __name__ == '__main__':
    # Start up the server to expose the metrics.
    start_http_server(8000)
    print("Metrics server started on port 8000")
    
    # Start generating metrics
    simulate_metrics()
EOF

# Create a ConfigMap for the metrics exporter
kubectl create configmap wifano-metrics-exporter \
  --from-file=wifano-metrics-exporter.py \
  -n wifano-system

# Deploy the metrics exporter
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wifano-metrics-exporter
  namespace: wifano-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wifano-metrics-exporter
  template:
    metadata:
      labels:
        app: wifano-metrics-exporter
    spec:
      containers:
      - name: metrics-exporter
        image: python:3.9-slim
        command: ["python", "/app/wifano-metrics-exporter.py"]
        ports:
        - containerPort: 8000
          name: metrics
        volumeMounts:
        - name: exporter-config
          mountPath: /app
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      volumes:
      - name: exporter-config
        configMap:
          name: wifano-metrics-exporter
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-metrics-exporter
  namespace: wifano-system
  labels:
    app: wifano-metrics-exporter
spec:
  ports:
  - port: 8000
    targetPort: 8000
    name: metrics
  selector:
    app: wifano-metrics-exporter
EOF

# Create a ServiceMonitor to scrape the metrics
kubectl apply -f - << EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: wifano-metrics-monitor
  namespace: wifano-monitoring
spec:
  selector:
    matchLabels:
      app: wifano-metrics-exporter
  endpoints:
  - port: metrics
    interval: 15s
  namespaceSelector:
    matchNames:
    - wifano-system
EOF
```

## Security Hardening

Securing Wifano.ai is critical for production deployments. This section covers security best practices.

### Network Security

Implement network security measures for Wifano.ai:

```shellscript
# Create network policies to restrict traffic
kubectl apply -f - << EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-default-deny
  namespace: wifano-system
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-api-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-reasoning
    ports:
    - protocol: TCP
      port: 8080
  - to:
    - podSelector:
        matchLabels:
          app: wifano-knowledge
    ports:
    - protocol: TCP
      port: 8080
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-reasoning-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-reasoning
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: wifano-api
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-knowledge
    ports:
    - protocol: TCP
      port: 8080
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-knowledge-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-knowledge
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: wifano-api
    ports:
    - protocol: TCP
      port: 8080
  - from:
    - podSelector:
        matchLabels:
          app: wifano-reasoning
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-db
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: wifano-vector-db
    ports:
    - protocol: TCP
      port: 6333
EOF

# Set up TLS for Wifano.ai services
kubectl apply -f - << EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-tls
  namespace: wifano-system
spec:
  secretName: wifano-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: api.wifano.ai
  dnsNames:
  - api.wifano.ai
  - dashboard.wifano.ai
EOF

# Configure ingress with TLS
kubectl apply -f - << EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: wifano-ingress
  namespace: wifano-system
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  tls:
  - hosts:
    - api.wifano.ai
    - dashboard.wifano.ai
    secretName: wifano-tls
  rules:
  - host: api.wifano.ai
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: wifano-api
            port:
              number: 8080
  - host: dashboard.wifano.ai
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: wifano-dashboard
            port:
              number: 3000
EOF

# Implement API rate limiting
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx
data:
  proxy-connect-timeout: "10"
  proxy-read-timeout: "300"
  proxy-send-timeout: "300"
  proxy-body-size: "50m"
  limit-rps: "100"
  limit-connections: "50"
EOF
```

### Authentication and Authorization

Implement robust authentication and authorization for Wifano.ai:

```shellscript
# Create a ConfigMap for authentication configuration
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-auth-config
  namespace: wifano-system
data:
  auth.yaml: |
    auth:
      # JWT configuration
      jwt:
        secret_key: "\${JWT_SECRET}"
        expiration: 86400  # 24 hours
        refresh_expiration: 604800  # 7 days
      
      # API key configuration
      api_keys:
        enabled: true
        rotation_period: 90  # days
      
      # RBAC configuration
      rbac:
        roles:
          - name: admin
            permissions:
              - "*"
          - name: user
            permissions:
              - "query:*"
              - "knowledge:read"
          - name: knowledge_manager
            permissions:
              - "query:*"
              - "knowledge:*"
      
      # OAuth2 configuration
      oauth2:
        enabled: true
        providers:
          - name: google
            client_id: "\${OAUTH_GOOGLE_CLIENT_ID}"
            client_secret: "\${OAUTH_GOOGLE_CLIENT_SECRET}"
            redirect_uri: "https://api.wifano.ai/auth/callback/google"
          - name: github
            client_id: "\${OAUTH_GITHUB_CLIENT_ID}"
            client_secret: "\${OAUTH_GITHUB_CLIENT_SECRET}"
            redirect_uri: "https://api.wifano.ai/auth/callback/github"
EOF

# Create secrets for authentication
kubectl create secret generic wifano-auth-secrets \
  --namespace wifano-system \
  --from-literal=JWT_SECRET=$(openssl rand -hex 32) \
  --from-literal=OAUTH_GOOGLE_CLIENT_ID="your-google-client-id" \
  --from-literal=OAUTH_GOOGLE_CLIENT_SECRET="your-google-client-secret" \
  --from-literal=OAUTH_GITHUB_CLIENT_ID="your-github-client-id" \
  --from-literal=OAUTH_GITHUB_CLIENT_SECRET="your-github-client-secret"

# Update the API deployment to use authentication
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "auth-config", 
      "configMap": {
        "name": "wifano-auth-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "auth-config",
      "mountPath": "/wifano/config/auth.yaml",
      "subPath": "auth.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_AUTH_CONFIG",
      "value": "/wifano/config/auth.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/envFrom",
    "value": [
      {
        "secretRef": {
          "name": "wifano-auth-secrets"
        }
      }
    ]
  }
]'
```

### Data Encryption

Implement data encryption for Wifano.ai:

```shellscript
# Create encryption keys
ENCRYPTION_KEY=$(openssl rand -hex 32)
echo "Encryption Key: $ENCRYPTION_KEY"

# Create a secret for encryption keys
kubectl create secret generic wifano-encryption-keys \
  --namespace wifano-system \
  --from-literal=data-encryption-key=$ENCRYPTION_KEY

# Configure database encryption
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-db-encryption
  namespace: wifano-system
data:
  db-encryption.yaml: |
    encryption:
      enabled: true
      key_source: env
      key_env_var: DATA_ENCRYPTION_KEY
      algorithms:
        - name: AES-256-GCM
          default: true
        - name: ChaCha20-Poly1305
      encrypted_fields:
        - table: users
          fields: [password, email, personal_data]
        - table: api_keys
          fields: [key_value]
        - table: knowledge_items
          fields: [content, metadata]
EOF

# Update the database deployment to use encryption
kubectl patch statefulset wifano-db -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "db-encryption-config", 
      "configMap": {
        "name": "wifano-db-encryption"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "db-encryption-config",
      "mountPath": "/wifano/config/db-encryption.yaml",
      "subPath": "db-encryption.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_ENCRYPTION_CONFIG",
      "value": "/wifano/config/db-encryption.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "DATA_ENCRYPTION_KEY",
      "valueFrom": {
        "secretKeyRef": {
          "name": "wifano-encryption-keys",
          "key": "data-encryption-key"
        }
      }
    }
  }
]'

# Configure TLS for internal communication
kubectl apply -f - << EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-internal-tls
  namespace: wifano-system
spec:
  secretName: wifano-internal-tls
  issuerRef:
    name: wifano-ca
    kind: Issuer
  commonName: wifano-internal
  dnsNames:
  - wifano-api.wifano-system.svc.cluster.local
  - wifano-reasoning.wifano-system.svc.cluster.local
  - wifano-knowledge.wifano-system.svc.cluster.local
  - wifano-db.wifano-system.svc.cluster.local
  - wifano-vector-db.wifano-system.svc.cluster.local
EOF

# Update services to use TLS
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "internal-tls", 
      "secret": {
        "secretName": "wifano-internal-tls"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "internal-tls",
      "mountPath": "/wifano/certs"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_TLS_CERT",
      "value": "/wifano/certs/tls.crt"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_TLS_KEY",
      "value": "/wifano/certs/tls.key"
    }
  }
]'
```

## Scaling Wifano.ai

Scaling Wifano.ai to handle increased load is essential for production deployments.

### Horizontal Scaling

Implement horizontal scaling for Wifano.ai:

```shellscript
# Create a Horizontal Pod Autoscaler for the API
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-api-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
EOF

# Create a Horizontal Pod Autoscaler for the reasoning engine
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-reasoning-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-reasoning
  minReplicas: 2
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: nvidia_gpu_duty_cycle
      target:
        type: AverageValue
        averageValue: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 120
      policies:
      - type: Pods
        value: 1
        periodSeconds: 120
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 300
EOF

# Create a Horizontal Pod Autoscaler for the knowledge system
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-knowledge-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-knowledge
  minReplicas: 2
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
EOF
```

### Vertical Scaling

Implement vertical scaling for Wifano.ai:

```shellscript
# Install the Vertical Pod Autoscaler
kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/vertical-pod-autoscaler/deploy/vpa-v0.9.2.yaml

# Create a Vertical Pod Autoscaler for the API
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-api-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-api
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 500m
        memory: 1Gi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
EOF

# Create a Vertical Pod Autoscaler for the reasoning engine
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-reasoning-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-reasoning
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 2
        memory: 8Gi
      maxAllowed:
        cpu: 16
        memory: 64Gi
      controlledResources: ["cpu", "memory"]
EOF

# Create a Vertical Pod Autoscaler for the knowledge system
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-knowledge-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-knowledge
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 1
        memory: 4Gi
      maxAllowed:
        cpu: 8
        memory: 32Gi
      controlledResources: ["cpu", "memory"]
EOF
```

### Load Testing

Implement load testing for Wifano.ai:

```shellscript
# Create a load testing script
cat <<EOF > wifano-load-test.js
import http from 'k6/http';
import { sleep, check } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 }, // Ramp up to 100 users over 2 minutes
    { duration: '5m', target: 100 }, // Stay at 100 users for 5 minutes
    { duration: '2m', target: 200 }, // Ramp up to 200 users over 2 minutes
    { duration: '5m', target: 200 }, // Stay at 200 users for 5 minutes
    { duration: '2m', target: 300 }, // Ramp up to 300 users over 2 minutes
    { duration: '5m', target: 300 }, // Stay at 300 users for 5 minutes
    { duration: '2m', target: 0 },   // Ramp down to 0 users over 2 minutes
  ],
  thresholds: {
    http_req_duration: ['p(95)<2000'], // 95% of requests should complete within 2s
    http_req_failed: ['rate<0.05'],    // Less than 5% of requests should fail
  },
};

const API_KEY = 'your-api-key';
const BASE_URL = 'https://api.wifano.ai';

export default function () {
  const headers = {
    'Content-Type': 'application/json',
    'Authorization': `Bearer \${API_KEY}`,
  };

  // Simple query test
  const queryPayload = JSON.stringify({
    query: 'What is the relationship between quantum entanglement and information theory?',
    max_tokens: 1000,
  });

  const queryResponse = http.post(`\${BASE_URL}/v1/query`, queryPayload, { headers });
  
  check(queryResponse, {
    'query status is 200': (r) => r.status === 200,
    'query response has content': (r) => r.json().content !== undefined,
    'query response time < 2s': (r) => r.timings.duration < 2000,
  });

  // Knowledge retrieval test
  const knowledgeResponse = http.get(`\${BASE_URL}/v1/knowledge/search?q=quantum+computing`, { headers });
  
  check(knowledgeResponse, {
    'knowledge status is 200': (r) => r.status === 200,
    'knowledge response has results': (r) => r.json().results.length > 0,
    'knowledge response time < 1s': (r) => r.timings.duration < 1000,
  });

  // Health check test
  const healthResponse = http.get(`\${BASE_URL}/health`);
  
  check(healthResponse, {
    'health status is 200': (r) => r.status === 200,
    'health response is ok': (r) => r.json().status === 'ok',
    'health response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);
}
EOF

# Run the load test
k6 run wifano-load-test.js

# Create a Kubernetes job for load testing
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: wifano-load-test
  namespace: wifano-system
spec:
  template:
    spec:
      containers:
      - name: k6
        image: loadimpact/k6:latest
        command: ["k6", "run", "/tests/wifano-load-test.js"]
        volumeMounts:
        - name: test-config
          mountPath: /tests
      volumes:
      - name: test-config
        configMap:
          name: wifano-load-test
      restartPolicy: Never
  backoffLimit: 0
EOF

# Create a ConfigMap for the load test script
kubectl create configmap wifano-load-test \
  --from-file=wifano-load-test.js \
  -n wifano-system

# Run the load test job
kubectl create job --from=cronjob/wifano-load-test wifano-load-test-manual -n wifano-system

# Monitor the load test results
kubectl logs -f job/wifano-load-test-manual -n wifano-system
```

## High Availability Setup

Implementing high availability for Wifano.ai ensures the system remains operational even during failures.

### Multi-Zone Deployment

Configure Wifano.ai for multi-zone deployment:

```shellscript
# Label nodes with availability zones
kubectl label nodes node1 topology.kubernetes.io/zone=zone-a
kubectl label nodes node2 topology.kubernetes.io/zone=zone-a
kubectl label nodes node3 topology.kubernetes.io/zone=zone-b
kubectl label nodes node4 topology.kubernetes.io/zone=zone-b
kubectl label nodes node5 topology.kubernetes.io/zone=zone-c
kubectl label nodes node6 topology.kubernetes.io/zone=zone-c

# Update deployments for zone distribution
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-api"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'

# Apply similar configurations to other deployments
kubectl patch deployment wifano-reasoning -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-reasoning"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'

kubectl patch deployment wifano-knowledge -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-knowledge"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'
```

### Database High Availability

Configure high availability for Wifano.ai databases:

```shellscript
# Create a StatefulSet for PostgreSQL with replication
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: wifano-db
  namespace: wifano-system
spec:
  serviceName: wifano-db
  replicas: 3
  selector:
    matchLabels:
      app: wifano-db
  template:
    metadata:
      labels:
        app: wifano-db
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_USER
          value: wifano
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: POSTGRES_DB
          value: wifano
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql/conf.d
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - wifano
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - wifano
          initialDelaySeconds: 30
          periodSeconds: 15
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: wifano-storage
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: wifano-system
data:
  postgresql.conf: |
    listen_addresses = '*'
    max_connections = 100
    shared_buffers = 4GB
    effective_cache_size = 12GB
    work_mem = 64MB
    maintenance_work_mem = 512MB
    random_page_cost = 1.1
    effective_io_concurrency = 200
    max_worker_processes = 8
    max_parallel_workers_per_gather = 4
    max_parallel_workers = 8
    wal_level = replica
    max_wal_senders = 10
    max_replication_slots = 10
    hot_standby = on
  pg_hba.conf: |
    local   all             all                                     trust
    host    all             all             127.0.0.1/32            trust
    host    all             all             ::1/128                 trust
    host    all             all             0.0.0.0/0               md5
    host    replication     all             0.0.0.0/0               md5
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db
  namespace: wifano-system
spec:
  selector:
    app: wifano-db
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-read
  namespace: wifano-system
spec:
  selector:
    app: wifano-db
  ports:
  - port: 5432
    targetPort: 5432
EOF

# Set up Patroni for PostgreSQL high availability
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: wifano-db-patroni
  namespace: wifano-system
spec:
  serviceName: wifano-db-patroni
  replicas: 3
  selector:
    matchLabels:
      app: wifano-db-patroni
  template:
    metadata:
      labels:
        app: wifano-db-patroni
    spec:
      containers:
      - name: patroni
        image: registry.opensource.zalan.do/acid/patroni:2.0.2
        env:
        - name: PATRONI_KUBERNETES_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: PATRONI_KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: PATRONI_KUBERNETES_LABELS
          value: '{app: wifano-db-patroni}'
        - name: PATRONI_SUPERUSER_USERNAME
          value: postgres
        - name: PATRONI_SUPERUSER_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: PATRONI_REPLICATION_USERNAME
          value: replicator
        - name: PATRONI_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: PATRONI_SCOPE
          value: wifano-db
        - name: PATRONI_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        ports:
        - containerPort: 8008
          name: patroni
        - containerPort: 5432
          name: postgres
        volumeMounts:
        - name: data
          mountPath: /home/postgres/pgdata
        readinessProbe:
          httpGet:
            path: /readiness
            port: 8008
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /liveness
            port: 8008
          initialDelaySeconds: 30
          periodSeconds: 15
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: wifano-db-patroni-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-db-patroni-data
  namespace: wifano-system
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: wifano-storage
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni
  namespace: wifano-system
spec:
  selector:
    app: wifano-db-patroni
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni-master
  namespace: wifano-system
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  selector:
    app: wifano-db-patroni
    role: master
  ports:
  - port: 5432
    targetPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni-replica
  namespace: wifano-system
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  selector:
    app: wifano-db-patroni
    role: replica
  ports:
  - port: 5432
    targetPort: 5432
EOF
```

### Fault Tolerance

Implement fault tolerance for Wifano.ai:

```shellscript
# Configure pod disruption budgets
kubectl apply -f - << EOF
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-api-pdb
  namespace: wifano-system
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: wifano-api
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-reasoning-pdb
  namespace: wifano-system
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: wifano-reasoning
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-knowledge-pdb
  namespace: wifano-system
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: wifano-knowledge
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-db-pdb
  namespace: wifano-system
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: wifano-db
EOF

# Configure liveness and readiness probes
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/containers/0/livenessProbe", 
    "value": {
      "httpGet": {
        "path": "/health",
        "port": 8080
      },
      "initialDelaySeconds": 30,
      "periodSeconds": 10,
      "timeoutSeconds": 5,
      "failureThreshold": 3
    }
  },
  {
    "op": "add", 
    "path": "/spec/template/spec/containers/0/readinessProbe", 
    "value": {
      "httpGet": {
        "path": "/ready",
        "port": 8080
      },
      "initialDelaySeconds": 5,
      "periodSeconds": 5,
      "timeoutSeconds": 3,
      "failureThreshold": 2
    }
  }
]'

# Configure circuit breakers
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: wifano-api-circuit-breaker
  namespace: wifano-system
spec:
  host: wifano-api
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 100
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: wifano-reasoning-circuit-breaker
  namespace: wifano-system
spec:
  host: wifano-reasoning
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 50
      http:
        http1MaxPendingRequests: 50
        maxRequestsPerConnection: 5
    outlierDetection:
      consecutive5xxErrors: 3
      interval: 30s
      baseEjectionTime: 60s
      maxEjectionPercent: 100
EOF
```

## Backup and Disaster Recovery

Implementing backup and disaster recovery procedures is essential for Wifano.ai.

### Database Backups

Configure database backups for Wifano.ai:

```shellscript
# Create a backup script
cat <<EOF > wifano-db-backup.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\${BACKUP_DIR}/wifano_db_\${TIMESTAMP}.sql.gz"
LOG_FILE="\${BACKUP_DIR}/backup_\${TIMESTAMP}.log"

# Ensure backup directory exists
mkdir -p \${BACKUP_DIR}

# Log start time
echo "Starting backup at \$(date)" > \${LOG_FILE}

# Perform backup
echo "Creating database dump..." >> \${LOG_FILE}
PGPASSWORD=\${POSTGRES_PASSWORD} pg_dump -h wifano-db -U wifano -d wifano | gzip > \${BACKUP_FILE}

# Check if backup was successful
if [ \$? -eq 0 ]; then
  echo "Backup completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Backup file: \${BACKUP_FILE}" >> \${LOG_FILE}
  echo "Backup size: \$(du -h \${BACKUP_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Backup failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

# Rotate old backups (keep last 30 days)
find \${BACKUP_DIR} -name "wifano_db_*.sql.gz" -type f -mtime +30 -delete

# Upload to remote storage (optional)
if [ ! -z "\${S3_BUCKET}" ]; then
  echo "Uploading backup to S3..." >> \${LOG_FILE}
  aws s3 cp \${BACKUP_FILE} s3://\${S3_BUCKET}/wifano/db/
  if [ \$? -eq 0 ]; then
    echo "Upload to S3 completed successfully" >> \${LOG_FILE}
  else
    echo "Upload to S3 failed" >> \${LOG_FILE}
  fi
fi

echo "Backup process completed at \$(date)" >> \${LOG_FILE}
EOF

chmod +x wifano-db-backup.sh

# Create a ConfigMap for the backup script
kubectl create configmap wifano-backup-scripts \
  --from-file=wifano-db-backup.sh \
  -n wifano-system

# Create a CronJob for regular backups
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-db-backup
  namespace: wifano-system
spec:
  schedule: "0 2 * * *"  # Run daily at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:14
            command: ["/scripts/wifano-db-backup.sh"]
            env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: wifano-secrets
                  key: db-password
            - name: S3_BUCKET
              value: "wifano-backups"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-secret-key
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
          volumes:
          - name: backup-scripts
            configMap:
              name: wifano-backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          restartPolicy: OnFailure
EOF

# Create a PVC for backup storage
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-backup-pvc
  namespace: wifano-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: wifano-storage
EOF

# Create secrets for backup credentials
kubectl create secret generic wifano-backup-credentials \
  --namespace wifano-system \
  --from-literal=aws-access-key=YOUR_AWS_ACCESS_KEY \
  --from-literal=aws-secret-key=YOUR_AWS_SECRET_KEY
```

### Knowledge Base Backups

Configure knowledge base backups for Wifano.ai:

```shellscript
# Create a knowledge base backup script
cat <<EOF > wifano-knowledge-backup.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups/knowledge"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\${BACKUP_DIR}/wifano_knowledge_\${TIMESTAMP}.tar.gz"
LOG_FILE="\${BACKUP_DIR}/backup_\${TIMESTAMP}.log"

# Ensure backup directory exists
mkdir -p \${BACKUP_DIR}

# Log start time
echo "Starting knowledge base backup at \$(date)" > \${LOG_FILE}

# Perform backup of vector database
echo "Creating vector database dump..." >> \${LOG_FILE}
curl -X POST "http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots" \
  -H "Content-Type: application/json" \
  -d '{"snapshot_path": "/snapshots/wifano_embeddings_\${TIMESTAMP}"}' >> \${LOG_FILE} 2>&1

# Backup knowledge graph
echo "Creating knowledge graph dump..." >> \${LOG_FILE}
curl -X GET "http://wifano-knowledge-graph:8182/graphs/wifano/backup" \
  -H "Content-Type: application/json" \
  -d '{"backupPath": "/backups/wifano_graph_\${TIMESTAMP}"}' >> \${LOG_FILE} 2>&1

# Create a tarball of all knowledge data
echo "Creating tarball of knowledge data..." >> \${LOG_FILE}
tar -czf \${BACKUP_FILE} -C /snapshots wifano_embeddings_\${TIMESTAMP} -C /backups wifano_graph_\${TIMESTAMP} >> \${LOG_FILE} 2>&1

# Check if backup was successful
if [ \$? -eq 0 ]; then
  echo "Backup completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Backup file: \${BACKUP_FILE}" >> \${LOG_FILE}
  echo "Backup size: \$(du -h \${BACKUP_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Backup failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

# Rotate old backups (keep last 7 days)
find \${BACKUP_DIR} -name "wifano_knowledge_*.tar.gz" -type f -mtime +7 -delete

# Upload to remote storage (optional)
if [ ! -z "\${S3_BUCKET}" ]; then
  echo "Uploading backup to S3..." >> \${LOG_FILE}
  aws s3 cp \${BACKUP_FILE} s3://\${S3_BUCKET}/wifano/knowledge/
  if [ \$? -eq 0 ]; then
    echo "Upload to S3 completed successfully" >> \${LOG_FILE}
  else
    echo "Upload to S3 failed" >> \${LOG_FILE}
  fi
fi

echo "Knowledge backup process completed at \$(date)" >> \${LOG_FILE}
EOF

chmod +x wifano-knowledge-backup.sh

# Add the knowledge backup script to the ConfigMap
kubectl create configmap wifano-knowledge-backup-scripts \
  --from-file=wifano-knowledge-backup.sh \
  -n wifano-system

# Create a CronJob for regular knowledge backups
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-knowledge-backup
  namespace: wifano-system
spec:
  schedule: "0 3 * * *"  # Run daily at 3 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: amazon/aws-cli:latest
            command: ["/scripts/wifano-knowledge-backup.sh"]
            env:
            - name: S3_BUCKET
              value: "wifano-backups"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-secret-key
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
            - name: snapshot-storage
              mountPath: /snapshots
          volumes:
          - name: backup-scripts
            configMap:
              name: wifano-knowledge-backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          - name: snapshot-storage
            persistentVolumeClaim:
              claimName: wifano-snapshot-pvc
          restartPolicy: OnFailure
EOF

# Create a PVC for snapshot storage
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-snapshot-pvc
  namespace: wifano-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  storageClassName: wifano-storage
EOF
```

### Disaster Recovery Plan

Create a disaster recovery plan for Wifano.ai:

```shellscript
# Create a disaster recovery script
cat <<EOF > wifano-disaster-recovery.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups"
RESTORE_LOG="/var/log/wifano-restore.log"

# Function to display usage
usage() {
  echo "Usage: \$0 [OPTIONS]"
  echo "Options:"
  echo "  --db-backup FILE     Specify the database backup file to restore"
  echo "  --knowledge-backup FILE  Specify the knowledge backup file to restore"
  echo "  --config-backup FILE     Specify the configuration backup file to restore"
  echo "  --full-restore       Perform a full system restore (requires all backup files)"
  echo "  --help               Display this help message"
  exit 1
}

# Parse command line arguments
while [[ \$# -gt 0 ]]; do
  key="\$1"
  case \$key in
    --db-backup)
      DB_BACKUP="\$2"
      shift
      shift
      ;;
    --knowledge-backup)
      KNOWLEDGE_BACKUP="\$2"
      shift
      shift
      ;;
    --config-backup)
      CONFIG_BACKUP="\$2"
      shift
      shift
      ;;
    --full-restore)
      FULL_RESTORE=true
      shift
      ;;
    --help)
      usage
      ;;
    *)
      echo "Unknown option: \$1"
      usage
      ;;
  esac
done

# Log start time
echo "Starting disaster recovery at \$(date)" > \${RESTORE_LOG}

# Restore database if specified
if [ ! -z "\${DB_BACKUP}" ]; then
  echo "Restoring database from \${DB_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Stop database-dependent services
  echo "Stopping database-dependent services..." | tee -a \${RESTORE_LOG}
  kubectl scale deployment wifano-api --replicas=0 -n wifano-system
  kubectl scale deployment wifano-knowledge --replicas=0 -n wifano-system
  
  # Wait for services to stop
  echo "Waiting for services to stop..." | tee -a \${RESTORE_LOG}
  kubectl wait --for=delete pod -l app=wifano-api -n wifano-system --timeout=300s
  kubectl wait --for=delete pod -l app=wifano-knowledge -n wifano-system --timeout=300s
  
  # Restore database
  echo "Performing database restore..." | tee -a \${RESTORE_LOG}
  if [[ \${DB_BACKUP} == *.gz ]]; then
    gunzip -c \${DB_BACKUP} | PGPASSWORD=\${POSTGRES_PASSWORD} psql -h wifano-db -U wifano -d wifano
  else
    PGPASSWORD=\${POSTGRES_PASSWORD} psql -h wifano-db -U wifano -d wifano -f \${DB_BACKUP}
  fi
  
  # Check restore status
  if [ \$? -eq 0 ]; then
    echo "Database restore completed successfully" | tee -a \${RESTORE_LOG}
  else
    echo "Database restore failed" | tee -a \${RESTORE_LOG}
    exit 1
  fi
  
  # Restart services
  echo "Restarting database-dependent services..." | tee -a \${RESTORE_LOG}
  kubectl scale deployment wifano-api --replicas=3 -n wifano-system
  kubectl scale deployment wifano-knowledge --replicas=2 -n wifano-system
fi

# Restore knowledge base if specified
if [ ! -z "\${KNOWLEDGE_BACKUP}" ]; then
  echo "Restoring knowledge base from \${KNOWLEDGE_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Extract the knowledge backup
  echo "Extracting knowledge backup..." | tee -a \${RESTORE_LOG}
  mkdir -p /tmp/knowledge-restore
  tar -xzf \${KNOWLEDGE_BACKUP} -C /tmp/knowledge-restore
  
  # Restore vector database
  echo "Restoring vector database..." | tee -a \${RESTORE_LOG}
  VECTOR_SNAPSHOT=\$(find /tmp/knowledge-restore -name "wifano_embeddings_*" | head -1)
  curl -X PUT "http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots/restore" \
    -H "Content-Type: application/json" \
    -d "{\"snapshot_path\": \"\${VECTOR_SNAPSHOT}\"}" >> \${RESTORE_LOG} 2>&1
  
  # Restore knowledge graph
  echo "Restoring knowledge graph..." | tee -a \${RESTORE_LOG}
  GRAPH_BACKUP=\$(find /tmp/knowledge-restore -name "wifano_graph_*" | head -1)
  curl -X POST "http://wifano-knowledge-graph:8182/graphs/wifano/restore" \
    -H "Content-Type: application/json" \
    -d "{\"backupPath\": \"\${GRAPH_BACKUP}\"}" >> \${RESTORE_LOG} 2>&1
  
  # Clean up
  rm -rf /tmp/knowledge-restore
  
  # Restart knowledge services
  echo "Restarting knowledge services..." | tee -a \${RESTORE_LOG}
  kubectl rollout restart deployment wifano-knowledge -n wifano-system
fi

# Restore configuration if specified
if [ ! -z "\${CONFIG_BACKUP}" ]; then
  echo "Restoring configuration from \${CONFIG_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Extract the configuration backup
  echo "Extracting configuration backup..." | tee -a \${RESTORE_LOG}
  mkdir -p /tmp/config-restore
  tar -xzf \${CONFIG_BACKUP} -C /tmp/config-restore
  
  # Apply configuration
  echo "Applying configuration..." | tee -a \${RESTORE_LOG}
  kubectl apply -f /tmp/config-restore/configmaps.yaml -n wifano-system
  kubectl apply -f /tmp/config-restore/secrets.yaml -n wifano-system
  
  # Clean up
  rm -rf /tmp/config-restore
  
  # Restart all services to apply new configuration
  echo "Restarting all services to apply new configuration..." | tee -a \${RESTORE_LOG}
  kubectl rollout restart deployment -n wifano-system
fi

# Perform full system restore if specified
if [ "\${FULL_RESTORE}" = true ]; then
  if [ -z "\${DB_BACKUP}" ] || [ -z "\${KNOWLEDGE_BACKUP}" ] || [ -z "\${CONFIG_BACKUP}" ]; then
    echo "Full restore requires all backup files to be specified" | tee -a \${RESTORE_LOG}
    exit 1
  fi
  
  echo "Performing full system verification..." | tee -a \${RESTORE_LOG}
  
  # Wait for all services to be ready
  echo "Waiting for all services to be ready..." | tee -a \${RESTORE_LOG}
  kubectl wait --for=condition=available deployment --all -n wifano-system --timeout=600s
  
  # Verify system health
  echo "Verifying system health..." | tee -a \${RESTORE_LOG}
  wifano-cli system health --full >> \${RESTORE_LOG} 2>&1
  
  # Run system tests
  echo "Running system tests..." | tee -a \${RESTORE_LOG}
  wifano-cli test run --suite basic >> \${RESTORE_LOG} 2>&1
  
  # Check test results
  if [ \$? -eq 0 ]; then
    echo "System tests passed. Full restore completed successfully." | tee -a \${RESTORE_LOG}
  else
    echo "System tests failed. Please check the logs for details." | tee -a \${RESTORE_LOG}
    exit 1
  fi
fi

echo "Disaster recovery process completed at \$(date)" | tee -a \${RESTORE_LOG}
EOF

chmod +x wifano-disaster-recovery.sh

# Create a ConfigMap for the disaster recovery script
kubectl create configmap wifano-dr-scripts \
  --from-file=wifano-disaster-recovery.sh \
  -n wifano-system

# Create a disaster recovery job template
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: wifano-disaster-recovery
  namespace: wifano-system
spec:
  template:
    spec:
      containers:
      - name: recovery
        image: postgres:14
        command: ["/scripts/wifano-disaster-recovery.sh"]
        args: ["--full-restore", "--db-backup", "/backups/wifano_db_latest.sql.gz", "--knowledge-backup", "/backups/wifano_knowledge_latest.tar.gz", "--config-backup", "/backups/wifano_config_latest.tar.gz"]
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        volumeMounts:
        - name: dr-scripts
          mountPath: /scripts
        - name: backup-storage
          mountPath: /backups
      volumes:
      - name: dr-scripts
        configMap:
          name: wifano-dr-scripts
          defaultMode: 0755
      - name: backup-storage
        persistentVolumeClaim:
          claimName: wifano-backup-pvc
      restartPolicy: OnFailure
EOF

# Create symbolic links to the latest backups
cat <<EOF > update-latest-backups.sh
#!/bin/bash

# Set backup directory
BACKUP_DIR="/backups"

# Update database backup symlink
DB_LATEST=\$(ls -t \${BACKUP_DIR}/wifano_db_*.sql.gz | head -1)
if [ ! -z "\${DB_LATEST}" ]; then
  ln -sf \${DB_LATEST} \${BACKUP_DIR}/wifano_db_latest.sql.gz
fi

# Update knowledge backup symlink
KNOWLEDGE_LATEST=\$(ls -t \${BACKUP_DIR}/knowledge/wifano_knowledge_*.tar.gz | head -1)
if [ ! -z "\${KNOWLEDGE_LATEST}" ]; then
  ln -sf \${KNOWLEDGE_LATEST} \${BACKUP_DIR}/wifano_knowledge_latest.tar.gz
fi

# Update config backup symlink
CONFIG_LATEST=\$(ls -t \${BACKUP_DIR}/config/wifano_config_*.tar.gz | head -1)
if [ ! -z "\${CONFIG_LATEST}" ]; then
  ln -sf \${CONFIG_LATEST} \${BACKUP_DIR}/wifano_config_latest.tar.gz
fi
EOF

chmod +x update-latest-backups.sh

# Add the script to the ConfigMap
kubectl create configmap wifano-backup-utils \
  --from-file=update-latest-backups.sh \
  -n wifano-system

# Create a CronJob to update the latest backup symlinks
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-update-latest-backups
  namespace: wifano-system
spec:
  schedule: "0 5 * * *"  # Run daily at 5 AM
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: update-symlinks
            image: alpine:latest
            command: ["/scripts/update-latest-backups.sh"]
            volumeMounts:
            - name: backup-utils
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
          volumes:
          - name: backup-utils
            configMap:
              name: wifano-backup-utils
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          restartPolicy: OnFailure
EOF
```

## Troubleshooting Common Issues

This section provides guidance on troubleshooting common issues with Wifano.ai.

### Diagnostic Tools

Set up diagnostic tools for Wifano.ai:

```shellscript
# Create a diagnostic script
cat <<EOF > wifano-diagnostics.sh
#!/bin/bash

# Set variables
DIAG_DIR="/tmp/wifano-diagnostics"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
DIAG_FILE="\${DIAG_DIR}/wifano_diagnostics_\${TIMESTAMP}.tar.gz"
LOG_FILE="\${DIAG_DIR}/diagnostics_\${TIMESTAMP}.log"

# Ensure diagnostic directory exists
mkdir -p \${DIAG_DIR}

# Log start time
echo "Starting diagnostics at \$(date)" > \${LOG_FILE}

# Collect system information
echo "Collecting system information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/system
uname -a > \${DIAG_DIR}/system/uname.txt
cat /etc/os-release > \${DIAG_DIR}/system/os-release.txt
free -h > \${DIAG_DIR}/system/memory.txt
df -h > \${DIAG_DIR}/system/disk.txt
top -b -n 1 > \${DIAG_DIR}/system/top.txt
ps aux > \${DIAG_DIR}/system/processes.txt
netstat -tuln > \${DIAG_DIR}/system/netstat.txt
ip addr > \${DIAG_DIR}/system/ip-addr.txt
ip route > \${DIAG_DIR}/system/ip-route.txt

# Collect Kubernetes information
echo "Collecting Kubernetes information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/kubernetes
kubectl get nodes -o wide > \${DIAG_DIR}/kubernetes/nodes.txt
kubectl get pods -A -o wide > \${DIAG_DIR}/kubernetes/pods.txt
kubectl get services -A > \${DIAG_DIR}/kubernetes/services.txt
kubectl get deployments -A > \${DIAG_DIR}/kubernetes/deployments.txt
kubectl get statefulsets -A > \${DIAG_DIR}/kubernetes/statefulsets.txt
kubectl get pv > \${DIAG_DIR}/kubernetes/pv.txt
kubectl get pvc -A > \${DIAG_DIR}/kubernetes/pvc.txt
kubectl get events -A > \${DIAG_DIR}/kubernetes/events.txt

# Collect Wifano.ai specific information
echo "Collecting Wifano.ai information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano
kubectl get pods -n wifano-system -o wide > \${DIAG_DIR}/wifano/pods.txt
kubectl get services -n wifano-system > \${DIAG_DIR}/wifano/services.txt
kubectl get deployments -n wifano-system > \${DIAG_DIR}/wifano/deployments.txt
kubectl get statefulsets -n wifano-system > \${DIAG_DIR}/wifano/statefulsets.txt
kubectl get configmaps -n wifano-system > \${DIAG_DIR}/wifano/configmaps.txt
kubectl get secrets -n wifano-system > \${DIAG_DIR}/wifano/secrets.txt
kubectl get events -n wifano-system > \${DIAG_DIR}/wifano/events.txt

# Collect logs from Wifano.ai pods
echo "Collecting Wifano.ai logs..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/logs
for pod in \$(kubectl get pods -n wifano-system -o jsonpath='{.items[*].metadata.name}'); do
  kubectl logs \${pod} -n wifano-system > \${DIAG_DIR}/wifano/logs/\${pod}.log 2>> \${LOG_FILE}
done

# Collect Wifano.ai configuration
echo "Collecting Wifano.ai configuration..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/config
for cm in \$(kubectl get configmaps -n wifano-system -o jsonpath='{.items[*].metadata.name}'); do
  kubectl get configmap \${cm} -n wifano-system -o yaml > \${DIAG_DIR}/wifano/config/\${cm}.yaml 2>> \${LOG_FILE}
done

# Run Wifano.ai health checks
echo "Running Wifano.ai health checks..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/health
wifano-cli system health --full > \${DIAG_DIR}/wifano/health/system-health.txt 2>> \${LOG_FILE}
wifano-cli diagnostics --full > \${DIAG_DIR}/wifano/health/diagnostics.txt 2>> \${LOG_FILE}

# Create a tarball of all diagnostic data
echo "Creating diagnostic tarball..." >> \${LOG_FILE}
tar -czf \${DIAG_FILE} -C \${DIAG_DIR} system kubernetes wifano \${LOG_FILE##*/}

# Check if tarball creation was successful
if [ \$? -eq 0 ]; then
  echo "Diagnostics completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Diagnostic file: \${DIAG_FILE}" >> \${LOG_FILE}
  echo "Diagnostic file size: \$(du -h \${DIAG_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Diagnostics tarball creation failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

echo "Diagnostics process completed at \$(date)" >> \${LOG_FILE}
echo "Diagnostic file: \${DIAG_FILE}"
EOF

chmod +x wifano-diagnostics.sh

# Create a ConfigMap for the diagnostic script
kubectl create configmap wifano-diagnostic-scripts \
  --from-file=wifano-diagnostics.sh \
  -n wifano-system

# Create a diagnostic pod template
kubectl apply -f - << EOF
apiVersion: v1
kind: Pod
metadata:
  name: wifano-diagnostics
  namespace: wifano-system
spec:
  containers:
  - name: diagnostics
    image: bitnami/kubectl:latest
    command: ["/scripts/wifano-diagnostics.sh"]
    volumeMounts:
    - name: diagnostic-scripts
      mountPath: /scripts
    - name: diagnostic-output
      mountPath: /tmp/wifano-diagnostics
  volumes:
  - name: diagnostic-scripts
    configMap:
      name: wifano-diagnostic-scripts
      defaultMode: 0755
  - name: diagnostic-output
    emptyDir: {}
  restartPolicy: Never
EOF
```

### Common Issues and Solutions

Here are solutions for common Wifano.ai issues:

```shellscript
# Create a troubleshooting guide
cat <<EOF > wifano-troubleshooting.md
# Wifano.ai Troubleshooting Guide

## API Connection Issues

### Symptom: Unable to connect to Wifano.ai API

**Possible causes and solutions:**

1. **Network connectivity issues**
   ```bash
   # Check if the API service is running
   kubectl get pods -n wifano-system -l app=wifano-api
   
   # Check if the API service is exposed correctly
   kubectl get svc wifano-api -n wifano-system
   
   # Test connectivity from within the cluster
   kubectl run -it --rm debug --image=curlimages/curl -- curl http://wifano-api.wifano-system:8080/health
```

2. **Ingress configuration issues**

```shellscript
# Check ingress configuration
kubectl get ingress -n wifano-system

# Check ingress controller logs
kubectl logs -n ingress-nginx -l app.kubernetes.io/name=ingress-nginx

# Verify TLS certificate
kubectl get secret wifano-tls -n wifano-system -o yaml
```


3. **API service is crashing**

```shellscript
# Check API pod logs
kubectl logs -n wifano-system -l app=wifano-api

# Check for resource constraints
kubectl describe pods -n wifano-system -l app=wifano-api
```




## Reasoning Engine Issues

### Symptom: Slow or failing reasoning responses

**Possible causes and solutions:**

1. **GPU resource constraints**

```shellscript
# Check GPU utilization
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- nvidia-smi

# Check for GPU memory leaks
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- nvidia-smi --query-compute-apps=pid,used_memory --format=csv

# Restart reasoning engine if needed
kubectl rollout restart deployment wifano-reasoning -n wifano-system
```


2. **Model loading issues**

```shellscript
# Check if model files exist
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- ls -la /models

# Verify model checksum
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- sha256sum /models/wifano-reasoning-v3.bin

# Check model loading logs
kubectl logs -n wifano-system -l app=wifano-reasoning | grep "Loading model"
```


3. **Configuration issues**

```shellscript
# Check reasoning engine configuration
kubectl get configmap wifano-config -n wifano-system -o yaml

# Verify environment variables
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- env | grep WIFANO
```




## Knowledge System Issues

### Symptom: Missing or outdated knowledge

**Possible causes and solutions:**

1. **Knowledge database connectivity issues**

```shellscript
# Check database connection
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- pg_isready -h wifano-db -U wifano

# Check vector database status
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- curl -s http://wifano-vector-db:6333/collections/wifano_embeddings
```


2. **Knowledge update failures**

```shellscript
# Check knowledge update logs
kubectl logs -n wifano-system -l app=wifano-knowledge | grep "Updating knowledge"

# Manually trigger knowledge update
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- wifano-cli knowledge update --force
```


3. **Storage issues**

```shellscript
# Check storage usage
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- df -h

# Check PVC status
kubectl get pvc -n wifano-system
kubectl describe pvc wifano-pvc -n wifano-system
```




## Performance Issues

### Symptom: High latency or timeouts

**Possible causes and solutions:**

1. **Resource constraints**

```shellscript
# Check node resource usage
kubectl top nodes

# Check pod resource usage
kubectl top pods -n wifano-system

# Increase resources if needed
kubectl scale deployment wifano-reasoning --replicas=4 -n wifano-system
```


2. **Network bottlenecks**

```shellscript
# Check network policies
kubectl get networkpolicies -n wifano-system

# Test network latency
kubectl run -it --rm netutils --image=nicolaka/netshoot -- ping wifano-api.wifano-system
```


3. **Database performance issues**

```shellscript
# Check database performance
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- psql -U wifano -c "SELECT * FROM pg_stat_activity WHERE state = 'active';"

# Optimize database
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- psql -U wifano -c "VACUUM ANALYZE;"
```




## Security Issues

### Symptom: Authentication or authorization failures

**Possible causes and solutions:**

1. **API key issues**

```shellscript
# Check API key configuration
kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.api-key}' | base64 --decode

# Regenerate API key if needed
NEW_API_KEY=$(openssl rand -hex 32)
kubectl patch secret wifano-secrets -n wifano-system -p="{\"data\":{\"api-key\":\"$(echo -n $NEW_API_KEY | base64)\"}}"
```


2. **TLS certificate issues**

```shellscript
# Check certificate expiration
kubectl get secret wifano-tls -n wifano-system -o jsonpath='{.data.tls\.crt}' | base64 --decode | openssl x509 -noout -dates

# Renew certificate if needed
kubectl delete certificate wifano-tls -n wifano-system
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-tls
  namespace: wifano-system
spec:
  secretName: wifano-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: api.wifano.ai
  dnsNames:
  - api.wifano.ai
  - dashboard.wifano.ai
EOF
```


3. **RBAC issues**

```shellscript
# Check RBAC configuration
kubectl get configmap wifano-auth-config -n wifano-system -o yaml

# Verify service account permissions
kubectl auth can-i --list --as=system:serviceaccount:wifano-system:wifano-sa -n wifano-system
```




## Monitoring and Logging Issues

### Symptom: Missing metrics or logs

**Possible causes and solutions:**

1. **Prometheus configuration issues**

```shellscript
# Check Prometheus targets
kubectl port-forward svc/wifano-monitoring-prometheus -n wifano-monitoring 9090:9090
# Then open http://localhost:9090/targets in your browser

# Check ServiceMonitor configuration
kubectl get servicemonitor -n wifano-monitoring
```


2. **Logging pipeline issues**

```shellscript
# Check Filebeat status
kubectl get pods -n wifano-logging -l app=filebeat
kubectl logs -n wifano-logging -l app=filebeat

# Check Logstash status
kubectl get pods -n wifano-logging -l app=logstash
kubectl logs -n wifano-logging -l app=logstash
```


3. **Storage issues for logs**

```shellscript
# Check Elasticsearch storage
kubectl get pvc -n wifano-logging
kubectl describe pvc elasticsearch-data -n wifano-logging
```




## Backup and Restore Issues

### Symptom: Backup failures or restore errors

**Possible causes and solutions:**

1. **Storage access issues**

```shellscript
# Check backup PVC status
kubectl get pvc wifano-backup-pvc -n wifano-system
kubectl describe pvc wifano-backup-pvc -n wifano-system

# Check backup storage usage
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l job-name=wifano-db-backup -o jsonpath='{.items[0].metadata.name}') -- df -h /backups
```


2. **Backup job failures**

```shellscript
# Check backup job logs
kubectl logs -n wifano-system -l job-name=wifano-db-backup

# Check CronJob status
kubectl get cronjob -n wifano-system
```


3. **Restore process issues**

```shellscript
# Check restore job logs
kubectl logs -n wifano-system -l job-name=wifano-disaster-recovery

# Verify backup files
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-api -o jsonpath='{.items[0].metadata.name}') -- ls -la /backups
```




EOF

# Create a ConfigMap for the troubleshooting guide

kubectl create configmap wifano-troubleshooting-guide --from-file=wifano-troubleshooting.md -n wifano-system

```plaintext

## Advanced Usage Scenarios

This section covers advanced usage scenarios for Wifano.ai.

### Custom Model Integration

Integrate custom models with Wifano.ai:

```bash
# Create a script for custom model integration
cat <<EOF > wifano-custom-model.sh
#!/bin/bash

# Set variables
MODEL_NAME=\$1
MODEL_PATH=\$2
MODEL_CONFIG=\$3

# Validate inputs
if [ -z "\$MODEL_NAME" ] || [ -z "\$MODEL_PATH" ] || [ -z "\$MODEL_CONFIG" ]; then
  echo "Usage: \$0 <model_name> <model_path> <model_config>"
  echo "Example: \$0 custom-model-v1 /models/custom-model-v1 /configs/custom-model-config.json"
  exit 1
fi

# Check if model files exist
if [ ! -f "\$MODEL_PATH" ]; then
  echo "Error: Model file not found at \$MODEL_PATH"
  exit 1
fi

if [ ! -f "\$MODEL_CONFIG" ]; then
  echo "Error: Model configuration file not found at \$MODEL_CONFIG"
  exit 1
fi

# Create a temporary directory for model processing
TEMP_DIR=\$(mktemp -d)
echo "Created temporary directory: \$TEMP_DIR"

# Copy model files to temporary directory
cp "\$MODEL_PATH" "\$TEMP_DIR/model.bin"
cp "\$MODEL_CONFIG" "\$TEMP_DIR/config.json"

# Create model metadata
cat <<EOT > "\$TEMP_DIR/metadata.json"
{
  "name": "\$MODEL_NAME",
  "version": "1.0.0",
  "description": "Custom model for Wifano.ai",
  "created_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "parameters": $(jq '.parameters // 0' "\$MODEL_CONFIG"),
  "architecture": "$(jq -r '.architecture // "custom"' "\$MODEL_CONFIG")",
  "license": "proprietary",
  "sha256": "$(sha256sum "\$MODEL_PATH" | cut -d' ' -f1)"
}
EOT

# Create a Docker image with the custom model
cat <<EOT > "\$TEMP_DIR/Dockerfile"
FROM wifano/reasoning-base:latest

# Copy model files
COPY model.bin /models/\$MODEL_NAME/model.bin
COPY config.json /models/\$MODEL_NAME/config.json
COPY metadata.json /models/\$MODEL_NAME/metadata.json

# Set environment variables
ENV WIFANO_MODEL_PATH=/models/\$MODEL_NAME
ENV WIFANO_MODEL_CONFIG=/models/\$MODEL_NAME/config.json
EOT

# Build the Docker image
echo "Building Docker image for custom model..."
docker build -t wifano/reasoning:\$MODEL_NAME \$TEMP_DIR

# Push the image to the registry
echo "Pushing Docker image to registry..."
docker tag wifano/reasoning:\$MODEL_NAME registry.wifano.ai/wifano/reasoning:\$MODEL_NAME
docker push registry.wifano.ai/wifano/reasoning:\$MODEL_NAME

# Clean up temporary directory
rm -rf \$TEMP_DIR

# Create a deployment for the custom model
kubectl apply -f - << EOT
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wifano-reasoning-\$MODEL_NAME
  namespace: wifano-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wifano-reasoning
      model: \$MODEL_NAME
  template:
    metadata:
      labels:
        app: wifano-reasoning
        model: \$MODEL_NAME
    spec:
      containers:
      - name: reasoning
        image: registry.wifano.ai/wifano/reasoning:\$MODEL_NAME
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "8"
            memory: "32Gi"
            nvidia.com/gpu: "1"
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 120
          periodSeconds: 30
        volumeMounts:
        - name: model-cache
          mountPath: /cache
      volumes:
      - name: model-cache
        emptyDir: {}
EOT

# Create a service for the custom model
kubectl apply -f - << EOT
apiVersion: v1
kind: Service
metadata:
  name: wifano-reasoning-\$MODEL_NAME
  namespace: wifano-system
  labels:
    app: wifano-reasoning
    model: \$MODEL_NAME
spec:
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  - port: 9090
    targetPort: 9090
    name: metrics
  selector:
    app: wifano-reasoning
    model: \$MODEL_NAME
EOT

# Update API configuration to use the custom model
kubectl apply -f - << EOT
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-custom-model-config
  namespace: wifano-system
data:
  custom-models.yaml: |
    models:
      - name: \$MODEL_NAME
        service: wifano-reasoning-\$MODEL_NAME
        port: 8080
        path: /v1/generate
        timeout: 300
        max_tokens: $(jq '.max_tokens // 4096' "\$MODEL_CONFIG")
EOT

# Restart the API to apply the new configuration
kubectl rollout restart deployment wifano-api -n wifano-system

echo "Custom model \$MODEL_NAME has been successfully integrated with Wifano.ai"
echo "You can now use the model by specifying 'model=\$MODEL_NAME' in your API requests"
EOF

chmod +x wifano-custom-model.sh

# Create a ConfigMap for the custom model integration script
kubectl create configmap wifano-custom-model-scripts \
  --from-file=wifano-custom-model.sh \
  -n wifano-system
```

### Advanced Query Techniques

Implement advanced query techniques for Wifano.ai:

```shellscript
# Create a guide for advanced query techniques
cat <<EOF > wifano-advanced-queries.md
# Wifano.ai Advanced Query Techniques

## Query Parameters

Wifano.ai supports a variety of query parameters to customize the behavior of the AI system:

| Parameter | Description | Default | Range |
|-----------|-------------|---------|-------|
| temperature | Controls randomness in generation | 0.7 | 0.0-1.0 |
| top_p | Controls diversity via nucleus sampling | 0.95 | 0.0-1.0 |
| max_tokens | Maximum number of tokens to generate | 1024 | 1-16384 |
| stop | Sequences where the API will stop generating | [] | Array of strings |
| presence_penalty | Penalizes repeated tokens | 0.0 | -2.0-2.0 |
| frequency_penalty | Penalizes frequent tokens | 0.0 | -2.0-2.0 |
| reasoning_depth | Controls depth of reasoning | "standard" | "basic", "standard", "deep" |
| knowledge_recency | Controls recency of knowledge | "balanced" | "recent", "balanced", "comprehensive" |
| tools | List of tools to enable | [] | Array of tool names |

## Example Queries

### Basic Query

```json
{
  "query": "What is the relationship between quantum entanglement and information theory?",
  "max_tokens": 1000,
  "temperature": 0.7
}
```

### Deep Reasoning Query

```json
{
  "query": "Analyze the implications of recent advances in quantum computing for cryptography.",
  "max_tokens": 2000,
  "temperature": 0.3,
  "reasoning_depth": "deep",
  "knowledge_recency": "recent"
}
```

### Tool-Augmented Query

```json
{
  "query": "Analyze this dataset and identify key trends.",
  "max_tokens": 1500,
  "temperature": 0.2,
  "tools": ["data-analyzer", "chart-generator"],
  "tool_inputs": {
    "data-analyzer": {
      "data_url": "https://example.com/dataset.csv",
      "analysis_type": "time_series"
    }
  }
}
```

### Multi-Step Reasoning Query

```json
{
  "query": "Design a research methodology to study the effects of climate change on marine ecosystems.",
  "max_tokens": 3000,
  "temperature": 0.4,
  "reasoning_steps": [
    "problem_definition",
    "literature_review",
    "methodology_design",
    "analysis_plan",
    "limitations"
  ]
}
```

### Knowledge-Intensive Query

```json
{
  "query": "Compare and contrast the latest treatment approaches for Alzheimer's disease.",
  "max_tokens": 2500,
  "temperature": 0.5,
  "knowledge_recency": "recent",
  "knowledge_sources": ["pubmed", "clinical_trials", "research_papers"],
  "min_citation_count": 10
}
```

## Advanced Techniques

### Chain of Thought Prompting

To encourage step-by-step reasoning, structure your query like this:

```json
{
  "query": "Let's solve this step by step: What would be the economic impact of a 2°C global temperature increase by 2050?",
  "max_tokens": 2000,
  "temperature": 0.3
}
```

### Tool Chaining

To use multiple tools in sequence:

```json
{
  "query": "Analyze this genomic sequence and identify potential therapeutic targets.",
  "max_tokens": 2000,
  "tools": ["sequence-analyzer", "protein-structure-predictor", "drug-target-finder"],
  "tool_chain": true,
  "tool_inputs": {
    "sequence-analyzer": {
      "sequence": "ATGCGATCGATCGATCGATCG..."
    }
  }
}
```

### Knowledge Graph Queries

To explicitly query the knowledge graph:

```json
{
  "query": "What are the connections between inflammation, gut microbiome, and autoimmune diseases?",
  "max_tokens": 2000,
  "knowledge_graph_query": true,
  "graph_depth": 3,
  "min_relationship_strength": 0.7
}
```

### Hybrid Queries

To combine different reasoning modes:

```json
{
  "query": "Develop a comprehensive climate action plan for a coastal city.",
  "max_tokens": 5000,
  "reasoning_modes": [
    {"mode": "analytical", "weight": 0.4},
    {"mode": "creative", "weight": 0.3},
    {"mode": "practical", "weight": 0.3}
  ]
}
```

## API Examples

### Python Example

```python
import requests
import json

API_KEY = "your_api_key"
API_URL = "https://api.wifano.ai/v1/query"

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

payload = {
    "query": "What are the latest advances in fusion energy research?",
    "max_tokens": 2000,
    "temperature": 0.5,
    "knowledge_recency": "recent"
}

response = requests.post(API_URL, headers=headers, data=json.dumps(payload))
result = response.json()

print(result["content"])
```

### cURL Example

```shellscript
curl -X POST https://api.wifano.ai/v1/query \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer your_api_key" \\
  -d '{
    "query": "What are the latest advances in fusion energy research?",
    "max_tokens": 2000,
    "temperature": 0.5,
    "knowledge_recency": "recent"
  }'
```

### JavaScript Example

```javascript
const fetch = require('node-fetch');

const API_KEY = 'your_api_key';
const API_URL = 'https://api.wifano.ai/v1/query';

const payload = {
  query: 'What are the latest advances in fusion energy research?',
  max_tokens: 2000,
  temperature: 0.5,
  knowledge_recency: 'recent'
};

fetch(API_URL, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${API_KEY}`
  },
  body: JSON.stringify(payload)
})
.then(response => response.json())
.then(data => console.log(data.content))
.catch(error => console.error('Error:', error));
```

EOF

# Create a ConfigMap for the advanced query techniques guide

kubectl create configmap wifano-advanced-queries --from-file=wifano-advanced-queries.md -n wifano-system

```plaintext

## Integration with External Systems

This section covers integration of Wifano.ai with external systems.

### API Integration

Set up API integration for Wifano.ai:

```bash
# Create an API integration guide
cat <<EOF > wifano-api-integration.md
# Wifano.ai API Integration Guide

## API Overview

Wifano.ai provides a comprehensive REST API for integration with external systems. The API follows OpenAPI 3.0 standards and supports both synchronous and asynchronous operations.

## Authentication

All API requests require authentication using an API key. The API key should be included in the Authorization header:

```

Authorization: Bearer your_api_key

```plaintext

API keys can be generated and managed through the Wifano.ai dashboard or using the CLI:

```bash
# Generate a new API key
wifano-cli auth create-key --name "integration-key" --role "api-user"

# List existing API keys
wifano-cli auth list-keys

# Revoke an API key
wifano-cli auth revoke-key KEY_ID
```

## Rate Limiting

The API enforces rate limits to ensure fair usage. The default limits are:

- 100 requests per minute per API key
- 10,000 requests per day per API key


Rate limit information is included in the response headers:

- X-RateLimit-Limit: The maximum number of requests allowed in the current time window
- X-RateLimit-Remaining: The number of requests remaining in the current time window
- X-RateLimit-Reset: The time when the current rate limit window resets (Unix timestamp)


## API Endpoints

### Query Endpoint

The primary endpoint for interacting with Wifano.ai is the query endpoint:

```plaintext
POST /v1/query
```

Example request:

```json
{
  "query": "What is the relationship between quantum entanglement and information theory?",
  "max_tokens": 1000,
  "temperature": 0.7
}
```

Example response:

```json
{
  "id": "query_123456789",
  "created": 1625097600,
  "content": "Quantum entanglement and information theory are deeply connected...",
  "tokens": 750,
  "model": "wifano-reasoning-v3",
  "sources": [
    {
      "title": "Quantum Information Theory",
      "url": "https://example.com/quantum-info",
      "year": 2022
    }
  ]
}
```

### Asynchronous Query Endpoint

For long-running queries, use the asynchronous endpoint:

```plaintext
POST /v1/query/async
```

Example request (same as synchronous query).

Example response:

```json
{
  "id": "async_query_123456789",
  "status": "processing",
  "created": 1625097600,
  "estimated_completion": 1625097660
}
```

To check the status of an asynchronous query:

```plaintext
GET /v1/query/async/{id}
```

### Knowledge Endpoints

To search the knowledge base:

```plaintext
GET /v1/knowledge/search?q=quantum+computing
```

To add custom knowledge:

```plaintext
POST /v1/knowledge/add
```

Example request:

```json
{
  "content": "New research on quantum computing shows...",
  "metadata": {
    "title": "Advances in Quantum Computing",
    "author": "Jane Smith",
    "year": 2023,
    "source": "Journal of Quantum Information"
  }
}
```

### Tool Endpoints

To list available tools:

```plaintext
GET /v1/tools
```

To execute a specific tool:

```plaintext
POST /v1/tools/{tool_name}/execute
```

Example request:

```json
{
  "input": {
    "data_url": "https://example.com/dataset.csv",
    "analysis_type": "time_series"
  }
}
```

## Webhook Integration

Wifano.ai supports webhooks for event-driven integration:

```plaintext
POST /v1/webhooks
```

Example request:

```json
{
  "url": "https://your-server.com/webhook",
  "events": ["query.completed", "knowledge.updated"],
  "secret": "your_webhook_secret"
}
```

Webhook payloads are signed using HMAC-SHA256 with your webhook secret. The signature is included in the X-Wifano-Signature header.

## Error Handling

The API uses standard HTTP status codes and returns detailed error information:

```json
{
  "error": {
    "code": "invalid_request",
    "message": "The request was invalid",
    "details": "The 'query' field is required"
  }
}
```

Common error codes:

- invalid_request: The request was malformed
- authentication_error: Authentication failed
- authorization_error: The API key doesn't have permission
- rate_limit_exceeded: Rate limit exceeded
- internal_error: An internal server error occurred


## SDKs and Client Libraries

Wifano.ai provides official client libraries for several programming languages:

- Python: pip install wifano-client
- JavaScript: npm install wifano-client
- Java: maven dependency org.wifano:wifano-client:1.0.0
- Go: go get github.com/wifano/wifano-client-go


## Example Integrations

### Integration with Slack

```python
import os
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
from wifano.client import WifanoClient

# Initialize Slack app
app = App(token=os.environ["SLACK_BOT_TOKEN"])

# Initialize Wifano client
wifano_client = WifanoClient(api_key=os.environ["WIFANO_API_KEY"])

# Handle mentions
@app.event("app_mention")
def handle_mention(event, say):
    query = event["text"].split(">")[1].strip()
    
    # Call Wifano API
    response = wifano_client.query(query=query, max_tokens=1000)
    
    # Reply in thread
    say(text=response.content, thread_ts=event["ts"])

# Start the app
if __name__ == "__main__":
    SocketModeHandler(app, os.environ["SLACK_APP_TOKEN"]).start()
```

### Integration with Microsoft Teams

```javascript
const restify = require('restify');
const { TeamsActivityHandler, TurnContext, CardFactory } = require('botbuilder');
const { WifanoClient } = require('wifano-client');

// Initialize Wifano client
const wifanoClient = new WifanoClient({ apiKey: process.env.WIFANO_API_KEY });

class WifanoBot extends TeamsActivityHandler {
    async onMessage(context, next) {
        const query = context.activity.text;
        
        // Call Wifano API
        const response = await wifanoClient.query({
            query,
            max_tokens: 1000
        });
        
        // Reply with the response
        await context.sendActivity(response.content);
        
        await next();
    }
}

// Create HTTP server
const server = restify.createServer();
server.listen(process.env.port || process.env.PORT || 3978, () => {
    console.log(`\n${server.name} listening to ${server.url}`);
});

// Initialize bot
const bot = new WifanoBot();
server.post('/api/messages', (req, res) => {
    adapter.processActivity(req, res, async (context) => {
        await botYou're right - my previous response only addressed the specific Helm and Kubernetes configuration snippets you shared, but doesn't fulfill your request for a comprehensive 10,000-word guide on Wifano.ai from a Linux expert's perspective.

I'll create a more complete guide following your table of contents. Here's "The Definitive Linux Guide to Wifano.ai: From Installation to Production Mastery":

# The Definitive Linux Guide to Wifano.ai: From Installation to Production Mastery

## Introduction to Wifano.ai

Wifano.ai represents a paradigm shift in artificial intelligence deployment for enterprise environments. As a distributed, knowledge-intensive AI system designed for PhD-level reasoning capabilities, Wifano.ai demands a robust Linux infrastructure to deliver its full potential. This guide approaches Wifano.ai from the perspective of a Linux administrator, providing comprehensive instructions for deploying, configuring, optimizing, and maintaining this sophisticated AI platform.

Wifano.ai combines several cutting-edge technologies: large language models, knowledge retrieval systems, specialized reasoning modules, and tool integration frameworks. The system is designed to operate across distributed computing environments, leveraging Kubernetes for orchestration, specialized GPU resources for inference, and a sophisticated data management layer for knowledge storage and retrieval.

As Linux administrators, our role in deploying Wifano.ai extends beyond simple installation. We must architect a system that ensures performance, security, reliability, and scalability. This guide will walk you through every aspect of Wifano.ai administration, from initial setup to advanced production configurations.

## System Architecture

Wifano.ai employs a microservices architecture consisting of several key components:

1. **Reasoning Engine**: The core AI system responsible for processing queries and generating responses. This component requires significant GPU resources and is typically deployed across multiple nodes for load balancing.

2. **Knowledge System**: A distributed database architecture that stores and indexes the vast knowledge required for PhD-level reasoning. This includes vector databases, knowledge graphs, and traditional relational databases.

3. **Tool Framework**: A service that allows Wifano.ai to interact with external systems, execute code, and perform specialized tasks.

4. **Orchestration Layer**: Manages the coordination between different components, handles request routing, and manages system resources.

5. **API Gateway**: Provides a unified interface for client applications to interact with Wifano.ai services.

From a Linux infrastructure perspective, Wifano.ai typically runs on a Kubernetes cluster with the following characteristics:

```

+-------------------+
|   Load Balancer   |
+--------+----------+
|
+-----------------------------+-----------------------------+
|                            |                             |
+-----------v-----------+   +-----------v-----------+   +-------------v-----------+
|  API Gateway Nodes    |   |  API Gateway Nodes    |   |  API Gateway Nodes      |
| (Ubuntu 22.04 LTS)    |   | (Ubuntu 22.04 LTS)    |   | (Ubuntu 22.04 LTS)      |
+-----------+-----------+   +-----------+-----------+   +-------------+-----------+
|                            |                             |
+-----------------------------+-----------------------------+
|
+--------v----------+
| Kubernetes Master |
| (Control Plane)   |
+--------+----------+
|
+-------------------------------+--+--+-------------------------------+
|                              |     |                               |
+-------v------+              +--------v-----+--+                  +--------v---------+
| Worker Nodes |              | Worker Nodes    |                  | Worker Nodes     |
| (CPU-focused)|              | (GPU-equipped)  |                  | (Storage-focused)|
| - Orchestrator|              | - Reasoning Engine|                  | - Knowledge System |
| - API Services|              | - Inference     |                  | - Databases      |
+-------+------+              +--------+--------+                  +--------+---------+
|                              |                                    |
+------------------------------+------------------------------------+
|
+-----------v------------+
|  Persistent Storage    |
|  - NFS/Ceph/GlusterFS  |
+-----------------------+

```plaintext

This distributed architecture allows Wifano.ai to scale horizontally, with different components scaled independently based on demand. The system typically requires:

- High-performance GPU nodes (NVIDIA A100 or equivalent) for the reasoning engine
- Memory-optimized nodes for the knowledge system
- General-purpose nodes for the orchestration layer and API gateway
- Distributed storage solution for persistent data

## Prerequisites and Environment Setup

Before installing Wifano.ai, ensure your Linux environment meets the following requirements:

### Hardware Requirements

For a production deployment of Wifano.ai, you'll need:

- **Minimum of 5 nodes**: 3 for control plane (master) and 2+ worker nodes
- **GPU nodes**: At least 2 nodes with NVIDIA A100 (or equivalent) GPUs, 8 GPUs per node recommended
- **CPU nodes**: 32+ cores per node, preferably AMD EPYC or Intel Xeon Platinum
- **Memory**: 512GB+ RAM per GPU node, 256GB+ per CPU node
- **Storage**: 2TB+ NVMe storage per node for local caching
- **Network**: 100Gbps interconnect (Infiniband or equivalent)
- **Persistent Storage**: 20TB+ distributed storage system (Ceph recommended)

### Software Prerequisites

Wifano.ai runs on modern Linux distributions with the following components:

```bash
# Check Linux distribution (Ubuntu 22.04 LTS recommended)
lsb_release -a

# Ensure system is up to date
sudo apt update && sudo apt upgrade -y

# Install required packages
sudo apt install -y apt-transport-https ca-certificates curl software-properties-common gnupg lsb-release

# Install Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io
sudo systemctl enable docker
sudo systemctl start docker

# Add current user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Install NVIDIA drivers and CUDA
sudo apt install -y linux-headers-$(uname -r)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID | sed -e 's/\.//g')
wget https://developer.download.nvidia.com/compute/cuda/repos/$distribution/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt update
sudo apt install -y cuda-drivers cuda

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID | sed -e 's/\.//g')
curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo systemctl restart docker

# Install Kubernetes components
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

# Disable swap (required for Kubernetes)
sudo swapoff -a
sudo sed -i '/ swap / s/^$$.*$$$/#\1/g' /etc/fstab

# Configure system settings for Kubernetes
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF
sudo sysctl --system

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
```

### Network Configuration

Wifano.ai requires specific network configurations for optimal performance:

```shellscript
# Configure firewall to allow Kubernetes and Wifano.ai traffic
sudo ufw allow 6443/tcp  # Kubernetes API server
sudo ufw allow 2379:2380/tcp  # etcd server client API
sudo ufw allow 10250/tcp  # Kubelet API
sudo ufw allow 10251/tcp  # kube-scheduler
sudo ufw allow 10252/tcp  # kube-controller-manager
sudo ufw allow 10255/tcp  # Read-only Kubelet API
sudo ufw allow 8080/tcp   # Wifano.ai API
sudo ufw allow 9090/tcp   # Prometheus
sudo ufw allow 3000/tcp   # Grafana
sudo ufw allow 9100/tcp   # Node exporter

# Enable IP forwarding
echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# Configure DNS for Wifano.ai services
sudo tee -a /etc/hosts <<EOF
127.0.0.1 wifano-api.local
127.0.0.1 wifano-dashboard.local
127.0.0.1 wifano-monitoring.local
EOF
```

### Environment Variables

Set up the environment variables required for Wifano.ai:

```shellscript
# Create environment file
cat <<EOF > ~/.wifano-env
# Wifano.ai Configuration
export WIFANO_HOME=/opt/wifano
export WIFANO_DATA=/data/wifano
export WIFANO_LOGS=/var/log/wifano
export WIFANO_CONFIG=/etc/wifano
export WIFANO_VERSION=3.2.1
export WIFANO_API_PORT=8080
export WIFANO_MONITORING_PORT=9090
export WIFANO_DASHBOARD_PORT=3000

# Kubernetes Configuration
export KUBECONFIG=/etc/kubernetes/admin.conf

# GPU Configuration
export NVIDIA_VISIBLE_DEVICES=all
export NVIDIA_DRIVER_CAPABILITIES=compute,utility
EOF

# Add to .bashrc
echo "source ~/.wifano-env" >> ~/.bashrc
source ~/.wifano-env

# Create required directories
sudo mkdir -p $WIFANO_HOME $WIFANO_DATA $WIFANO_LOGS $WIFANO_CONFIG
sudo chown -R $(id -u):$(id -g) $WIFANO_HOME $WIFANO_DATA $WIFANO_LOGS $WIFANO_CONFIG
```

## Installation Process

With the prerequisites in place, we can now proceed with the installation of Wifano.ai. The installation process involves several steps:

### 1. Initialize Kubernetes Cluster

First, we need to set up the Kubernetes cluster that will host Wifano.ai:

```shellscript
# Initialize the control plane
sudo kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint="control-plane.wifano.local:6443" --upload-certs

# Set up kubeconfig for the current user
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Install Calico network plugin
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# Verify the cluster is running
kubectl get nodes
```

### 2. Configure GPU Support in Kubernetes

Next, we need to enable GPU support in the Kubernetes cluster:

```shellscript
# Install NVIDIA device plugin for Kubernetes
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.12.2/nvidia-device-plugin.yml

# Verify GPU support
kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
```

### 3. Set Up Helm for Wifano.ai

Helm is used to manage Wifano.ai deployments:

```shellscript
# Download and install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Add the Wifano Helm repository (this is a fictional URL)
helm repo add wifano https://charts.wifano.ai
helm repo update

# Verify the repository was added
helm repo list
```

### 4. Set Up Persistent Storage

Configure storage classes for Kubernetes:

```shellscript
# Create a storage class for Wifano
kubectl apply -f - << EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: wifano-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: wifano-pv
spec:
  capacity:
    storage: 1000Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: wifano-storage
  local:
    path: /data/wifano
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - wifano-storage-node
EOF

# Create a PersistentVolumeClaim for Wifano
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-pvc
  namespace: wifano-system
spec:
  storageClassName: wifano-storage
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
EOF
```

### 5. Install Wifano.ai Core Components

Now we can install the core Wifano.ai components:

```shellscript
# Create namespace for Wifano.ai
kubectl create namespace wifano-system

# Create secrets for Wifano.ai
kubectl create secret generic wifano-secrets \
  --namespace wifano-system \
  --from-literal=db-password=$(openssl rand -hex 16) \
  --from-literal=api-key=$(openssl rand -hex 32) \
  --from-literal=encryption-key=$(openssl rand -hex 32)

# Install Wifano.ai using Helm
helm install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai

# Verify the installation
kubectl get pods -n wifano-system
helm status wifano -n wifano-system
```

### 6. Install Wifano.ai CLI

The Wifano.ai CLI is a powerful tool for managing the system:

```shellscript
# Download the Wifano.ai CLI
curl -Lo wifano-cli https://downloads.wifano.ai/cli/wifano-cli-linux-amd64-${WIFANO_VERSION}
chmod +x wifano-cli
sudo mv wifano-cli /usr/local/bin/

# Configure the CLI
wifano-cli config set-context wifano-prod \
  --server=https://api.wifano.ai \
  --api-key=$(kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.api-key}' | base64 --decode)

# Verify the CLI is working
wifano-cli version
wifano-cli status
```

### 7. Install Monitoring Stack

Set up monitoring for Wifano.ai:

```shellscript
# Install Prometheus and Grafana for monitoring
helm install wifano-monitoring wifano/wifano-monitoring \
  --namespace wifano-monitoring \
  --create-namespace \
  --set grafana.adminPassword=$(openssl rand -hex 8) \
  --set prometheus.retention=15d \
  --set alertmanager.enabled=true

# Verify monitoring installation
kubectl get pods -n wifano-monitoring
```

## Core Configuration

After installation, Wifano.ai requires proper configuration to function optimally. This section covers the essential configuration steps.

### System Configuration

First, let's configure the core system parameters:

```shellscript
# Create ConfigMap for Wifano.ai configuration
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-config
  namespace: wifano-system
data:
  wifano.yaml: |
    system:
      log_level: INFO
      max_concurrent_requests: 100
      request_timeout: 300
      health_check_interval: 60
    
    reasoning_engine:
      model_path: /models/wifano-reasoning-v3
      max_tokens: 16384
      temperature: 0.7
      top_p: 0.95
      cache_size: 8192
      batch_size: 4
    
    knowledge_system:
      vector_db_uri: http://wifano-vector-db:6333
      knowledge_graph_uri: http://wifano-knowledge-graph:8182
      update_interval: 86400
      cache_ttl: 3600
      max_results: 50
    
    tool_framework:
      max_tools_per_request: 10
      tool_execution_timeout: 60
      allowed_domains:
        - wifano.ai
        - github.com
        - gitlab.com
      blocked_commands:
        - rm -rf
        - shutdown
        - reboot
    
    api_gateway:
      rate_limit: 100
      token_expiration: 86400
      cors_allowed_origins:
        - https://dashboard.wifano.ai
        - https://api.wifano.ai
EOF

# Apply the configuration
kubectl rollout restart deployment -n wifano-system
```

### Database Configuration

Configure the database settings for optimal performance:

```shellscript
# Connect to the Wifano database pod
WIFANO_DB_POD=$(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $WIFANO_DB_POD -n wifano-system -- bash

# Configure PostgreSQL for Wifano.ai
cat <<EOF > /var/lib/postgresql/data/postgresql.conf.d/wifano-optimizations.conf
# Memory Configuration
shared_buffers = 8GB
effective_cache_size = 24GB
work_mem = 128MB
maintenance_work_mem = 2GB

# Checkpoint Configuration
checkpoint_completion_target = 0.9
max_wal_size = 4GB
min_wal_size = 1GB

# Query Optimization
random_page_cost = 1.1
effective_io_concurrency = 200

# Parallel Query
max_parallel_workers_per_gather = 4
max_parallel_workers = 8
max_parallel_maintenance_workers = 4

# Logging
log_min_duration_statement = 1000
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
log_temp_files = 0
EOF

# Restart PostgreSQL to apply changes
exit
kubectl rollout restart statefulset wifano-db -n wifano-system
```

### Vector Database Configuration

Configure the vector database for knowledge retrieval:

```shellscript
# Connect to the vector database pod
WIFANO_VECTOR_POD=$(kubectl get pods -n wifano-system -l app=wifano-vector-db -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $WIFANO_VECTOR_POD -n wifano-system -- bash

# Configure Milvus/Qdrant (example for Qdrant)
cat <<EOF > /qdrant/config/config.yaml
log_level: INFO

storage:
  # Storage persistence path
  storage_path: /qdrant/storage
  
  # Size of RAM allocated for MMAP
  # Default: 50% of available RAM
  mmap_size_mb: 32768
  
  # Number of parallel threads for data indexing
  # Default: number of available CPU cores
  indexing_threads: 8
  
  # Optimization options
  optimization:
    # Interval between optimizations in seconds
    interval_sec: 3600
    # Number of segments to optimize per iteration
    segments_per_iteration: 10

service:
  # Host to bind the service on
  host: 0.0.0.0
  # HTTP port to bind the service on
  http_port: 6333
  # gRPC port to bind the service on
  grpc_port: 6334

cluster:
  # Enable cluster mode
  enabled: true
  # This node address in format: http://localhost:6335
  p2p:
    port: 6335
EOF

# Restart the vector database
exit
kubectl rollout restart statefulset wifano-vector-db -n wifano-system
```

### GPU Configuration

Optimize GPU settings for the reasoning engine:

```shellscript
# Create a ConfigMap for GPU optimization
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-gpu-config
  namespace: wifano-system
data:
  gpu-optimization.sh: |
    #!/bin/bash
    # Set GPU clock speeds to maximum (requires nvidia-smi with root privileges)
    nvidia-smi -pm 1
    nvidia-smi --auto-boost-default=0
    nvidia-smi -ac 5001,1590
    
    # Configure CUDA for optimal performance
    export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
    export CUDA_CACHE_PATH=/tmp/cuda-cache
    export CUDA_AUTO_BOOST=0
    export CUDA_DEVICE_MAX_CONNECTIONS=32
    
    # TensorRT optimization settings
    export TRT_MAX_WORKSPACE_SIZE=8589934592
    export TRT_FP16_ENABLE=1
    
    # PyTorch settings
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    export TORCH_CUDNN_V8_API_ENABLED=1
    export TORCH_USE_CUDA_DSA=1
EOF

# Update the Wifano reasoning deployment to use the GPU configuration
kubectl patch deployment wifano-reasoning -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/initContainers", 
    "value": [{
      "name": "gpu-init",
      "image": "nvidia/cuda:11.8.0-base-ubuntu22.04",
      "command": ["/bin/bash", "-c"],
      "args": ["cp /configmap/gpu-optimization.sh /shared && chmod +x /shared/gpu-optimization.sh"],
      "volumeMounts": [
        {"name": "gpu-config", "mountPath": "/configmap"},
        {"name": "shared-scripts", "mountPath": "/shared"}
      ]
    }]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {"name": "shared-scripts", "mountPath": "/scripts"}
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/command",
    "value": ["/bin/bash", "-c"]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/args",
    "value": ["source /scripts/gpu-optimization.sh && exec /wifano/start.sh"]
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "gpu-config", "configMap": {"name": "wifano-gpu-config"}}
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "shared-scripts", "emptyDir": {}}
  }
]'
```

## Deployment Strategies

Deploying Wifano.ai in production requires careful planning. This section covers different deployment strategies.

### Blue-Green Deployment

Blue-green deployment allows for zero-downtime updates:

```shellscript
# Create a new "green" deployment
helm upgrade --install wifano-green wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=false \
  --set version=${WIFANO_VERSION}

# Wait for the green deployment to be ready
kubectl rollout status deployment wifano-green-reasoning -n wifano-system
kubectl rollout status deployment wifano-green-api -n wifano-system

# Test the green deployment
GREEN_API_POD=$(kubectl get pods -n wifano-system -l app=wifano-green-api -o jsonpath='{.items[0].metadata.name}')
kubectl port-forward $GREEN_API_POD 8081:8080 -n wifano-system &
curl -s http://localhost:8081/health | jq

# Switch traffic to the green deployment
kubectl patch service wifano-api -n wifano-system --type=json -p='[
  {
    "op": "replace", 
    "path": "/spec/selector/app", 
    "value": "wifano-green-api"
  }
]'

# Verify the switch
kubectl get endpoints wifano-api -n wifano-system

# If everything is working, remove the old "blue" deployment
helm uninstall wifano -n wifano-system

# Rename the green deployment to be the main deployment
helm upgrade --install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai \
  --set version=${WIFANO_VERSION}

# Clean up the green deployment
helm uninstall wifano-green -n wifano-system
```

### Canary Deployment

Canary deployment allows for gradual rollout of new versions:

```shellscript
# Deploy a canary version (10% of traffic)
helm upgrade --install wifano-canary wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=false \
  --set version=${WIFANO_VERSION}-canary

# Create a canary service
kubectl apply -f - << EOF
apiVersion: v1
kind: Service
metadata:
  name: wifano-api-canary
  namespace: wifano-system
spec:
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: wifano-canary-api
EOF

# Set up Istio for traffic splitting (requires Istio to be installed)
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api
        port:
          number: 8080
      weight: 90
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 10
EOF

# Monitor the canary deployment
kubectl logs -f -l app=wifano-canary-api -n wifano-system

# If the canary is stable, gradually increase its traffic
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api
        port:
          number: 8080
      weight: 50
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 50
EOF

# Eventually, promote the canary to be the main deployment
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: wifano-api-vs
  namespace: wifano-system
spec:
  hosts:
  - api.wifano.ai
  gateways:
  - wifano-gateway
  http:
  - route:
    - destination:
        host: wifano-api-canary
        port:
          number: 8080
      weight: 100
EOF

# Update the main deployment to match the canary
helm upgrade --install wifano wifano/wifano-core \
  --namespace wifano-system \
  --set persistence.enabled=true \
  --set persistence.existingClaim=wifano-pvc \
  --set resources.requests.memory=16Gi \
  --set resources.requests.cpu=4 \
  --set resources.limits.memory=32Gi \
  --set resources.limits.cpu=8 \
  --set gpu.enabled=true \
  --set gpu.count=2 \
  --set ingress.enabled=true \
  --set ingress.host=api.wifano.ai \
  --set version=${WIFANO_VERSION}

# Clean up the canary deployment
helm uninstall wifano-canary -n wifano-system
kubectl delete service wifano-api-canary -n wifano-system
```

## Performance Optimization

Optimizing Wifano.ai for maximum performance is critical for production deployments. This section covers various optimization techniques.

### Linux Kernel Tuning

Optimize the Linux kernel parameters for AI workloads:

```shellscript
# Create a sysctl configuration file for Wifano.ai
cat <<EOF | sudo tee /etc/sysctl.d/99-wifano.conf
# Virtual Memory Settings
vm.swappiness = 10
vm.dirty_ratio = 80
vm.dirty_background_ratio = 5
vm.max_map_count = 1048576

# Network Settings
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 250000
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_max_syn_backlog = 65536
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_tw_reuse = 1
net.ipv4.ip_local_port_range = 1024 65535

# File System Settings
fs.file-max = 2097152
fs.nr_open = 2097152
fs.inotify.max_user_watches = 524288
EOF

# Apply the settings
sudo sysctl --system

# Verify the changes
sudo sysctl -a | grep -E 'vm.swappiness|vm.dirty_ratio|vm.max_map_count|net.core.somaxconn'

# Configure user limits for Wifano.ai services
cat <<EOF | sudo tee /etc/security/limits.d/wifano.conf
# Wifano.ai service user limits
wifano soft nofile 1048576
wifano hard nofile 1048576
wifano soft nproc 65535
wifano hard nproc 65535
wifano soft memlock unlimited
wifano hard memlock unlimited
EOF

# Apply the limits to current session
ulimit -n 1048576
ulimit -u 65535
```

### GPU Optimization

Optimize GPU performance for Wifano.ai:

```shellscript
# Create a script for GPU optimization
cat <<EOF > ~/gpu-optimize.sh
#!/bin/bash

# Set GPU power limits to maximum
sudo nvidia-smi -pl 300

# Set GPU persistence mode
sudo nvidia-smi -pm 1

# Disable GPU autoboost
sudo nvidia-smi --auto-boost-default=0

# Set GPU clock speeds to maximum
sudo nvidia-smi -ac 5001,1590

# Configure GPU compute mode to exclusive process
sudo nvidia-smi -c 3

# Verify settings
echo "GPU Settings:"
nvidia-smi --query-gpu=name,pstate,memory.total,power.limit --format=csv
EOF

chmod +x ~/gpu-optimize.sh
sudo ~/gpu-optimize.sh

# Create a systemd service to apply settings on boot
cat <<EOF | sudo tee /etc/systemd/system/wifano-gpu-optimize.service
[Unit]
Description=Optimize GPUs for Wifano.ai
After=nvidia-persistenced.service

[Service]
Type=oneshot
ExecStart=/home/$(whoami)/gpu-optimize.sh
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable wifano-gpu-optimize.service
sudo systemctl start wifano-gpu-optimize.service
```

### Memory Optimization

Optimize memory usage for Wifano.ai:

```shellscript
# Install and configure Transparent Huge Pages for better memory performance
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/defrag

# Create a systemd service to disable THP on boot
cat <<EOF | sudo tee /etc/systemd/system/disable-thp.service
[Unit]
Description=Disable Transparent Huge Pages (THP)
After=network.target

[Service]
Type=oneshot
ExecStart=/bin/sh -c "echo never > /sys/kernel/mm/transparent_hugepage/enabled && echo never > /sys/kernel/mm/transparent_hugepage/defrag"
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable disable-thp.service
sudo systemctl start disable-thp.service

# Configure NUMA settings for optimal memory access
cat <<EOF | sudo tee /etc/systemd/system/wifano-numa.service
[Unit]
Description=Configure NUMA for Wifano.ai
After=network.target

[Service]
Type=oneshot
ExecStart=/bin/sh -c "numactl --hardware && echo 0 | sudo tee /proc/sys/kernel/numa_balancing"
RemainAfterExit=true

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl enable wifano-numa.service
sudo systemctl start wifano-numa.service
```

### Network Optimization

Optimize network performance for Wifano.ai:

```shellscript
# Install and configure network performance tools
sudo apt install -y ethtool tuned

# Configure network interface for jumbo frames and optimize settings
INTERFACE=$(ip route | grep default | awk '{print $5}')
sudo ethtool -G $INTERFACE rx 4096 tx 4096
sudo ethtool -K $INTERFACE tso on gso on gro on lro on

# Set up tuned profile for network-latency
sudo tuned-adm profile network-latency

# Configure irqbalance for better network performance
cat <<EOF | sudo tee /etc/default/irqbalance
ENABLED="1"
ONESHOT="0"
OPTIONS="--hintpolicy=prefer"
EOF

sudo systemctl restart irqbalance

# Configure network settings for Kubernetes pods
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-network-config
  namespace: wifano-system
data:
  network-optimize.sh: |
    #!/bin/bash
    # Optimize network settings within container
    sysctl -w net.core.somaxconn=65535
    sysctl -w net.ipv4.tcp_max_syn_backlog=65536
    sysctl -w net.ipv4.tcp_slow_start_after_idle=0
    sysctl -w net.ipv4.tcp_keepalive_time=600
    sysctl -w net.ipv4.tcp_keepalive_intvl=60
    sysctl -w net.ipv4.tcp_keepalive_probes=10
EOF

# Update Wifano deployments to use network optimization
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/initContainers/-", 
    "value": {
      "name": "network-init",
      "image": "alpine:3.16",
      "command": ["/bin/sh", "-c"],
      "args": ["cp /configmap/network-optimize.sh /shared && chmod +x /shared/network-optimize.sh"],
      "volumeMounts": [
        {"name": "network-config", "mountPath": "/configmap"},
        {"name": "shared-scripts", "mountPath": "/shared"}
      ],
      "securityContext": {
        "privileged": true
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/volumes/-",
    "value": {"name": "network-config", "configMap": {"name": "wifano-network-config"}}
  }
]'
```

## Monitoring and Logging

Comprehensive monitoring and logging are essential for maintaining Wifano.ai in production.

### Prometheus and Grafana Setup

Set up advanced monitoring for Wifano.ai:

```shellscript
# Create a values file for the monitoring stack
cat <<EOF > wifano-monitoring-values.yaml
prometheus:
  prometheusSpec:
    retention: 15d
    resources:
      requests:
        memory: 2Gi
        cpu: 500m
      limits:
        memory: 4Gi
        cpu: 1000m
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: wifano-storage
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    additionalScrapeConfigs:
      - job_name: 'wifano-metrics'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - wifano-system
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            regex: wifano-.*
            action: keep
          - source_labels: [__meta_kubernetes_pod_container_port_name]
            regex: metrics
            action: keep

grafana:
  adminPassword: "wifano-admin"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 10Gi
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'wifano'
          orgId: 1
          folder: 'Wifano'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/wifano
  dashboards:
    wifano:
      wifano-system-dashboard:
        json: |
          {
            "annotations": {
              "list": [
                {
                  "builtIn": 1,
                  "datasource": "-- Grafana --",
                  "enable": true,
                  "hide": true,
                  "iconColor": "rgba(0, 211, 255, 1)",
                  "name": "Annotations & Alerts",
                  "type": "dashboard"
                }
              ]
            },
            "editable": true,
            "gnetId": null,
            "graphTooltip": 0,
            "id": 1,
            "links": [],
            "panels": [
              {
                "aliasColors": {},
                "bars": false,
                "dashLength": 10,
                "dashes": false,
                "datasource": "Prometheus",
                "fieldConfig": {
                  "defaults": {
                    "custom": {}
                  },
                  "overrides": []
                },
                "fill": 1,
                "fillGradient": 0,
                "gridPos": {
                  "h": 8,
                  "w": 12,
                  "x": 0,
                  "y": 0
                },
                "hiddenSeries": false,
                "id": 2,
                "legend": {
                  "avg": false,
                  "current": false,
                  "max": false,
                  "min": false,
                  "show": true,
                  "total": false,
                  "values": false
                },
                "lines": true,
                "linewidth": 1,
                "nullPointMode": "null",
                "options": {
                  "alertThreshold": true
                },
                "percentage": false,
                "pluginVersion": "7.2.0",
                "pointradius": 2,
                "points": false,
                "renderer": "flot",
                "seriesOverrides": [],
                "spaceLength": 10,
                "stack": false,
                "steppedLine": false,
                "targets": [
                  {
                    "expr": "sum(rate(wifano_requests_total[5m])) by (service)",
                    "interval": "",
                    "legendFormat": "{{service}}",
                    "refId": "A"
                  }
                ],
                "thresholds": [],
                "timeFrom": null,
                "timeRegions": [],
                "timeShift": null,
                "title": "Request Rate",
                "tooltip": {
                  "shared": true,
                  "sort": 0,
                  "value_type": "individual"
                },
                "type": "graph",
                "xaxis": {
                  "buckets": null,
                  "mode": "time",
                  "name": null,
                  "show": true,
                  "values": []
                },
                "yaxes": [
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  },
                  {
                    "format": "short",
                    "label": null,
                    "logBase": 1,
                    "max": null,
                    "min": null,
                    "show": true
                  }
                ],
                "yaxis": {
                  "align": false,
                  "alignLevel": null
                }
              }
            ],
            "schemaVersion": 26,
            "style": "dark",
            "tags": [],
            "templating": {
              "list": []
            },
            "time": {
              "from": "now-6h",
              "to": "now"
            },
            "timepicker": {},
            "timezone": "",
            "title": "Wifano System Dashboard",
            "uid": "wifano-system",
            "version": 1
          }

alertmanager:
  enabled: true
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'wifano-team'
      routes:
      - match:
          severity: critical
        receiver: 'wifano-team'
    receivers:
    - name: 'wifano-team'
      email_configs:
      - to: 'alerts@wifano.ai'
        from: 'prometheus@wifano.ai'
        smarthost: 'smtp.example.com:587'
        auth_username: 'prometheus@wifano.ai'
        auth_password: 'password'
        send_resolved: true
EOF

# Install the monitoring stack with custom values
helm upgrade --install wifano-monitoring wifano/wifano-monitoring \
  --namespace wifano-monitoring \
  --create-namespace \
  -f wifano-monitoring-values.yaml

# Verify the installation
kubectl get pods -n wifano-monitoring
```

### Centralized Logging with ELK Stack

Set up centralized logging for Wifano.ai:

```shellscript
# Create a values file for the ELK stack
cat <<EOF > wifano-logging-values.yaml
elasticsearch:
  replicas: 3
  resources:
    requests:
      cpu: "1000m"
      memory: "2Gi"
    limits:
      cpu: "2000m"
      memory: "4Gi"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 100Gi
  esJavaOpts: "-Xmx2g -Xms2g"

kibana:
  resources:
    requests:
      cpu: "500m"
      memory: "1Gi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 5Gi

logstash:
  enabled: true
  persistence:
    enabled: true
    storageClassName: wifano-storage
    size: 20Gi
  
filebeat:
  enabled: true
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/wifano-*.log
        processors:
          - add_kubernetes_metadata:
              host: \${NODE_NAME}
              matchers:
              - logs_path:
                  logs_path: "/var/log/containers/"
      
      output.logstash:
        hosts: ["wifano-logging-logstash:5044"]
EOF

# Install the ELK stack
helm repo add elastic https://helm.elastic.co
helm repo update
helm install wifano-logging elastic/elastic-stack \
  --namespace wifano-logging \
  --create-namespace \
  -f wifano-logging-values.yaml

# Configure Wifano.ai to send logs to the ELK stack
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-logging-config
  namespace: wifano-system
data:
  log4j2.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <Configuration status="INFO">
      <Appenders>
        <Console name="Console" target="SYSTEM_OUT">
          <PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n"/>
        </Console>
        <Socket name="Logstash" host="wifano-logging-logstash.wifano-logging.svc.cluster.local" port="5044" protocol="TCP">
          <JSONLayout complete="false" compact="true" eventEol="true" properties="true" propertiesAsList="true"/>
        </Socket>
      </Appenders>
      <Loggers>
        <Root level="info">
          <AppenderRef ref="Console"/>
          <AppenderRef ref="Logstash"/>
        </Root>
      </Loggers>
    </Configuration>
EOF

# Update Wifano deployments to use the logging configuration
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "logging-config", 
      "configMap": {
        "name": "wifano-logging-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "logging-config",
      "mountPath": "/wifano/config/log4j2.xml",
      "subPath": "log4j2.xml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "LOG4J_CONFIGURATION_FILE",
      "value": "/wifano/config/log4j2.xml"
    }
  }
]'
```

### Custom Metrics and Alerts

Set up custom metrics and alerts for Wifano.ai:

```shellscript
# Create custom Prometheus rules for Wifano.ai
kubectl apply -f - << EOF
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: wifano-alerts
  namespace: wifano-monitoring
spec:
  groups:
  - name: wifano.rules
    rules:
    - alert: WifanoHighErrorRate
      expr: sum(rate(wifano_errors_total[5m])) / sum(rate(wifano_requests_total[5m])) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate in Wifano.ai"
        description: "Wifano.ai is experiencing a high error rate (> 5%) for the last 5 minutes."
    
    - alert: WifanoHighLatency
      expr: histogram_quantile(0.95, sum(rate(wifano_request_duration_seconds_bucket[5m])) by (le)) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High latency in Wifano.ai"
        description: "95th percentile of request latency is above 2 seconds for the last 5 minutes."
    
    - alert: WifanoHighGPUUsage
      expr: avg(nvidia_gpu_duty_cycle) > 90
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "High GPU usage in Wifano.ai"
        description: "Average GPU usage is above 90% for the last 15 minutes."
    
    - alert: WifanoLowDiskSpace
      expr: kubelet_volume_stats_available_bytes{namespace="wifano-system"} / kubelet_volume_stats_capacity_bytes{namespace="wifano-system"} < 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Low disk space for Wifano.ai"
        description: "Wifano.ai is running out of disk space (< 10% available)."
EOF

# Create a custom metrics exporter for Wifano.ai
cat <<EOF > wifano-metrics-exporter.py
#!/usr/bin/env python3
import time
import random
import http.server
import socketserver
from prometheus_client import start_http_server, Counter, Gauge, Histogram

# Create metrics
REQUESTS = Counter('wifano_requests_total', 'Total number of requests', ['service', 'endpoint'])
ERRORS = Counter('wifano_errors_total', 'Total number of errors', ['service', 'error_type'])
LATENCY = Histogram('wifano_request_duration_seconds', 'Request duration in seconds', ['service', 'endpoint'], buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0])
ACTIVE_REQUESTS = Gauge('wifano_active_requests', 'Number of active requests', ['service'])
KNOWLEDGE_SIZE = Gauge('wifano_knowledge_size_bytes', 'Size of knowledge base in bytes')
MODEL_MEMORY_USAGE = Gauge('wifano_model_memory_usage_bytes', 'Memory usage of AI models')

# Simulate metrics for demonstration
def simulate_metrics():
    services = ['reasoning', 'knowledge', 'api', 'orchestrator']
    endpoints = ['query', 'update', 'health', 'status']
    error_types = ['timeout', 'validation', 'internal', 'database']
    
    while True:
        # Simulate requests
        for service in services:
            for endpoint in endpoints:
                REQUESTS.labels(service=service, endpoint=endpoint).inc(random.randint(1, 10))
                
                # Simulate latency
                with LATENCY.labels(service=service, endpoint=endpoint).time():
                    time.sleep(random.uniform(0.01, 0.1))
        
        # Simulate errors
        for service in services:
            for error_type in error_types:
                if random.random() < 0.1:  # 10% chance of error
                    ERRORS.labels(service=service, error_type=error_type).inc()
        
        # Simulate active requests
        for service in services:
            ACTIVE_REQUESTS.labels(service=service).set(random.randint(1, 100))
        
        # Simulate knowledge size (growing over time)
        current_size = KNOWLEDGE_SIZE._value.get()
        if current_size is None:
            current_size = 1000000000  # Start at 1GB
        KNOWLEDGE_SIZE.set(current_size + random.randint(1000000, 10000000))  # Add 1-10MB
        
        # Simulate model memory usage
        MODEL_MEMORY_USAGE.set(random.randint(10000000000, 20000000000))  # 10-20GB
        
        time.sleep(5)

if __name__ == '__main__':
    # Start up the server to expose the metrics.
    start_http_server(8000)
    print("Metrics server started on port 8000")
    
    # Start generating metrics
    simulate_metrics()
EOF

# Create a ConfigMap for the metrics exporter
kubectl create configmap wifano-metrics-exporter \
  --from-file=wifano-metrics-exporter.py \
  -n wifano-system

# Deploy the metrics exporter
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wifano-metrics-exporter
  namespace: wifano-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wifano-metrics-exporter
  template:
    metadata:
      labels:
        app: wifano-metrics-exporter
    spec:
      containers:
      - name: metrics-exporter
        image: python:3.9-slim
        command: ["python", "/app/wifano-metrics-exporter.py"]
        ports:
        - containerPort: 8000
          name: metrics
        volumeMounts:
        - name: exporter-config
          mountPath: /app
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
      volumes:
      - name: exporter-config
        configMap:
          name: wifano-metrics-exporter
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-metrics-exporter
  namespace: wifano-system
  labels:
    app: wifano-metrics-exporter
spec:
  ports:
  - port: 8000
    targetPort: 8000
    name: metrics
  selector:
    app: wifano-metrics-exporter
EOF

# Create a ServiceMonitor to scrape the metrics
kubectl apply -f - << EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: wifano-metrics-monitor
  namespace: wifano-monitoring
spec:
  selector:
    matchLabels:
      app: wifano-metrics-exporter
  endpoints:
  - port: metrics
    interval: 15s
  namespaceSelector:
    matchNames:
    - wifano-system
EOF
```

## Security Hardening

Securing Wifano.ai is critical for production deployments. This section covers security best practices.

### Network Security

Implement network security measures for Wifano.ai:

```shellscript
# Create network policies to restrict traffic
kubectl apply -f - << EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-default-deny
  namespace: wifano-system
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-api-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-reasoning
    ports:
    - protocol: TCP
      port: 8080
  - to:
    - podSelector:
        matchLabels:
          app: wifano-knowledge
    ports:
    - protocol: TCP
      port: 8080
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-reasoning-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-reasoning
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: wifano-api
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-knowledge
    ports:
    - protocol: TCP
      port: 8080
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wifano-knowledge-allow
  namespace: wifano-system
spec:
  podSelector:
    matchLabels:
      app: wifano-knowledge
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: wifano-api
    ports:
    - protocol: TCP
      port: 8080
  - from:
    - podSelector:
        matchLabels:
          app: wifano-reasoning
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: wifano-db
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: wifano-vector-db
    ports:
    - protocol: TCP
      port: 6333
EOF

# Set up TLS for Wifano.ai services
kubectl apply -f - << EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-tls
  namespace: wifano-system
spec:
  secretName: wifano-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: api.wifano.ai
  dnsNames:
  - api.wifano.ai
  - dashboard.wifano.ai
EOF

# Configure ingress with TLS
kubectl apply -f - << EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: wifano-ingress
  namespace: wifano-system
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  tls:
  - hosts:
    - api.wifano.ai
    - dashboard.wifano.ai
    secretName: wifano-tls
  rules:
  - host: api.wifano.ai
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: wifano-api
            port:
              number: 8080
  - host: dashboard.wifano.ai
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: wifano-dashboard
            port:
              number: 3000
EOF

# Implement API rate limiting
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configuration
  namespace: ingress-nginx
data:
  proxy-connect-timeout: "10"
  proxy-read-timeout: "300"
  proxy-send-timeout: "300"
  proxy-body-size: "50m"
  limit-rps: "100"
  limit-connections: "50"
EOF
```

### Authentication and Authorization

Implement robust authentication and authorization for Wifano.ai:

```shellscript
# Create a ConfigMap for authentication configuration
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-auth-config
  namespace: wifano-system
data:
  auth.yaml: |
    auth:
      # JWT configuration
      jwt:
        secret_key: "\${JWT_SECRET}"
        expiration: 86400  # 24 hours
        refresh_expiration: 604800  # 7 days
      
      # API key configuration
      api_keys:
        enabled: true
        rotation_period: 90  # days
      
      # RBAC configuration
      rbac:
        roles:
          - name: admin
            permissions:
              - "*"
          - name: user
            permissions:
              - "query:*"
              - "knowledge:read"
          - name: knowledge_manager
            permissions:
              - "query:*"
              - "knowledge:*"
      
      # OAuth2 configuration
      oauth2:
        enabled: true
        providers:
          - name: google
            client_id: "\${OAUTH_GOOGLE_CLIENT_ID}"
            client_secret: "\${OAUTH_GOOGLE_CLIENT_SECRET}"
            redirect_uri: "https://api.wifano.ai/auth/callback/google"
          - name: github
            client_id: "\${OAUTH_GITHUB_CLIENT_ID}"
            client_secret: "\${OAUTH_GITHUB_CLIENT_SECRET}"
            redirect_uri: "https://api.wifano.ai/auth/callback/github"
EOF

# Create secrets for authentication
kubectl create secret generic wifano-auth-secrets \
  --namespace wifano-system \
  --from-literal=JWT_SECRET=$(openssl rand -hex 32) \
  --from-literal=OAUTH_GOOGLE_CLIENT_ID="your-google-client-id" \
  --from-literal=OAUTH_GOOGLE_CLIENT_SECRET="your-google-client-secret" \
  --from-literal=OAUTH_GITHUB_CLIENT_ID="your-github-client-id" \
  --from-literal=OAUTH_GITHUB_CLIENT_SECRET="your-github-client-secret"

# Update the API deployment to use authentication
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "auth-config", 
      "configMap": {
        "name": "wifano-auth-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "auth-config",
      "mountPath": "/wifano/config/auth.yaml",
      "subPath": "auth.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_AUTH_CONFIG",
      "value": "/wifano/config/auth.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/envFrom",
    "value": [
      {
        "secretRef": {
          "name": "wifano-auth-secrets"
        }
      }
    ]
  }
]'
```

### Data Encryption

Implement data encryption for Wifano.ai:

```shellscript
# Create encryption keys
ENCRYPTION_KEY=$(openssl rand -hex 32)
echo "Encryption Key: $ENCRYPTION_KEY"

# Create a secret for encryption keys
kubectl create secret generic wifano-encryption-keys \
  --namespace wifano-system \
  --from-literal=data-encryption-key=$ENCRYPTION_KEY

# Configure database encryption
kubectl apply -f - << EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-db-encryption
  namespace: wifano-system
data:
  db-encryption.yaml: |
    encryption:
      enabled: true
      key_source: env
      key_env_var: DATA_ENCRYPTION_KEY
      algorithms:
        - name: AES-256-GCM
          default: true
        - name: ChaCha20-Poly1305
      encrypted_fields:
        - table: users
          fields: [password, email, personal_data]
        - table: api_keys
          fields: [key_value]
        - table: knowledge_items
          fields: [content, metadata]
EOF

# Update the database deployment to use encryption
kubectl patch statefulset wifano-db -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "db-encryption-config", 
      "configMap": {
        "name": "wifano-db-encryption"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "db-encryption-config",
      "mountPath": "/wifano/config/db-encryption.yaml",
      "subPath": "db-encryption.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_ENCRYPTION_CONFIG",
      "value": "/wifano/config/db-encryption.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "DATA_ENCRYPTION_KEY",
      "valueFrom": {
        "secretKeyRef": {
          "name": "wifano-encryption-keys",
          "key": "data-encryption-key"
        }
      }
    }
  }
]'

# Configure TLS for internal communication
kubectl apply -f - << EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-internal-tls
  namespace: wifano-system
spec:
  secretName: wifano-internal-tls
  issuerRef:
    name: wifano-ca
    kind: Issuer
  commonName: wifano-internal
  dnsNames:
  - wifano-api.wifano-system.svc.cluster.local
  - wifano-reasoning.wifano-system.svc.cluster.local
  - wifano-knowledge.wifano-system.svc.cluster.local
  - wifano-db.wifano-system.svc.cluster.local
  - wifano-vector-db.wifano-system.svc.cluster.local
EOF

# Update services to use TLS
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "internal-tls", 
      "secret": {
        "secretName": "wifano-internal-tls"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "internal-tls",
      "mountPath": "/wifano/certs"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_TLS_CERT",
      "value": "/wifano/certs/tls.crt"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_TLS_KEY",
      "value": "/wifano/certs/tls.key"
    }
  }
]'
```

## Scaling Wifano.ai

Scaling Wifano.ai to handle increased load is essential for production deployments.

### Horizontal Scaling

Implement horizontal scaling for Wifano.ai:

```shellscript
# Create a Horizontal Pod Autoscaler for the API
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-api-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
EOF

# Create a Horizontal Pod Autoscaler for the reasoning engine
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-reasoning-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-reasoning
  minReplicas: 2
  maxReplicas: 8
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: nvidia_gpu_duty_cycle
      target:
        type: AverageValue
        averageValue: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 120
      policies:
      - type: Pods
        value: 1
        periodSeconds: 120
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 300
EOF

# Create a Horizontal Pod Autoscaler for the knowledge system
kubectl apply -f - << EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wifano-knowledge-hpa
  namespace: wifano-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wifano-knowledge
  minReplicas: 2
  maxReplicas: 6
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
EOF
```

### Vertical Scaling

Implement vertical scaling for Wifano.ai:

```shellscript
# Install the Vertical Pod Autoscaler
kubectl apply -f https://raw.githubusercontent.com/kubernetes/autoscaler/master/vertical-pod-autoscaler/deploy/vpa-v0.9.2.yaml

# Create a Vertical Pod Autoscaler for the API
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-api-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-api
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 500m
        memory: 1Gi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
EOF

# Create a Vertical Pod Autoscaler for the reasoning engine
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-reasoning-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-reasoning
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 2
        memory: 8Gi
      maxAllowed:
        cpu: 16
        memory: 64Gi
      controlledResources: ["cpu", "memory"]
EOF

# Create a Vertical Pod Autoscaler for the knowledge system
kubectl apply -f - << EOF
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: wifano-knowledge-vpa
  namespace: wifano-system
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: wifano-knowledge
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: "*"
      minAllowed:
        cpu: 1
        memory: 4Gi
      maxAllowed:
        cpu: 8
        memory: 32Gi
      controlledResources: ["cpu", "memory"]
EOF
```

### Load Testing

Implement load testing for Wifano.ai:

```shellscript
# Create a load testing script
cat <<EOF > wifano-load-test.js
import http from 'k6/http';
import { sleep, check } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 }, // Ramp up to 100 users over 2 minutes
    { duration: '5m', target: 100 }, // Stay at 100 users for 5 minutes
    { duration: '2m', target: 200 }, // Ramp up to 200 users over 2 minutes
    { duration: '5m', target: 200 }, // Stay at 200 users for 5 minutes
    { duration: '2m', target: 300 }, // Ramp up to 300 users over 2 minutes
    { duration: '5m', target: 300 }, // Stay at 300 users for 5 minutes
    { duration: '2m', target: 0 },   // Ramp down to 0 users over 2 minutes
  ],
  thresholds: {
    http_req_duration: ['p(95)<2000'], // 95% of requests should complete within 2s
    http_req_failed: ['rate<0.05'],    // Less than 5% of requests should fail
  },
};

const API_KEY = 'your-api-key';
const BASE_URL = 'https://api.wifano.ai';

export default function () {
  const headers = {
    'Content-Type': 'application/json',
    'Authorization': `Bearer \${API_KEY}`,
  };

  // Simple query test
  const queryPayload = JSON.stringify({
    query: 'What is the relationship between quantum entanglement and information theory?',
    max_tokens: 1000,
  });

  const queryResponse = http.post(`\${BASE_URL}/v1/query`, queryPayload, { headers });
  
  check(queryResponse, {
    'query status is 200': (r) => r.status === 200,
    'query response has content': (r) => r.json().content !== undefined,
    'query response time < 2s': (r) => r.timings.duration < 2000,
  });

  // Knowledge retrieval test
  const knowledgeResponse = http.get(`\${BASE_URL}/v1/knowledge/search?q=quantum+computing`, { headers });
  
  check(knowledgeResponse, {
    'knowledge status is 200': (r) => r.status === 200,
    'knowledge response has results': (r) => r.json().results.length > 0,
    'knowledge response time < 1s': (r) => r.timings.duration < 1000,
  });

  // Health check test
  const healthResponse = http.get(`\${BASE_URL}/health`);
  
  check(healthResponse, {
    'health status is 200': (r) => r.status === 200,
    'health response is ok': (r) => r.json().status === 'ok',
    'health response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);
}
EOF

# Run the load test
k6 run wifano-load-test.js

# Create a Kubernetes job for load testing
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: wifano-load-test
  namespace: wifano-system
spec:
  template:
    spec:
      containers:
      - name: k6
        image: loadimpact/k6:latest
        command: ["k6", "run", "/tests/wifano-load-test.js"]
        volumeMounts:
        - name: test-config
          mountPath: /tests
      volumes:
      - name: test-config
        configMap:
          name: wifano-load-test
      restartPolicy: Never
  backoffLimit: 0
EOF

# Create a ConfigMap for the load test script
kubectl create configmap wifano-load-test \
  --from-file=wifano-load-test.js \
  -n wifano-system

# Run the load test job
kubectl create job --from=cronjob/wifano-load-test wifano-load-test-manual -n wifano-system

# Monitor the load test results
kubectl logs -f job/wifano-load-test-manual -n wifano-system
```

## High Availability Setup

Implementing high availability for Wifano.ai ensures the system remains operational even during failures.

### Multi-Zone Deployment

Configure Wifano.ai for multi-zone deployment:

```shellscript
# Label nodes with availability zones
kubectl label nodes node1 topology.kubernetes.io/zone=zone-a
kubectl label nodes node2 topology.kubernetes.io/zone=zone-a
kubectl label nodes node3 topology.kubernetes.io/zone=zone-b
kubectl label nodes node4 topology.kubernetes.io/zone=zone-b
kubectl label nodes node5 topology.kubernetes.io/zone=zone-c
kubectl label nodes node6 topology.kubernetes.io/zone=zone-c

# Update deployments for zone distribution
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-api"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'

# Apply similar configurations to other deployments
kubectl patch deployment wifano-reasoning -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-reasoning"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'

kubectl patch deployment wifano-knowledge -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/affinity", 
    "value": {
      "podAntiAffinity": {
        "preferredDuringSchedulingIgnoredDuringExecution": [
          {
            "weight": 100,
            "podAffinityTerm": {
              "labelSelector": {
                "matchExpressions": [
                  {
                    "key": "app",
                    "operator": "In",
                    "values": ["wifano-knowledge"]
                  }
                ]
              },
              "topologyKey": "topology.kubernetes.io/zone"
            }
          }
        ]
      }
    }
  }
]'
```

### Database High Availability

Configure high availability for Wifano.ai databases:

```shellscript
# Create a StatefulSet for PostgreSQL with replication
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: wifano-db
  namespace: wifano-system
spec:
  serviceName: wifano-db
  replicas: 3
  selector:
    matchLabels:
      app: wifano-db
  template:
    metadata:
      labels:
        app: wifano-db
    spec:
      containers:
      - name: postgres
        image: postgres:14
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_USER
          value: wifano
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: POSTGRES_DB
          value: wifano
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql/conf.d
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - wifano
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - wifano
          initialDelaySeconds: 30
          periodSeconds: 15
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: wifano-storage
      resources:
        requests:
          storage: 100Gi
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: wifano-system
data:
  postgresql.conf: |
    listen_addresses = '*'
    max_connections = 100
    shared_buffers = 4GB
    effective_cache_size = 12GB
    work_mem = 64MB
    maintenance_work_mem = 512MB
    random_page_cost = 1.1
    effective_io_concurrency = 200
    max_worker_processes = 8
    max_parallel_workers_per_gather = 4
    max_parallel_workers = 8
    wal_level = replica
    max_wal_senders = 10
    max_replication_slots = 10
    hot_standby = on
  pg_hba.conf: |
    local   all             all                                     trust
    host    all             all             127.0.0.1/32            trust
    host    all             all             ::1/128                 trust
    host    all             all             0.0.0.0/0               md5
    host    replication     all             0.0.0.0/0               md5
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db
  namespace: wifano-system
spec:
  selector:
    app: wifano-db
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-read
  namespace: wifano-system
spec:
  selector:
    app: wifano-db
  ports:
  - port: 5432
    targetPort: 5432
EOF

# Set up Patroni for PostgreSQL high availability
kubectl apply -f - << EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: wifano-db-patroni
  namespace: wifano-system
spec:
  serviceName: wifano-db-patroni
  replicas: 3
  selector:
    matchLabels:
      app: wifano-db-patroni
  template:
    metadata:
      labels:
        app: wifano-db-patroni
    spec:
      containers:
      - name: patroni
        image: registry.opensource.zalan.do/acid/patroni:2.0.2
        env:
        - name: PATRONI_KUBERNETES_POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: PATRONI_KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: PATRONI_KUBERNETES_LABELS
          value: '{app: wifano-db-patroni}'
        - name: PATRONI_SUPERUSER_USERNAME
          value: postgres
        - name: PATRONI_SUPERUSER_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: PATRONI_REPLICATION_USERNAME
          value: replicator
        - name: PATRONI_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        - name: PATRONI_SCOPE
          value: wifano-db
        - name: PATRONI_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        ports:
        - containerPort: 8008
          name: patroni
        - containerPort: 5432
          name: postgres
        volumeMounts:
        - name: data
          mountPath: /home/postgres/pgdata
        readinessProbe:
          httpGet:
            path: /readiness
            port: 8008
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /liveness
            port: 8008
          initialDelaySeconds: 30
          periodSeconds: 15
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: wifano-db-patroni-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-db-patroni-data
  namespace: wifano-system
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: wifano-storage
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni
  namespace: wifano-system
spec:
  selector:
    app: wifano-db-patroni
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni-master
  namespace: wifano-system
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  selector:
    app: wifano-db-patroni
    role: master
  ports:
  - port: 5432
    targetPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: wifano-db-patroni-replica
  namespace: wifano-system
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  selector:
    app: wifano-db-patroni
    role: replica
  ports:
  - port: 5432
    targetPort: 5432
EOF
```

### Fault Tolerance

Implement fault tolerance for Wifano.ai:

```shellscript
# Configure pod disruption budgets
kubectl apply -f - << EOF
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-api-pdb
  namespace: wifano-system
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: wifano-api
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-reasoning-pdb
  namespace: wifano-system
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: wifano-reasoning
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-knowledge-pdb
  namespace: wifano-system
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: wifano-knowledge
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wifano-db-pdb
  namespace: wifano-system
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: wifano-db
EOF

# Configure liveness and readiness probes
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/containers/0/livenessProbe", 
    "value": {
      "httpGet": {
        "path": "/health",
        "port": 8080
      },
      "initialDelaySeconds": 30,
      "periodSeconds": 10,
      "timeoutSeconds": 5,
      "failureThreshold": 3
    }
  },
  {
    "op": "add", 
    "path": "/spec/template/spec/containers/0/readinessProbe", 
    "value": {
      "httpGet": {
        "path": "/ready",
        "port": 8080
      },
      "initialDelaySeconds": 5,
      "periodSeconds": 5,
      "timeoutSeconds": 3,
      "failureThreshold": 2
    }
  }
]'

# Configure circuit breakers
kubectl apply -f - << EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: wifano-api-circuit-breaker
  namespace: wifano-system
spec:
  host: wifano-api
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
    outlierDetection:
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 100
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: wifano-reasoning-circuit-breaker
  namespace: wifano-system
spec:
  host: wifano-reasoning
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 50
      http:
        http1MaxPendingRequests: 50
        maxRequestsPerConnection: 5
    outlierDetection:
      consecutive5xxErrors: 3
      interval: 30s
      baseEjectionTime: 60s
      maxEjectionPercent: 100
EOF
```

## Backup and Disaster Recovery

Implementing backup and disaster recovery procedures is essential for Wifano.ai.

### Database Backups

Configure database backups for Wifano.ai:

```shellscript
# Create a backup script
cat <<EOF > wifano-db-backup.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\${BACKUP_DIR}/wifano_db_\${TIMESTAMP}.sql.gz"
LOG_FILE="\${BACKUP_DIR}/backup_\${TIMESTAMP}.log"

# Ensure backup directory exists
mkdir -p \${BACKUP_DIR}

# Log start time
echo "Starting backup at \$(date)" > \${LOG_FILE}

# Perform backup
echo "Creating database dump..." >> \${LOG_FILE}
PGPASSWORD=\${POSTGRES_PASSWORD} pg_dump -h wifano-db -U wifano -d wifano | gzip > \${BACKUP_FILE}

# Check if backup was successful
if [ \$? -eq 0 ]; then
  echo "Backup completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Backup file: \${BACKUP_FILE}" >> \${LOG_FILE}
  echo "Backup size: \$(du -h \${BACKUP_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Backup failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

# Rotate old backups (keep last 30 days)
find \${BACKUP_DIR} -name "wifano_db_*.sql.gz" -type f -mtime +30 -delete

# Upload to remote storage (optional)
if [ ! -z "\${S3_BUCKET}" ]; then
  echo "Uploading backup to S3..." >> \${LOG_FILE}
  aws s3 cp \${BACKUP_FILE} s3://\${S3_BUCKET}/wifano/db/
  if [ \$? -eq 0 ]; then
    echo "Upload to S3 completed successfully" >> \${LOG_FILE}
  else
    echo "Upload to S3 failed" >> \${LOG_FILE}
  fi
fi

echo "Backup process completed at \$(date)" >> \${LOG_FILE}
EOF

chmod +x wifano-db-backup.sh

# Create a ConfigMap for the backup script
kubectl create configmap wifano-backup-scripts \
  --from-file=wifano-db-backup.sh \
  -n wifano-system

# Create a CronJob for regular backups
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-db-backup
  namespace: wifano-system
spec:
  schedule: "0 2 * * *"  # Run daily at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:14
            command: ["/scripts/wifano-db-backup.sh"]
            env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: wifano-secrets
                  key: db-password
            - name: S3_BUCKET
              value: "wifano-backups"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-secret-key
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
          volumes:
          - name: backup-scripts
            configMap:
              name: wifano-backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          restartPolicy: OnFailure
EOF

# Create a PVC for backup storage
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-backup-pvc
  namespace: wifano-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: wifano-storage
EOF

# Create secrets for backup credentials
kubectl create secret generic wifano-backup-credentials \
  --namespace wifano-system \
  --from-literal=aws-access-key=YOUR_AWS_ACCESS_KEY \
  --from-literal=aws-secret-key=YOUR_AWS_SECRET_KEY
```

### Knowledge Base Backups

Configure knowledge base backups for Wifano.ai:

```shellscript
# Create a knowledge base backup script
cat <<EOF > wifano-knowledge-backup.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups/knowledge"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\${BACKUP_DIR}/wifano_knowledge_\${TIMESTAMP}.tar.gz"
LOG_FILE="\${BACKUP_DIR}/backup_\${TIMESTAMP}.log"

# Ensure backup directory exists
mkdir -p \${BACKUP_DIR}

# Log start time
echo "Starting knowledge base backup at \$(date)" > \${LOG_FILE}

# Perform backup of vector database
echo "Creating vector database dump..." >> \${LOG_FILE}
curl -X POST "http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots" \
  -H "Content-Type: application/json" \
  -d '{"snapshot_path": "/snapshots/wifano_embeddings_\${TIMESTAMP}"}' >> \${LOG_FILE} 2>&1

# Backup knowledge graph
echo "Creating knowledge graph dump..." >> \${LOG_FILE}
curl -X GET "http://wifano-knowledge-graph:8182/graphs/wifano/backup" \
  -H "Content-Type: application/json" \
  -d '{"backupPath": "/backups/wifano_graph_\${TIMESTAMP}"}' >> \${LOG_FILE} 2>&1

# Create a tarball of all knowledge data
echo "Creating tarball of knowledge data..." >> \${LOG_FILE}
tar -czf \${BACKUP_FILE} -C /snapshots wifano_embeddings_\${TIMESTAMP} -C /backups wifano_graph_\${TIMESTAMP} >> \${LOG_FILE} 2>&1

# Check if backup was successful
if [ \$? -eq 0 ]; then
  echo "Backup completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Backup file: \${BACKUP_FILE}" >> \${LOG_FILE}
  echo "Backup size: \$(du -h \${BACKUP_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Backup failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

# Rotate old backups (keep last 7 days)
find \${BACKUP_DIR} -name "wifano_knowledge_*.tar.gz" -type f -mtime +7 -delete

# Upload to remote storage (optional)
if [ ! -z "\${S3_BUCKET}" ]; then
  echo "Uploading backup to S3..." >> \${LOG_FILE}
  aws s3 cp \${BACKUP_FILE} s3://\${S3_BUCKET}/wifano/knowledge/
  if [ \$? -eq 0 ]; then
    echo "Upload to S3 completed successfully" >> \${LOG_FILE}
  else
    echo "Upload to S3 failed" >> \${LOG_FILE}
  fi
fi

echo "Knowledge backup process completed at \$(date)" >> \${LOG_FILE}
EOF

chmod +x wifano-knowledge-backup.sh

# Add the knowledge backup script to the ConfigMap
kubectl create configmap wifano-knowledge-backup-scripts \
  --from-file=wifano-knowledge-backup.sh \
  -n wifano-system

# Create a CronJob for regular knowledge backups
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-knowledge-backup
  namespace: wifano-system
spec:
  schedule: "0 3 * * *"  # Run daily at 3 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: amazon/aws-cli:latest
            command: ["/scripts/wifano-knowledge-backup.sh"]
            env:
            - name: S3_BUCKET
              value: "wifano-backups"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: wifano-backup-credentials
                  key: aws-secret-key
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
            - name: snapshot-storage
              mountPath: /snapshots
          volumes:
          - name: backup-scripts
            configMap:
              name: wifano-knowledge-backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          - name: snapshot-storage
            persistentVolumeClaim:
              claimName: wifano-snapshot-pvc
          restartPolicy: OnFailure
EOF

# Create a PVC for snapshot storage
kubectl apply -f - << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: wifano-snapshot-pvc
  namespace: wifano-system
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  storageClassName: wifano-storage
EOF
```

### Disaster Recovery Plan

Create a disaster recovery plan for Wifano.ai:

```shellscript
# Create a disaster recovery script
cat <<EOF > wifano-disaster-recovery.sh
#!/bin/bash

# Set variables
BACKUP_DIR="/backups"
RESTORE_LOG="/var/log/wifano-restore.log"

# Function to display usage
usage() {
  echo "Usage: \$0 [OPTIONS]"
  echo "Options:"
  echo "  --db-backup FILE     Specify the database backup file to restore"
  echo "  --knowledge-backup FILE  Specify the knowledge backup file to restore"
  echo "  --config-backup FILE     Specify the configuration backup file to restore"
  echo "  --full-restore       Perform a full system restore (requires all backup files)"
  echo "  --help               Display this help message"
  exit 1
}

# Parse command line arguments
while [[ \$# -gt 0 ]]; do
  key="\$1"
  case \$key in
    --db-backup)
      DB_BACKUP="\$2"
      shift
      shift
      ;;
    --knowledge-backup)
      KNOWLEDGE_BACKUP="\$2"
      shift
      shift
      ;;
    --config-backup)
      CONFIG_BACKUP="\$2"
      shift
      shift
      ;;
    --full-restore)
      FULL_RESTORE=true
      shift
      ;;
    --help)
      usage
      ;;
    *)
      echo "Unknown option: \$1"
      usage
      ;;
  esac
done

# Log start time
echo "Starting disaster recovery at \$(date)" > \${RESTORE_LOG}

# Restore database if specified
if [ ! -z "\${DB_BACKUP}" ]; then
  echo "Restoring database from \${DB_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Stop database-dependent services
  echo "Stopping database-dependent services..." | tee -a \${RESTORE_LOG}
  kubectl scale deployment wifano-api --replicas=0 -n wifano-system
  kubectl scale deployment wifano-knowledge --replicas=0 -n wifano-system
  
  # Wait for services to stop
  echo "Waiting for services to stop..." | tee -a \${RESTORE_LOG}
  kubectl wait --for=delete pod -l app=wifano-api -n wifano-system --timeout=300s
  kubectl wait --for=delete pod -l app=wifano-knowledge -n wifano-system --timeout=300s
  
  # Restore database
  echo "Performing database restore..." | tee -a \${RESTORE_LOG}
  if [[ \${DB_BACKUP} == *.gz ]]; then
    gunzip -c \${DB_BACKUP} | PGPASSWORD=\${POSTGRES_PASSWORD} psql -h wifano-db -U wifano -d wifano
  else
    PGPASSWORD=\${POSTGRES_PASSWORD} psql -h wifano-db -U wifano -d wifano -f \${DB_BACKUP}
  fi
  
  # Check restore status
  if [ \$? -eq 0 ]; then
    echo "Database restore completed successfully" | tee -a \${RESTORE_LOG}
  else
    echo "Database restore failed" | tee -a \${RESTORE_LOG}
    exit 1
  fi
  
  # Restart services
  echo "Restarting database-dependent services..." | tee -a \${RESTORE_LOG}
  kubectl scale deployment wifano-api --replicas=3 -n wifano-system
  kubectl scale deployment wifano-knowledge --replicas=2 -n wifano-system
fi

# Restore knowledge base if specified
if [ ! -z "\${KNOWLEDGE_BACKUP}" ]; then
  echo "Restoring knowledge base from \${KNOWLEDGE_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Extract the knowledge backup
  echo "Extracting knowledge backup..." | tee -a \${RESTORE_LOG}
  mkdir -p /tmp/knowledge-restore
  tar -xzf \${KNOWLEDGE_BACKUP} -C /tmp/knowledge-restore
  
  # Restore vector database
  echo "Restoring vector database..." | tee -a \${RESTORE_LOG}
  VECTOR_SNAPSHOT=\$(find /tmp/knowledge-restore -name "wifano_embeddings_*" | head -1)
  curl -X PUT "http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots/restore" \
    -H "Content-Type: application/json" \
    -d "{\"snapshot_path\": \"\${VECTOR_SNAPSHOT}\"}" >> \${RESTORE_LOG} 2>&1
  
  # Restore knowledge graph
  echo "Restoring knowledge graph..." | tee -a \${RESTORE_LOG}
  GRAPH_BACKUP=\$(find /tmp/knowledge-restore -name "wifano_graph_*" | head -1)
  curl -X POST "http://wifano-knowledge-graph:8182/graphs/wifano/restore" \
    -H "Content-Type: application/json" \
    -d "{\"backupPath\": \"\${GRAPH_BACKUP}\"}" >> \${RESTORE_LOG} 2>&1
  
  # Clean up
  rm -rf /tmp/knowledge-restore
  
  # Restart knowledge services
  echo "Restarting knowledge services..." | tee -a \${RESTORE_LOG}
  kubectl rollout restart deployment wifano-knowledge -n wifano-system
fi

# Restore configuration if specified
if [ ! -z "\${CONFIG_BACKUP}" ]; then
  echo "Restoring configuration from \${CONFIG_BACKUP}..." | tee -a \${RESTORE_LOG}
  
  # Extract the configuration backup
  echo "Extracting configuration backup..." | tee -a \${RESTORE_LOG}
  mkdir -p /tmp/config-restore
  tar -xzf \${CONFIG_BACKUP} -C /tmp/config-restore
  
  # Apply configuration
  echo "Applying configuration..." | tee -a \${RESTORE_LOG}
  kubectl apply -f /tmp/config-restore/configmaps.yaml -n wifano-system
  kubectl apply -f /tmp/config-restore/secrets.yaml -n wifano-system
  
  # Clean up
  rm -rf /tmp/config-restore
  
  # Restart all services to apply new configuration
  echo "Restarting all services to apply new configuration..." | tee -a \${RESTORE_LOG}
  kubectl rollout restart deployment -n wifano-system
fi

# Perform full system restore if specified
if [ "\${FULL_RESTORE}" = true ]; then
  if [ -z "\${DB_BACKUP}" ] || [ -z "\${KNOWLEDGE_BACKUP}" ] || [ -z "\${CONFIG_BACKUP}" ]; then
    echo "Full restore requires all backup files to be specified" | tee -a \${RESTORE_LOG}
    exit 1
  fi
  
  echo "Performing full system verification..." | tee -a \${RESTORE_LOG}
  
  # Wait for all services to be ready
  echo "Waiting for all services to be ready..." | tee -a \${RESTORE_LOG}
  kubectl wait --for=condition=available deployment --all -n wifano-system --timeout=600s
  
  # Verify system health
  echo "Verifying system health..." | tee -a \${RESTORE_LOG}
  wifano-cli system health --full >> \${RESTORE_LOG} 2>&1
  
  # Run system tests
  echo "Running system tests..." | tee -a \${RESTORE_LOG}
  wifano-cli test run --suite basic >> \${RESTORE_LOG} 2>&1
  
  # Check test results
  if [ \$? -eq 0 ]; then
    echo "System tests passed. Full restore completed successfully." | tee -a \${RESTORE_LOG}
  else
    echo "System tests failed. Please check the logs for details." | tee -a \${RESTORE_LOG}
    exit 1
  fi
fi

echo "Disaster recovery process completed at \$(date)" | tee -a \${RESTORE_LOG}
EOF

chmod +x wifano-disaster-recovery.sh

# Create a ConfigMap for the disaster recovery script
kubectl create configmap wifano-dr-scripts \
  --from-file=wifano-disaster-recovery.sh \
  -n wifano-system

# Create a disaster recovery job template
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: wifano-disaster-recovery
  namespace: wifano-system
spec:
  template:
    spec:
      containers:
      - name: recovery
        image: postgres:14
        command: ["/scripts/wifano-disaster-recovery.sh"]
        args: ["--full-restore", "--db-backup", "/backups/wifano_db_latest.sql.gz", "--knowledge-backup", "/backups/wifano_knowledge_latest.tar.gz", "--config-backup", "/backups/wifano_config_latest.tar.gz"]
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: wifano-secrets
              key: db-password
        volumeMounts:
        - name: dr-scripts
          mountPath: /scripts
        - name: backup-storage
          mountPath: /backups
      volumes:
      - name: dr-scripts
        configMap:
          name: wifano-dr-scripts
          defaultMode: 0755
      - name: backup-storage
        persistentVolumeClaim:
          claimName: wifano-backup-pvc
      restartPolicy: OnFailure
EOF

# Create symbolic links to the latest backups
cat <<EOF > update-latest-backups.sh
#!/bin/bash

# Set backup directory
BACKUP_DIR="/backups"

# Update database backup symlink
DB_LATEST=\$(ls -t \${BACKUP_DIR}/wifano_db_*.sql.gz | head -1)
if [ ! -z "\${DB_LATEST}" ]; then
  ln -sf \${DB_LATEST} \${BACKUP_DIR}/wifano_db_latest.sql.gz
fi

# Update knowledge backup symlink
KNOWLEDGE_LATEST=\$(ls -t \${BACKUP_DIR}/knowledge/wifano_knowledge_*.tar.gz | head -1)
if [ ! -z "\${KNOWLEDGE_LATEST}" ]; then
  ln -sf \${KNOWLEDGE_LATEST} \${BACKUP_DIR}/wifano_knowledge_latest.tar.gz
fi

# Update config backup symlink
CONFIG_LATEST=\$(ls -t \${BACKUP_DIR}/config/wifano_config_*.tar.gz | head -1)
if [ ! -z "\${CONFIG_LATEST}" ]; then
  ln -sf \${CONFIG_LATEST} \${BACKUP_DIR}/wifano_config_latest.tar.gz
fi
EOF

chmod +x update-latest-backups.sh

# Add the script to the ConfigMap
kubectl create configmap wifano-backup-utils \
  --from-file=update-latest-backups.sh \
  -n wifano-system

# Create a CronJob to update the latest backup symlinks
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-update-latest-backups
  namespace: wifano-system
spec:
  schedule: "0 5 * * *"  # Run daily at 5 AM
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: update-symlinks
            image: alpine:latest
            command: ["/scripts/update-latest-backups.sh"]
            volumeMounts:
            - name: backup-utils
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backups
          volumes:
          - name: backup-utils
            configMap:
              name: wifano-backup-utils
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: wifano-backup-pvc
          restartPolicy: OnFailure
EOF
```

## Troubleshooting Common Issues

This section provides guidance on troubleshooting common issues with Wifano.ai.

### Diagnostic Tools

Set up diagnostic tools for Wifano.ai:

```shellscript
# Create a diagnostic script
cat <<EOF > wifano-diagnostics.sh
#!/bin/bash

# Set variables
DIAG_DIR="/tmp/wifano-diagnostics"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
DIAG_FILE="\${DIAG_DIR}/wifano_diagnostics_\${TIMESTAMP}.tar.gz"
LOG_FILE="\${DIAG_DIR}/diagnostics_\${TIMESTAMP}.log"

# Ensure diagnostic directory exists
mkdir -p \${DIAG_DIR}

# Log start time
echo "Starting diagnostics at \$(date)" > \${LOG_FILE}

# Collect system information
echo "Collecting system information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/system
uname -a > \${DIAG_DIR}/system/uname.txt
cat /etc/os-release > \${DIAG_DIR}/system/os-release.txt
free -h > \${DIAG_DIR}/system/memory.txt
df -h > \${DIAG_DIR}/system/disk.txt
top -b -n 1 > \${DIAG_DIR}/system/top.txt
ps aux > \${DIAG_DIR}/system/processes.txt
netstat -tuln > \${DIAG_DIR}/system/netstat.txt
ip addr > \${DIAG_DIR}/system/ip-addr.txt
ip route > \${DIAG_DIR}/system/ip-route.txt

# Collect Kubernetes information
echo "Collecting Kubernetes information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/kubernetes
kubectl get nodes -o wide > \${DIAG_DIR}/kubernetes/nodes.txt
kubectl get pods -A -o wide > \${DIAG_DIR}/kubernetes/pods.txt
kubectl get services -A > \${DIAG_DIR}/kubernetes/services.txt
kubectl get deployments -A > \${DIAG_DIR}/kubernetes/deployments.txt
kubectl get statefulsets -A > \${DIAG_DIR}/kubernetes/statefulsets.txt
kubectl get pv > \${DIAG_DIR}/kubernetes/pv.txt
kubectl get pvc -A > \${DIAG_DIR}/kubernetes/pvc.txt
kubectl get events -A > \${DIAG_DIR}/kubernetes/events.txt

# Collect Wifano.ai specific information
echo "Collecting Wifano.ai information..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano
kubectl get pods -n wifano-system -o wide > \${DIAG_DIR}/wifano/pods.txt
kubectl get services -n wifano-system > \${DIAG_DIR}/wifano/services.txt
kubectl get deployments -n wifano-system > \${DIAG_DIR}/wifano/deployments.txt
kubectl get statefulsets -n wifano-system > \${DIAG_DIR}/wifano/statefulsets.txt
kubectl get configmaps -n wifano-system > \${DIAG_DIR}/wifano/configmaps.txt
kubectl get secrets -n wifano-system > \${DIAG_DIR}/wifano/secrets.txt
kubectl get events -n wifano-system > \${DIAG_DIR}/wifano/events.txt

# Collect logs from Wifano.ai pods
echo "Collecting Wifano.ai logs..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/logs
for pod in \$(kubectl get pods -n wifano-system -o jsonpath='{.items[*].metadata.name}'); do
  kubectl logs \${pod} -n wifano-system > \${DIAG_DIR}/wifano/logs/\${pod}.log 2>> \${LOG_FILE}
done

# Collect Wifano.ai configuration
echo "Collecting Wifano.ai configuration..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/config
for cm in \$(kubectl get configmaps -n wifano-system -o jsonpath='{.items[*].metadata.name}'); do
  kubectl get configmap \${cm} -n wifano-system -o yaml > \${DIAG_DIR}/wifano/config/\${cm}.yaml 2>> \${LOG_FILE}
done

# Run Wifano.ai health checks
echo "Running Wifano.ai health checks..." >> \${LOG_FILE}
mkdir -p \${DIAG_DIR}/wifano/health
wifano-cli system health --full > \${DIAG_DIR}/wifano/health/system-health.txt 2>> \${LOG_FILE}
wifano-cli diagnostics --full > \${DIAG_DIR}/wifano/health/diagnostics.txt 2>> \${LOG_FILE}

# Create a tarball of all diagnostic data
echo "Creating diagnostic tarball..." >> \${LOG_FILE}
tar -czf \${DIAG_FILE} -C \${DIAG_DIR} system kubernetes wifano \${LOG_FILE##*/}

# Check if tarball creation was successful
if [ \$? -eq 0 ]; then
  echo "Diagnostics completed successfully at \$(date)" >> \${LOG_FILE}
  echo "Diagnostic file: \${DIAG_FILE}" >> \${LOG_FILE}
  echo "Diagnostic file size: \$(du -h \${DIAG_FILE} | cut -f1)" >> \${LOG_FILE}
else
  echo "Diagnostics tarball creation failed at \$(date)" >> \${LOG_FILE}
  exit 1
fi

echo "Diagnostics process completed at \$(date)" >> \${LOG_FILE}
echo "Diagnostic file: \${DIAG_FILE}"
EOF

chmod +x wifano-diagnostics.sh

# Create a ConfigMap for the diagnostic script
kubectl create configmap wifano-diagnostic-scripts \
  --from-file=wifano-diagnostics.sh \
  -n wifano-system

# Create a diagnostic pod template
kubectl apply -f - << EOF
apiVersion: v1
kind: Pod
metadata:
  name: wifano-diagnostics
  namespace: wifano-system
spec:
  containers:
  - name: diagnostics
    image: bitnami/kubectl:latest
    command: ["/scripts/wifano-diagnostics.sh"]
    volumeMounts:
    - name: diagnostic-scripts
      mountPath: /scripts
    - name: diagnostic-output
      mountPath: /tmp/wifano-diagnostics
  volumes:
  - name: diagnostic-scripts
    configMap:
      name: wifano-diagnostic-scripts
      defaultMode: 0755
  - name: diagnostic-output
    emptyDir: {}
  restartPolicy: Never
EOF
```

### Common Issues and Solutions

Here are solutions for common Wifano.ai issues:

```shellscript
# Create a troubleshooting guide
cat <<EOF > wifano-troubleshooting.md
# Wifano.ai Troubleshooting Guide

## API Connection Issues

### Symptom: Unable to connect to Wifano.ai API

**Possible causes and solutions:**

1. **Network connectivity issues**
   ```bash
   # Check if the API service is running
   kubectl get pods -n wifano-system -l app=wifano-api
   
   # Check if the API service is exposed correctly
   kubectl get svc wifano-api -n wifano-system
   
   # Test connectivity from within the cluster
   kubectl run -it --rm debug --image=curlimages/curl -- curl http://wifano-api.wifano-system:8080/health
```

2. **Ingress configuration issues**

```shellscript
# Check ingress configuration
kubectl get ingress -n wifano-system

# Check ingress controller logs
kubectl logs -n ingress-nginx -l app.kubernetes.io/name=ingress-nginx

# Verify TLS certificate
kubectl get secret wifano-tls -n wifano-system -o yaml
```


3. **API service is crashing**

```shellscript
# Check API pod logs
kubectl logs -n wifano-system -l app=wifano-api

# Check for resource constraints
kubectl describe pods -n wifano-system -l app=wifano-api
```




## Reasoning Engine Issues

### Symptom: Slow or failing reasoning responses

**Possible causes and solutions:**

1. **GPU resource constraints**

```shellscript
# Check GPU utilization
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- nvidia-smi

# Check for GPU memory leaks
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- nvidia-smi --query-compute-apps=pid,used_memory --format=csv

# Restart reasoning engine if needed
kubectl rollout restart deployment wifano-reasoning -n wifano-system
```


2. **Model loading issues**

```shellscript
# Check if model files exist
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- ls -la /models

# Verify model checksum
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- sha256sum /models/wifano-reasoning-v3.bin

# Check model loading logs
kubectl logs -n wifano-system -l app=wifano-reasoning | grep "Loading model"
```


3. **Configuration issues**

```shellscript
# Check reasoning engine configuration
kubectl get configmap wifano-config -n wifano-system -o yaml

# Verify environment variables
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-reasoning -o jsonpath='{.items[0].metadata.name}') -- env | grep WIFANO
```




## Knowledge System Issues

### Symptom: Missing or outdated knowledge

**Possible causes and solutions:**

1. **Knowledge database connectivity issues**

```shellscript
# Check database connection
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- pg_isready -h wifano-db -U wifano

# Check vector database status
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- curl -s http://wifano-vector-db:6333/collections/wifano_embeddings
```


2. **Knowledge update failures**

```shellscript
# Check knowledge update logs
kubectl logs -n wifano-system -l app=wifano-knowledge | grep "Updating knowledge"

# Manually trigger knowledge update
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-knowledge -o jsonpath='{.items[0].metadata.name}') -- wifano-cli knowledge update --force
```


3. **Storage issues**

```shellscript
# Check storage usage
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- df -h

# Check PVC status
kubectl get pvc -n wifano-system
kubectl describe pvc wifano-pvc -n wifano-system
```




## Performance Issues

### Symptom: High latency or timeouts

**Possible causes and solutions:**

1. **Resource constraints**

```shellscript
# Check node resource usage
kubectl top nodes

# Check pod resource usage
kubectl top pods -n wifano-system

# Increase resources if needed
kubectl scale deployment wifano-reasoning --replicas=4 -n wifano-system
```


2. **Network bottlenecks**

```shellscript
# Check network policies
kubectl get networkpolicies -n wifano-system

# Test network latency
kubectl run -it --rm netutils --image=nicolaka/netshoot -- ping wifano-api.wifano-system
```


3. **Database performance issues**

```shellscript
# Check database performance
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- psql -U wifano -c "SELECT * FROM pg_stat_activity WHERE state = 'active';"

# Optimize database
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- psql -U wifano -c "VACUUM ANALYZE;"
```




## Security Issues

### Symptom: Authentication or authorization failures

**Possible causes and solutions:**

1. **API key issues**

```shellscript
# Check API key configuration
kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.api-key}' | base64 --decode

# Regenerate API key if needed
NEW_API_KEY=$(openssl rand -hex 32)
kubectl patch secret wifano-secrets -n wifano-system -p="{\"data\":{\"api-key\":\"$(echo -n $NEW_API_KEY | base64)\"}}"
```


2. **TLS certificate issues**

```shellscript
# Check certificate expiration
kubectl get secret wifano-tls -n wifano-system -o jsonpath='{.data.tls\.crt}' | base64 --decode | openssl x509 -noout -dates

# Renew certificate if needed
kubectl delete certificate wifano-tls -n wifano-system
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: wifano-tls
  namespace: wifano-system
spec:
  secretName: wifano-tls
  issuerRef:
    name: letsencrypt-prod
    kind: ClusterIssuer
  commonName: api.wifano.ai
  dnsNames:
  - api.wifano.ai
  - dashboard.wifano.ai
EOF
```


3. **RBAC issues**

```shellscript
# Check RBAC configuration
kubectl get configmap wifano-auth-config -n wifano-system -o yaml

# Verify service account permissions
kubectl auth can-i --list --as=system:serviceaccount:wifano-system:wifano-sa -n wifano-system
```




## Monitoring and Logging Issues

### Symptom: Missing metrics or logs

**Possible causes and solutions:**

1. **Prometheus configuration issues**

```shellscript
# Check Prometheus targets
kubectl port-forward svc/wifano-monitoring-prometheus -n wifano-monitoring 9090:9090
# Then open http://localhost:9090/targets in your browser

# Check ServiceMonitor configuration
kubectl get servicemonitor -n wifano-monitoring
```


2. **Logging pipeline issues**

```shellscript
# Check Filebeat status
kubectl get pods -n wifano-logging -l app=filebeat
kubectl logs -n wifano-logging -l app=filebeat

# Check Logstash status
kubectl get pods -n wifano-logging -l app=logstash
kubectl logs -n wifano-logging -l app=logstash
```


3. **Storage issues for logs**

```shellscript
# Check Elasticsearch storage
kubectl get pvc -n wifano-logging
kubectl describe pvc elasticsearch-data -n wifano-logging
```




## Backup and Restore Issues

### Symptom: Backup failures or restore errors

**Possible causes and solutions:**

1. **Storage access issues**

```shellscript
# Check backup PVC status
kubectl get pvc wifano-backup-pvc -n wifano-system
kubectl describe pvc wifano-backup-pvc -n wifano-system

# Check backup storage usage
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l job-name=wifano-db-backup -o jsonpath='{.items[0].metadata.name}') -- df -h /backups
```


2. **Backup job failures**

```shellscript
# Check backup job logs
kubectl logs -n wifano-system -l job-name=wifano-db-backup

# Check CronJob status
kubectl get cronjob -n wifano-system
```


3. **Restore process issues**

```shellscript
# Check restore job logs
kubectl logs -n wifano-system -l job-name=wifano-disaster-recovery

# Verify backup files
kubectl exec -it -n wifano-system $(kubectl get pods -n wifano-system -l app=wifano-api -o jsonpath='{.items[0].metadata.name}') -- ls -la /backups
```




EOF

# Create a ConfigMap for the troubleshooting guide

kubectl create configmap wifano-troubleshooting-guide --from-file=wifano-troubleshooting.md -n wifano-system

```plaintext

## Advanced Usage Scenarios

This section covers advanced usage scenarios for Wifano.ai.

### Custom Model Integration

Integrate custom models with Wifano.ai:

```bash
# Create a script for custom model integration
cat <<EOF > wifano-custom-model.sh
#!/bin/bash

# Set variables
MODEL_NAME=\$1
MODEL_PATH=\$2
MODEL_CONFIG=\$3

# Validate inputs
if [ -z "\$MODEL_NAME" ] || [ -z "\$MODEL_PATH" ] || [ -z "\$MODEL_CONFIG" ]; then
  echo "Usage: \$0 <model_name> <model_path> <model_config>"
  echo "Example: \$0 custom-model-v1 /models/custom-model-v1 /configs/custom-model-config.json"
  exit 1
fi

# Check if model files exist
if [ ! -f "\$MODEL_PATH" ]; then
  echo "Error: Model file not found at \$MODEL_PATH"
  exit 1
fi

if [ ! -f "\$MODEL_CONFIG" ]; then
  echo "Error: Model configuration file not found at \$MODEL_CONFIG"
  exit 1
fi

# Create a temporary directory for model processing
TEMP_DIR=\$(mktemp -d)
echo "Created temporary directory: \$TEMP_DIR"

# Copy model files to temporary directory
cp "\$MODEL_PATH" "\$TEMP_DIR/model.bin"
cp "\$MODEL_CONFIG" "\$TEMP_DIR/config.json"

# Create model metadata
cat <<EOT > "\$TEMP_DIR/metadata.json"
{
  "name": "\$MODEL_NAME",
  "version": "1.0.0",
  "description": "Custom model for Wifano.ai",
  "created_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "parameters": $(jq '.parameters // 0' "\$MODEL_CONFIG"),
  "architecture": "$(jq -r '.architecture // "custom"' "\$MODEL_CONFIG")",
  "license": "proprietary",
  "sha256": "$(sha256sum "\$MODEL_PATH" | cut -d' ' -f1)"
}
EOT

# Create a Docker image with the custom model
cat <<EOT > "\$TEMP_DIR/Dockerfile"
FROM wifano/reasoning-base:latest

# Copy model files
COPY model.bin /models/\$MODEL_NAME/model.bin
COPY config.json /models/\$MODEL_NAME/config.json
COPY metadata.json /models/\$MODEL_NAME/metadata.json

# Set environment variables
ENV WIFANO_MODEL_PATH=/models/\$MODEL_NAME
ENV WIFANO_MODEL_CONFIG=/models/\$MODEL_NAME/config.json
EOT

# Build the Docker image
echo "Building Docker image for custom model..."
docker build -t wifano/reasoning:\$MODEL_NAME \$TEMP_DIR

# Push the image to the registry
echo "Pushing Docker image to registry..."
docker tag wifano/reasoning:\$MODEL_NAME registry.wifano.ai/wifano/reasoning:\$MODEL_NAME
docker push registry.wifano.ai/wifano/reasoning:\$MODEL_NAME

# Clean up temporary directory
rm -rf \$TEMP_DIR

# Create a deployment for the custom model
kubectl apply -f - << EOT
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wifano-reasoning-\$MODEL_NAME
  namespace: wifano-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wifano-reasoning
      model: \$MODEL_NAME
  template:
    metadata:
      labels:
        app: wifano-reasoning
        model: \$MODEL_NAME
    spec:
      containers:
      - name: reasoning
        image: registry.wifano.ai/wifano/reasoning:\$MODEL_NAME
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "8"
            memory: "32Gi"
            nvidia.com/gpu: "1"
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 120
          periodSeconds: 30
        volumeMounts:
        - name: model-cache
          mountPath: /cache
      volumes:
      - name: model-cache
        emptyDir: {}
EOT

# Create a service for the custom model
kubectl apply -f - << EOT
apiVersion: v1
kind: Service
metadata:
  name: wifano-reasoning-\$MODEL_NAME
  namespace: wifano-system
  labels:
    app: wifano-reasoning
    model: \$MODEL_NAME
spec:
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  - port: 9090
    targetPort: 9090
    name: metrics
  selector:
    app: wifano-reasoning
    model: \$MODEL_NAME
EOT

# Update API configuration to use the custom model
kubectl apply -f - << EOT
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-custom-model-config
  namespace: wifano-system
data:
  custom-models.yaml: |
    models:
      - name: \$MODEL_NAME
        service: wifano-reasoning-\$MODEL_NAME
        port: 8080
        path: /v1/generate
        timeout: 300
        max_tokens: $(jq '.max_tokens // 4096' "\$MODEL_CONFIG")
EOT

# Restart the API to apply the new configuration
kubectl rollout restart deployment wifano-api -n wifano-system

echo "Custom model \$MODEL_NAME has been successfully integrated with Wifano.ai"
echo "You can now use the model by specifying 'model=\$MODEL_NAME' in your API requests"
EOF

chmod +x wifano-custom-model.sh

# Create a ConfigMap for the custom model integration script
kubectl create configmap wifano-custom-model-scripts \
  --from-file=wifano-custom-model.sh \
  -n wifano-system
```

### Advanced Query Techniques

Implement advanced query techniques for Wifano.ai:

```shellscript
# Create a guide for advanced query techniques
cat <<EOF > wifano-advanced-queries.md
# Wifano.ai Advanced Query Techniques

## Query Parameters

Wifano.ai supports a variety of query parameters to customize the behavior of the AI system:

| Parameter | Description | Default | Range |
|-----------|-------------|---------|-------|
| temperature | Controls randomness in generation | 0.7 | 0.0-1.0 |
| top_p | Controls diversity via nucleus sampling | 0.95 | 0.0-1.0 |
| max_tokens | Maximum number of tokens to generate | 1024 | 1-16384 |
| stop | Sequences where the API will stop generating | [] | Array of strings |
| presence_penalty | Penalizes repeated tokens | 0.0 | -2.0-2.0 |
| frequency_penalty | Penalizes frequent tokens | 0.0 | -2.0-2.0 |
| reasoning_depth | Controls depth of reasoning | "standard" | "basic", "standard", "deep" |
| knowledge_recency | Controls recency of knowledge | "balanced" | "recent", "balanced", "comprehensive" |
| tools | List of tools to enable | [] | Array of tool names |

## Example Queries

### Basic Query

```json
{
  "query": "What is the relationship between quantum entanglement and information theory?",
  "max_tokens": 1000,
  "temperature": 0.7
}
```

### Deep Reasoning Query

```json
{
  "query": "Analyze the implications of recent advances in quantum computing for cryptography.",
  "max_tokens": 2000,
  "temperature": 0.3,
  "reasoning_depth": "deep",
  "knowledge_recency": "recent"
}
```

### Tool-Augmented Query

```json
{
  "query": "Analyze this dataset and identify key trends.",
  "max_tokens": 1500,
  "temperature": 0.2,
  "tools": ["data-analyzer", "chart-generator"],
  "tool_inputs": {
    "data-analyzer": {
      "data_url": "https://example.com/dataset.csv",
      "analysis_type": "time_series"
    }
  }
}
```

### Multi-Step Reasoning Query

```json
{
  "query": "Design a research methodology to study the effects of climate change on marine ecosystems.",
  "max_tokens": 3000,
  "temperature": 0.4,
  "reasoning_steps": [
    "problem_definition",
    "literature_review",
    "methodology_design",
    "analysis_plan",
    "limitations"
  ]
}
```

### Knowledge-Intensive Query

```json
{
  "query": "Compare and contrast the latest treatment approaches for Alzheimer's disease.",
  "max_tokens": 2500,
  "temperature": 0.5,
  "knowledge_recency": "recent",
  "knowledge_sources": ["pubmed", "clinical_trials", "research_papers"],
  "min_citation_count": 10
}
```

## Advanced Techniques

### Chain of Thought Prompting

To encourage step-by-step reasoning, structure your query like this:

```json
{
  "query": "Let's solve this step by step: What would be the economic impact of a 2°C global temperature increase by 2050?",
  "max_tokens": 2000,
  "temperature": 0.3
}
```

### Tool Chaining

To use multiple tools in sequence:

```json
{
  "query": "Analyze this genomic sequence and identify potential therapeutic targets.",
  "max_tokens": 2000,
  "tools": ["sequence-analyzer", "protein-structure-predictor", "drug-target-finder"],
  "tool_chain": true,
  "tool_inputs": {
    "sequence-analyzer": {
      "sequence": "ATGCGATCGATCGATCGATCG..."
    }
  }
}
```

### Knowledge Graph Queries

To explicitly query the knowledge graph:

```json
{
  "query": "What are the connections between inflammation, gut microbiome, and autoimmune diseases?",
  "max_tokens": 2000,
  "knowledge_graph_query": true,
  "graph_depth": 3,
  "min_relationship_strength": 0.7
}
```

### Hybrid Queries

To combine different reasoning modes:

```json
{
  "query": "Develop a comprehensive climate action plan for a coastal city.",
  "max_tokens": 5000,
  "reasoning_modes": [
    {"mode": "analytical", "weight": 0.4},
    {"mode": "creative", "weight": 0.3},
    {"mode": "practical", "weight": 0.3}
  ]
}
```

## API Examples

### Python Example

```python
import requests
import json

API_KEY = "your_api_key"
API_URL = "https://api.wifano.ai/v1/query"

headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
}

payload = {
    "query": "What are the latest advances in fusion energy research?",
    "max_tokens": 2000,
    "temperature": 0.5,
    "knowledge_recency": "recent"
}

response = requests.post(API_URL, headers=headers, data=json.dumps(payload))
result = response.json()

print(result["content"])
```

### cURL Example

```shellscript
curl -X POST https://api.wifano.ai/v1/query \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer your_api_key" \\
  -d '{
    "query": "What are the latest advances in fusion energy research?",
    "max_tokens": 2000,
    "temperature": 0.5,
    "knowledge_recency": "recent"
  }'
```

### JavaScript Example

```javascript
const fetch = require('node-fetch');

const API_KEY = 'your_api_key';
const API_URL = 'https://api.wifano.ai/v1/query';

const payload = {
  query: 'What are the latest advances in fusion energy research?',
  max_tokens: 2000,
  temperature: 0.5,
  knowledge_recency: 'recent'
};

fetch(API_URL, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${API_KEY}`
  },
  body: JSON.stringify(payload)
})
.then(response => response.json())
.then(data => console.log(data.content))
.catch(error => console.error('Error:', error));
```

EOF

# Create a ConfigMap for the advanced query techniques guide

kubectl create configmap wifano-advanced-queries --from-file=wifano-advanced-queries.md -n wifano-system

```plaintext

## Integration with External Systems

This section covers integration of Wifano.ai with external systems.

### API Integration

Set up API integration for Wifano.ai:

```bash
# Create an API integration guide
cat <<EOF > wifano-api-integration.md
# Wifano.ai API Integration Guide

## API Overview

Wifano.ai provides a comprehensive REST API for integration with external systems. The API follows OpenAPI 3.0 standards and supports both synchronous and asynchronous operations.

## Authentication

All API requests require authentication using an API key. The API key should be included in the Authorization header:

```

Authorization: Bearer your_api_key

```plaintext

API keys can be generated and managed through the Wifano.ai dashboard or using the CLI:

```bash
# Generate a new API key
wifano-cli auth create-key --name "integration-key" --role "api-user"

# List existing API keys
wifano-cli auth list-keys

# Revoke an API key
wifano-cli auth revoke-key KEY_ID
```

## Rate Limiting

The API enforces rate limits to ensure fair usage. The default limits are:

- 100 requests per minute per API key
- 10,000 requests per day per API key


Rate limit information is included in the response headers:

- X-RateLimit-Limit: The maximum number of requests allowed in the current time window
- X-RateLimit-Remaining: The number of requests remaining in the current time window
- X-RateLimit-Reset: The time when the current rate limit window resets (Unix timestamp)


## API Endpoints

### Query Endpoint

The primary endpoint for interacting with Wifano.ai is the query endpoint:

```plaintext
POST /v1/query
```

Example request:

```json
{
  "query": "What is the relationship between quantum entanglement and information theory?",
  "max_tokens": 1000,
  "temperature": 0.7
}
```

Example response:

```json
{
  "id": "query_123456789",
  "created": 1625097600,
  "content": "Quantum entanglement and information theory are deeply connected...",
  "tokens": 750,
  "model": "wifano-reasoning-v3",
  "sources": [
    {
      "title": "Quantum Information Theory",
      "url": "https://example.com/quantum-info",
      "year": 2022
    }
  ]
}
```

### Asynchronous Query Endpoint

For long-running queries, use the asynchronous endpoint:

```plaintext
POST /v1/query/async
```

Example request (same as synchronous query).

Example response:

```json
{
  "id": "async_query_123456789",
  "status": "processing",
  "created": 1625097600,
  "estimated_completion": 1625097660
}
```

To check the status of an asynchronous query:

```plaintext
GET /v1/query/async/{id}
```

### Knowledge Endpoints

To search the knowledge base:

```plaintext
GET /v1/knowledge/search?q=quantum+computing
```

To add custom knowledge:

```plaintext
POST /v1/knowledge/add
```

Example request:

```json
{
  "content": "New research on quantum computing shows...",
  "metadata": {
    "title": "Advances in Quantum Computing",
    "author": "Jane Smith",
    "year": 2023,
    "source": "Journal of Quantum Information"
  }
}
```

### Tool Endpoints

To list available tools:

```plaintext
GET /v1/tools
```

To execute a specific tool:

```plaintext
POST /v1/tools/{tool_name}/execute
```

Example request:

```json
{
  "input": {
    "data_url": "https://example.com/dataset.csv",
    "analysis_type": "time_series"
  }
}
```

## Webhook Integration

Wifano.ai supports webhooks for event-driven integration:

```plaintext
POST /v1/webhooks
```

Example request:

```json
{
  "url": "https://your-server.com/webhook",
  "events": ["query.completed", "knowledge.updated"],
  "secret": "your_webhook_secret"
}
```

Webhook payloads are signed using HMAC-SHA256 with your webhook secret. The signature is included in the X-Wifano-Signature header.

## Error Handling

The API uses standard HTTP status codes and returns detailed error information:

```json
{
  "error": {
    "code": "invalid_request",
    "message": "The request was invalid",
    "details": "The 'query' field is required"
  }
}
```

Common error codes:

- invalid_request: The request was malformed
- authentication_error: Authentication failed
- authorization_error: The API key doesn't have permission
- rate_limit_exceeded: Rate limit exceeded
- internal_error: An internal server error occurred


## SDKs and Client Libraries

Wifano.ai provides official client libraries for several programming languages:

- Python: pip install wifano-client
- JavaScript: npm install wifano-client
- Java: maven dependency org.wifano:wifano-client:1.0.0
- Go: go get github.com/wifano/wifano-client-go


## Example Integrations

### Integration with Slack

```python
import os
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
from wifano.client import WifanoClient

# Initialize Slack app
app = App(token=os.environ["SLACK_BOT_TOKEN"])

# Initialize Wifano client
wifano_client = WifanoClient(api_key=os.environ["WIFANO_API_KEY"])

# Handle mentions
@app.event("app_mention")
def handle_mention(event, say):
    query = event["text"].split(">")[1].strip()
    
    # Call Wifano API
    response = wifano_client.query(query=query, max_tokens=1000)
    
    # Reply in thread
    say(text=response.content, thread_ts=event["ts"])

# Start the app
if __name__ == "__main__":
    SocketModeHandler(app, os.environ["SLACK_APP_TOKEN"]).start()
```

### Integration with Microsoft Teams

```javascript
const restify = require('restify');
const { TeamsActivityHandler, TurnContext, CardFactory } = require('botbuilder');
const { WifanoClient } = require('wifano-client');

// Initialize Wifano client
const wifanoClient = new WifanoClient({ apiKey: process.env.WIFANO_API_KEY });

class WifanoBot extends TeamsActivityHandler {
    async onMessage(context, next) {
        const query = context.activity.text;
        
        // Call Wifano API
        const response = await wifanoClient.query({
            query,
            max_tokens: 1000
        });
        
        // Reply with the response
        await context.sendActivity(response.content);
        
        await next();
    }
}

// Create HTTP server
const server = restify.createServer();
server.listen(process.env.port || process.env.PORT || 3978, () => {
    console.log(`\n${server.name} listening to ${server.url}`);
});

// Initialize bot
const bot = new WifanoBot();
server.post('/api/messages', (req, res) => {
    adapter.processActivity(req, res, async (context) => {
        await bot.run(context);
    });
});
```

### Integration with Custom Web Application

```javascript
// React component example
import React, { useState } from 'react';
import { WifanoClient } from 'wifano-client';

const wifanoClient = new WifanoClient({ apiKey: process.env.REACT_APP_WIFANO_API_KEY });

function WifanoQueryComponent() {
    const [query, setQuery] = useState('');
    const [response, setResponse] = useState('');
    const [loading, setLoading] = useState(false);
    
    const handleSubmit = async (e) => {
        e.preventDefault();
        setLoading(true);
        
        try {
            const result = await wifanoClient.query({
                query,
                max_tokens: 1000
            });
            
            setResponse(result.content);
        } catch (error) {
            console.error('Error querying Wifano:', error);
            setResponse('An error occurred while processing your query.');
        } finally {
            setLoading(false);
        }
    };
    
    return (
        <div>
            <form onSubmit={handleSubmit}>
                <textarea
                    value={query}
                    onChange={(e) => setQuery(e.target.value)}
                    placeholder="Enter your query..."
                    rows={4}
                    cols={50}
                />
                <button type="submit" disabled={loading}>
                    {loading ? 'Processing...' : 'Submit'}
                </button>
            </form>
            
            {response && (
                <div>
                    <h3>Response:</h3>
                    <div>{response}</div>
                </div>
            )}
        </div>
    );
}

export default WifanoQueryComponent;
```

EOF

# Create a ConfigMap for the API integration guide

kubectl create configmap wifano-api-integration --from-file=wifano-api-integration.md -n wifano-system

```plaintext

### Database Integration

Set up database integration for Wifano.ai:

```bash
# Create a database integration script
cat <<EOF > wifano-db-integration.sh
#!/bin/bash

# Set variables
DB_TYPE=\$1
DB_HOST=\$2
DB_PORT=\$3
DB_NAME=\$4
DB_USER=\$5
DB_PASSWORD=\$6

# Validate inputs
if [ -z "\$DB_TYPE" ] || [ -z "\$DB_HOST" ] || [ -z "\$DB_PORT" ] || [ -z "\$DB_NAME" ] || [ -z "\$DB_USER" ] || [ -z "\$DB_PASSWORD" ]; then
  echo "Usage: \$0 <db_type> <db_host> <db_port> <db_name> <db_user> <db_password>"
  echo "Example: \$0 postgresql db.example.com 5432 wifano_db wifano_user password123"
  exit 1
fi

# Create a secret for database credentials
kubectl create secret generic wifano-external-db \
  --namespace wifano-system \
  --from-literal=db-type=\$DB_TYPE \
  --from-literal=db-host=\$DB_HOST \
  --from-literal=db-port=\$DB_PORT \
  --from-literal=db-name=\$DB_NAME \
  --from-literal=db-user=\$DB_USER \
  --from-literal=db-password=\$DB_PASSWORD

# Create a ConfigMap for database configuration
kubectl apply -f - << EOT
apiVersion: v1
kind: ConfigMap
metadata:
  name: wifano-external-db-config
  namespace: wifano-system
data:
  db-integration.yaml: |
    database:
      type: \$DB_TYPE
      host: \$DB_HOST
      port: \$DB_PORT
      name: \$DB_NAME
      user: \$DB_USER
      # Password is loaded from the secret
      connection_pool:
        max_connections: 20
        min_connections: 5
        max_idle_time: 300
      ssl:
        enabled: true
        mode: require
      retry:
        max_attempts: 5
        initial_backoff: 1
        max_backoff: 30
EOT

# Update Wifano deployments to use the external database
kubectl patch deployment wifano-api -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "db-config", 
      "configMap": {
        "name": "wifano-external-db-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "db-config",
      "mountPath": "/wifano/config/db-integration.yaml",
      "subPath": "db-integration.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_CONFIG",
      "value": "/wifano/config/db-integration.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_PASSWORD",
      "valueFrom": {
        "secretKeyRef": {
          "name": "wifano-external-db",
          "key": "db-password"
        }
      }
    }
  }
]'

# Apply similar changes to other deployments
kubectl patch deployment wifano-knowledge -n wifano-system --type=json -p='[
  {
    "op": "add", 
    "path": "/spec/template/spec/volumes/-", 
    "value": {
      "name": "db-config", 
      "configMap": {
        "name": "wifano-external-db-config"
      }
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/volumeMounts/-",
    "value": {
      "name": "db-config",
      "mountPath": "/wifano/config/db-integration.yaml",
      "subPath": "db-integration.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_CONFIG",
      "value": "/wifano/config/db-integration.yaml"
    }
  },
  {
    "op": "add",
    "path": "/spec/template/spec/containers/0/env/-",
    "value": {
      "name": "WIFANO_DB_PASSWORD",
      "valueFrom": {
        "secretKeyRef": {
          "name": "wifano-external-db",
          "key": "db-password"
        }
      }
    }
  }
]'

# Restart deployments to apply changes
kubectl rollout restart deployment wifano-api -n wifano-system
kubectl rollout restart deployment wifano-knowledge -n wifano-system

echo "External database integration completed successfully"
echo "Wifano.ai is now configured to use the external \$DB_TYPE database at \$DB_HOST:\$DB_PORT"
EOF

chmod +x wifano-db-integration.sh

# Create a ConfigMap for the database integration script
kubectl create configmap wifano-db-integration-scripts \
  --from-file=wifano-db-integration.sh \
  -n wifano-system
```

## Maintenance and Updates

This section covers maintenance and updates for Wifano.ai.

### Regular Maintenance Tasks

Set up regular maintenance tasks for Wifano.ai:

```shellscript
# Create a maintenance script
cat <<EOF > wifano-maintenance.sh
#!/bin/bash

# Set variables
LOG_FILE="/var/log/wifano-maintenance.log"
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)

# Log start time
echo "Starting maintenance at \$(date)" > \${LOG_FILE}

# Function to log messages
log() {
  echo "[\$(date +%Y-%m-%d\ %H:%M:%S)] \$1" >> \${LOG_FILE}
}

# Update system packages
log "Updating system packages..."
apt update && apt upgrade -y >> \${LOG_FILE} 2>&1

# Check disk space
log "Checking disk space..."
df -h >> \${LOG_FILE}

# Clean up Docker images
log "Cleaning up Docker images..."
docker system prune -af --volumes >> \${LOG_FILE} 2>&1

# Update Kubernetes components
log "Updating Kubernetes components..."
kubeadm upgrade plan >> \${LOG_FILE} 2>&1
# Uncomment the following line to actually perform the upgrade
# kubeadm upgrade apply -y >> \${LOG_FILE} 2>&1

# Update Wifano.ai components
log "Updating Wifano.ai components..."
helm repo update >> \${LOG_FILE} 2>&1
helm upgrade wifano wifano/wifano-core -n wifano-system --reuse-values >> \${LOG_FILE} 2>&1

# Restart services
log "Restarting services..."
kubectl rollout restart deployment -n wifano-system >> \${LOG_FILE} 2>&1

# Verify system health
log "Verifying system health..."
kubectl get nodes >> \${LOG_FILE}
kubectl get pods -n wifano-system >> \${LOG_FILE}
wifano-cli system health --full >> \${LOG_FILE} 2>&1

# Run system tests
log "Running system tests..."
wifano-cli test run --suite basic >> \${LOG_FILE} 2>&1

# Check for security updates
log "Checking for security updates..."
apt list --upgradable | grep security >> \${LOG_FILE}

# Update knowledge base
log "Updating knowledge base..."
wifano-cli knowledge update --all >> \${LOG_FILE} 2>&1

# Optimize databases
log "Optimizing databases..."
kubectl exec -it -n wifano-system \$(kubectl get pods -n wifano-system -l app=wifano-db -o jsonpath='{.items[0].metadata.name}') -- psql -U wifano -c "VACUUM ANALYZE;" >> \${LOG_FILE} 2>&1

# Clean up logs
log "Cleaning up logs..."
find /var/log -name "*.gz" -mtime +30 -delete
find /var/log -name "*.log.*" -mtime +30 -delete

# Rotate logs
log "Rotating logs..."
logrotate -f /etc/logrotate.conf >> \${LOG_FILE} 2>&1

# Check for failed systemd services
log "Checking for failed systemd services..."
systemctl --failed >> \${LOG_FILE}

# Check for failed Kubernetes jobs
log "Checking for failed Kubernetes jobs..."
kubectl get jobs -A --field-selector status.successful=0 >> \${LOG_FILE}

# Send maintenance report
log "Sending maintenance report..."
mail -s "Wifano.ai Maintenance Report \${TIMESTAMP}" admin@wifano.ai < \${LOG_FILE}

log "Maintenance completed at \$(date)"
EOF

chmod +x wifano-maintenance.sh

# Create a ConfigMap for the maintenance script
kubectl create configmap wifano-maintenance-scripts \
  --from-file=wifano-maintenance.sh \
  -n wifano-system

# Create a CronJob for regular maintenance
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: wifano-maintenance
  namespace: wifano-system
spec:
  schedule: "0 1 * * 0"  # Run weekly on Sunday at 1 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: maintenance
            image: ubuntu:22.04
            command: ["/scripts/wifano-maintenance.sh"]
            volumeMounts:
            - name: maintenance-scripts
              mountPath: /scripts
            - name: logs
              mountPath: /var/log
          volumes:
          - name: maintenance-scripts
            configMap:
              name: wifano-maintenance-scripts
              defaultMode: 0755
          - name: logs
            emptyDir: {}
          restartPolicy: OnFailure
EOF
```

### Version Upgrades

Set up version upgrades for Wifano.ai:

```shellscript
# Create a version upgrade script
cat <<EOF > wifano-upgrade.sh
#!/bin/bash

# Set variables
TARGET_VERSION=\$1
BACKUP_BEFORE_UPGRADE=\$2
ROLLBACK_ON_FAILURE=\$3

# Validate inputs
if [ -z "\$TARGET_VERSION" ]; then
  echo "Usage: \$0 <target_version> [backup_before_upgrade] [rollback_on_failure]"
  echo "Example: \$0 3.2.1 true true"
  exit 1
fi

# Set defaults
BACKUP_BEFORE_UPGRADE=\${BACKUP_BEFORE_UPGRADE:-true}
ROLLBACK_ON_FAILURE=\${ROLLBACK_ON_FAILURE:-true}

# Log file
LOG_FILE="/var/log/wifano-upgrade-\${TARGET_VERSION}.log"
echo "Starting Wifano.ai upgrade to version \${TARGET_VERSION} at \$(date)" > \${LOG_FILE}

# Function to log messages
log() {
  echo "[\$(date +%Y-%m-%d\ %H:%M:%S)] \$1" | tee -a \${LOG_FILE}
}

# Get current version
CURRENT_VERSION=\$(helm get values wifano -n wifano-system -o json | jq -r '.version // "unknown"')
log "Current version: \${CURRENT_VERSION}"
log "Target version: \${TARGET_VERSION}"

# Check if upgrade is necessary
if [ "\$CURRENT_VERSION" == "\$TARGET_VERSION" ]; then
  log "Already at target version \${TARGET_VERSION}. No upgrade needed."
  exit 0
fi

# Create backup before upgrade if requested
if [ "\$BACKUP_BEFORE_UPGRADE" == "true" ]; then
  log "Creating backup before upgrade..."
  BACKUP_DIR="/backups/pre-upgrade-\${TARGET_VERSION}"
  mkdir -p \${BACKUP_DIR}
  
  # Backup database
  log "Backing up database..."
  PGPASSWORD=\$(kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.db-password}' | base64 --decode) \
    pg_dump -h wifano-db.wifano-system.svc.cluster.local -U wifano -d wifano | gzip > \${BACKUP_DIR}/wifano_db_backup.sql.gz
  
  # Backup configuration
  log "Backing up configuration..."
  kubectl get configmap -n wifano-system -o yaml > \${BACKUP_DIR}/configmaps.yaml
  kubectl get secret -n wifano-system -o yaml > \${BACKUP_DIR}/secrets.yaml
  
  # Backup Helm values
  log "Backing up Helm values..."
  helm get values wifano -n wifano-system -o yaml > \${BACKUP_DIR}/helm_values.yaml
  
  log "Backup completed: \${BACKUP_DIR}"
fi

# Update Helm repository
log "Updating Helm repository..."
helm repo update

# Check if the target version exists
if ! helm search repo wifano/wifano-core --version \${TARGET_VERSION} | grep -q \${TARGET_VERSION}; then
  log "Error: Version \${TARGET_VERSION} not found in Helm repository."
  exit 1
fi

# Perform the upgrade
log "Performing upgrade to version \${TARGET_VERSION}..."
UPGRADE_OUTPUT=\$(helm upgrade wifano wifano/wifano-core \
  --namespace wifano-system \
  --reuse-values \
  --set version=\${TARGET_VERSION} \
  --timeout 10m 2>&1)
UPGRADE_STATUS=\$?

echo "\${UPGRADE_OUTPUT}" >> \${LOG_FILE}

if [ \$UPGRADE_STATUS -ne 0 ]; then
  log "Error: Upgrade failed with status \${UPGRADE_STATUS}"
  
  if [ "\$ROLLBACK_ON_FAILURE" == "true" ]; then
    log "Rolling back to previous version..."
    helm rollback wifano -n wifano-system
    
    if [ \$? -eq 0 ]; then
      log "Rollback successful."
    else
      log "Error: Rollback failed. Manual intervention required."
    fi
  fi
  
  exit 1
fi

# Wait for all pods to be ready
log "Waiting for all pods to be ready..."
kubectl rollout status deployment -n wifano-system --timeout=10m

# Verify the upgrade
log "Verifying upgrade..."
NEW_VERSION=\$(helm get values wifano -n wifano-system -o json | jq -r '.version // "unknown"')
log "New version: \${NEW_VERSION}"

if [ "\$NEW_VERSION" != "\$TARGET_VERSION" ]; then
  log "Warning: Version mismatch after upgrade. Expected \${TARGET_VERSION}, got \${NEW_VERSION}."
fi

# Run system health check
log "Running system health check..."
wifano-cli system health --full >> \${LOG_FILE} 2>&1

# Run system tests
log "Running system tests..."
wifano-cli test run --suite basic >> \${LOG_FILE} 2>&1
TEST_STATUS=\$?

if [ \$TEST_STATUS -ne 0 ]; then
  log "Warning: System tests failed with status \${TEST_STATUS}"
  
  if [ "\$ROLLBACK_ON_FAILURE" == "true" ]; then
    log "Rolling back to previous version due to failed tests..."
    helm rollback wifano -n wifano-system
    
    if [ \$? -eq 0 ]; then
      log "Rollback successful."
    else
      log "Error: Rollback failed. Manual intervention required."
    fi
    
    exit 1
  fi
fi

log "Upgrade to version \${TARGET_VERSION} completed successfully at \$(date)"
EOF

chmod +x wifano-upgrade.sh

# Create a ConfigMap for the upgrade script
kubectl create configmap wifano-upgrade-scripts \
  --from-file=wifano-upgrade.sh \
  -n wifano-system
```

## Performance Benchmarking

This section covers performance benchmarking for Wifano.ai.

### Benchmark Suite

Set up a benchmark suite for Wifano.ai:

```shellscript
# Create a benchmark script
cat <<EOF > wifano-benchmark.sh
#!/bin/bash

# Set variables
BENCHMARK_TYPE=\$1
OUTPUT_DIR=\$2
DURATION=\$3
CONCURRENCY=\$4

# Validate inputs
if [ -z "\$BENCHMARK_TYPE" ] || [ -z "\$OUTPUT_DIR" ]; then
  echo "Usage: \$0 <benchmark_type> <output_dir> [duration] [concurrency]"
  echo "Benchmark types: basic, performance, stress, endurance"
  echo "Example: \$0 performance /tmp/benchmark 5m 50"
  exit 1
fi

# Set defaults
DURATION=\${DURATION:-5m}
CONCURRENCY=\${CONCURRENCY:-10}

# Create output directory
mkdir -p \${OUTPUT_DIR}

# Log file
LOG_FILE="\${OUTPUT_DIR}/benchmark-\$(date +%Y%m%d_%H%M%S).log"
echo "Starting Wifano.ai \${BENCHMARK_TYPE} benchmark at \$(date)" > \${LOG_FILE}

# Function to log messages
log() {
  echo "[\$(date +%Y-%m-%d\ %H:%M:%S)] \$1" | tee -a \${LOG_FILE}
}

# Get API endpoint and key
API_ENDPOINT="https://api.wifano.ai"
API_KEY=\$(kubectl get secret wifano-secrets -n wifano-system -o jsonpath='{.data.api-key}' | base64 --decode)

# Create benchmark queries
QUERIES_FILE="\${OUTPUT_DIR}/queries.json"

case "\$BENCHMARK_TYPE" in
  basic)
    log "Creating basic benchmark queries..."
    cat <<EOT > \${QUERIES_FILE}
[
  {
    "query": "What is the capital of France?",
    "max_tokens": 100,
    "temperature": 0.7
  },
  {
    "query": "Explain the theory of relativity briefly.",
    "max_tokens": 200,
    "temperature": 0.7
  },
  {
    "query": "What are the main causes of climate change?",
    "max_tokens": 300,
    "temperature": 0.7
  }
]
EOT
    ;;
    
  performance)
    log "Creating performance benchmark queries..."
    cat <<EOT > \${QUERIES_FILE}
[
  {
    "query": "Explain the relationship between quantum mechanics and general relativity.",
    "max_tokens": 500,
    "temperature": 0.7
  },
  {
    "query": "Analyze the economic impact of artificial intelligence on global labor markets.",
    "max_tokens": 800,
    "temperature": 0.7
  },
  {
    "query": "Compare and contrast different approaches to fusion energy research.",
    "max_tokens": 1000,
    "temperature": 0.7
  }
]
EOT
    ;;
    
  stress)
    log "Creating stress benchmark queries..."
    cat <<EOT > \${QUERIES_FILE}
[
  {
    "query": "Write a comprehensive analysis of climate change mitigation strategies across different economic sectors.",
    "max_tokens": 2000,
    "temperature": 0.7
  },
  {
    "query": "Develop a detailed research proposal for studying the effects of quantum computing on cryptographic systems.",
    "max_tokens": 3000,
    "temperature": 0.7
  },
  {
    "query": "Create a systematic review of all major machine learning approaches for drug discovery.",
    "max_tokens": 4000,
    "temperature": 0.7
  }
]
EOT
    ;;
    
  endurance)
    log "Creating endurance benchmark queries..."
    cat <<EOT > \${QUERIES_FILE}
[
  {
    "query": "What is the capital of France?",
    "max_tokens": 100,
    "temperature": 0.7
  },
  {
    "query": "Explain the theory of relativity briefly.",
    "max_tokens": 200,
    "temperature": 0.7
  },
  {
    "query": "What are the main causes of climate change?",
    "max_tokens": 300,
    "temperature": 0.7
  },
  {
    "query": "Explain the relationship between quantum mechanics and general relativity.",
    "max_tokens": 500,
    "temperature": 0.7
  },
  {
    "query": "Analyze the economic impact of artificial intelligence on global labor markets.",
    "max_tokens": 800,
    "temperature": 0.7
  }
]
EOT
    ;;
    
  *)
    log "Error: Unknown benchmark type \${BENCHMARK_TYPE}"
    exit 1
    ;;
esac

# Create k6 script
K6_SCRIPT="\${OUTPUT_DIR}/k6-script.js"
cat <<EOT > \${K6_SCRIPT}
import http from 'k6/http';
import { sleep, check } from 'k6';
import { Counter, Rate, Trend } from 'k6/metrics';
import { SharedArray } from 'k6/data';

// Load queries from file
const queries = new SharedArray('queries', function() {
  return JSON.parse(open('./queries.json'));
});

// Custom metrics
const tokensTrend = new Trend('tokens_generated');
const queryErrors = new Counter('query_errors');
const querySuccess = new Rate('query_success');

export const options = {
  scenarios: {
    wifano_benchmark: {
      executor: 'ramping-vus',
      startVUs: 1,
      stages: [
        { duration: '1m', target: Math.ceil(\${CONCURRENCY} / 4) },
        { duration: '2m', target: Math.ceil(\${CONCURRENCY} / 2) },
        { duration: '2m', target: \${CONCURRENCY} },
        { duration: '\${DURATION}', target: \${CONCURRENCY} },
        { duration: '1m', target: 0 },
      ],
    },
  },
  thresholds: {
    'http_req_duration': ['p(95)<10000'], // 95% of requests should complete within 10s
    'query_success': ['rate>0.95'],       // 95% success rate
  },
};

export default function() {
  // Select a random query
  const queryIndex = Math.floor(Math.random() * queries.length);
  const payload = JSON.stringify(queries[queryIndex]);
  
  // Set headers
  const headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer \${API_KEY}',
  };
  
  // Send request
  const response = http.post('\${API_ENDPOINT}/v1/query', payload, { headers });
  
  // Check response
  const success = check(response, {
    'status is 200': (r) => r.status === 200,
    'has content': (r) => r.json().content !== undefined,
  });
  
  // Update metrics
  if (success) {
    querySuccess.add(1);
    const tokens = response.json().tokens || 0;
    tokensTrend.add(tokens);
  } else {
    queryErrors.add(1);
    console.log('Error response:', response.body);
  }
  
  // Sleep between requests
  sleep(1);
}
EOT

# Run the benchmark
log "Running \${BENCHMARK_TYPE} benchmark with concurrency \${CONCURRENCY} for \${DURATION}..."
k6 run \${K6_SCRIPT} --out json=\${OUTPUT_DIR}/results.json

# Generate report
log "Generating benchmark report..."
cat <<EOT > \${OUTPUT_DIR}/report.html
<!DOCTYPE html>
<html>
<head>
  <title>Wifano.ai Benchmark Report</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    h1 { color: #333; }
    .summary { background-color: #f5f5f5; padding: 15px; border-radius: 5px; }
    .metrics { margin-top: 20px; }
    table { border-collapse: collapse; width: 100%; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background-color: #f2f2f2; }
    tr:nth-child(even) { background-color: #f9f9f9; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
  <h1>Wifano.ai Benchmark Report</h1>
  <div class="summary">
    <h2>Benchmark Summary</h2>
    <p><strong>Type:</strong> \${BENCHMARK_TYPE}</p>
    <p><strong>Duration:</strong> \${DURATION}</p>
    <p><strong>Concurrency:</strong> \${CONCURRENCY}</p>
    <p><strong>Date:</strong> \$(date)</p>
  </div>
  
  <div class="metrics">
    <h2>Performance Metrics</h2>
    <div style="width: 100%; height: 400px;">
      <canvas id="responseTimeChart"></canvas>
    </div>
    
    <h2>Detailed Metrics</h2>
    <table id="metricsTable">
      <tr>
        <th>Metric</th>
        <th>Value</th>
      </tr>
      <!-- Metrics will be inserted here by JavaScript -->
    </table>
  </div>
  
  <script>
    // Load the benchmark results
    fetch('results.json')
      .then(response => response.json())
      .then(data => {
        // Extract metrics
        const metrics = data.metrics;
        const table = document.getElementById('metricsTable');
        
        // Add rows to the table
        for (const [key, value] of Object.entries(metrics)) {
          if (value.values) {
            const row = table.insertRow();
            const cell1 = row.insertCell(0);
            const cell2 = row.insertCell(1);
            cell1.textContent = key;
            cell2.textContent = value.values.rate.toFixed(2);
          }
        }
        
        // Create chart
        const ctx = document.getElementById('responseTimeChart').getContext('2d');
        new Chart(ctx, {
          type: 'line',
          data: {
            labels: Object.keys(data.metrics.http_req_duration.values),
            datasets: [{
              label: 'Response Time (ms)',
              data: Object.values(data.metrics.http_req_duration.values),
              borderColor: 'rgb(75, 192, 192)',
              tension: 0.1
            }]
          },
          options: {
            responsive: true,
            scales: {
              y: {
                beginAtZero: true
              }
            }
          }
        });
      });
  </script>
</body>
</html>
EOT

log "Benchmark completed. Results available at \${OUTPUT_DIR}"
log "Report: \${OUTPUT_DIR}/report.html"
EOF

chmod +x wifano-benchmark.sh

# Create a ConfigMap for the benchmark script
kubectl create configmap wifano-benchmark-scripts \
  --from-file=wifano-benchmark.sh \
  -n wifano-system

# Create a benchmark job template
kubectl apply -f - << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: wifano-benchmark
  namespace: wifano-system
spec:
  template:
    spec:
      containers:
      - name: benchmark
        image: loadimpact/k6:latest
        command: ["/scripts/wifano-benchmark.sh"]
        args: ["performance", "/benchmark", "5m", "20"]
        volumeMounts:
        - name: benchmark-scripts
          mountPath: /scripts
        - name: benchmark-output
          mountPath: /benchmark
      volumes:
      - name: benchmark-scripts
        configMap:
          name: wifano-benchmark-scripts
          defaultMode: 0755
      - name: benchmark-output
        emptyDir: {}
      restartPolicy: OnFailure
EOF
```

## Community Resources

This section provides information about community resources for Wifano.ai.

### Documentation

Create documentation for Wifano.ai:

```shellscript
# Create a documentation guide
cat <<EOF > wifano-documentation.md
# Wifano.ai Documentation

## Overview

Wifano.ai is a distributed, knowledge-intensive AI system designed for PhD-level reasoning capabilities. This documentation provides comprehensive information about deploying, configuring, and maintaining Wifano.ai in production environments.

## Table of Contents

1. [System Architecture](#system-architecture)
2. [Installation](#installation)
3. [Configuration](#configuration)
4. [API Reference](#api-reference)
5. [Administration](#administration)
6. [Troubleshooting](#troubleshooting)
7. [Best Practices](#best-practices)
8. [FAQ](#faq)

## System Architecture

Wifano.ai employs a microservices architecture consisting of several key components:

- **Reasoning Engine**: The core AI system responsible for processing queries and generating responses.
- **Knowledge System**: A distributed database architecture that stores and indexes knowledge.
- **Tool Framework**: A service that allows Wifano.ai to interact with external systems.
- **Orchestration Layer**: Manages the coordination between different components.
- **API Gateway**: Provides a unified interface for client applications.

For detailed architecture information, see the [Architecture Guide](https://docs.wifano.ai/architecture).

## Installation

Wifano.ai can be installed using Helm charts on a Kubernetes cluster. The installation process involves several steps:

1. Set up a Kubernetes cluster with GPU support
2. Configure persistent storage
3. Install Wifano.ai core components
4. Set up monitoring and logging

For detailed installation instructions, see the [Installation Guide](https://docs.wifano.ai/installation).

## Configuration

Wifano.ai can be configured through ConfigMaps and environment variables. Key configuration areas include:

- System settings
- Database configuration
- GPU optimization
- Network settings
- Security settings

For detailed configuration information, see the [Configuration Guide](https://docs.wifano.ai/configuration).

## API Reference

Wifano.ai provides a comprehensive REST API for integration with external systems. The API follows OpenAPI 3.0 standards and supports both synchronous and asynchronous operations.

Key endpoints include:

- `/v1/query`: For synchronous queries
- `/v1/query/async`: For asynchronous queries
- `/v1/knowledge`: For knowledge management
- `/v1/tools`: For tool integration

For detailed API documentation, see the [API Reference](https://docs.wifano.ai/api).

## Administration

Administering Wifano.ai involves several tasks:

- Monitoring system health
- Managing resources
- Scaling the system
- Performing backups
- Upgrading components

For detailed administration information, see the [Administration Guide](https://docs.wifano.ai/administration).

## Troubleshooting

Common issues with Wifano.ai include:

- API connection issues
- Reasoning engine problems
- Knowledge system issues
- Performance bottlenecks
- Security concerns

For detailed troubleshooting information, see the [Troubleshooting Guide](https://docs.wifano.ai/troubleshooting).

## Best Practices

Best practices for Wifano.ai include:

- Resource allocation guidelines
- Security hardening
- High availability setup
- Performance optimization
- Backup and disaster recovery

For detailed best practices, see the [Best Practices Guide](https://docs.wifano.ai/best-practices).

## FAQ

### General Questions

**Q: What is Wifano.ai?**
A: Wifano.ai is a distributed, knowledge-intensive AI system designed for PhD-level reasoning capabilities.

**Q: What are the hardware requirements for Wifano.ai?**
A: Wifano.ai requires a Kubernetes cluster with GPU support, high-memory nodes, and sufficient storage.

**Q: Is Wifano.ai open source?**
A: No, Wifano.ai is a proprietary AI system, but it integrates with many open-source components.

### Technical Questions

**Q: How does Wifano.ai handle large knowledge bases?**
A: Wifano.ai uses a distributed vector database and knowledge graph to efficiently store and retrieve information.

**Q: Can Wifano.ai be deployed on-premises?**
A: Yes, Wifano.ai can be deployed on-premises on any Kubernetes cluster that meets the hardware requirements.

**Q: How does Wifano.ai ensure data security?**
A: Wifano.ai implements multiple security measures, including encryption at rest and in transit, authentication, authorization, and network policies.

For more FAQs, see the [FAQ Page](https://docs.wifano.ai/faq).

## Community Resources

- [GitHub Repository](https://github.com/wifano/wifano-ai)
- [Community Forum](https://community.wifano.ai)
- [Slack Channel](https://wifano.slack.com)
- [Twitter](https://twitter.com/wifanoai)
- [YouTube Channel](https://youtube.com/wifanoai)

## Support

For enterprise support, contact [support@wifano.ai](mailto:support@wifano.ai).
EOF

# Create a ConfigMap for the documentation
kubectl create configmap wifano-documentation \
  --from-file=wifano-documentation.md \
  -n wifano-system
```

### Command Cheat Sheet

Create a command cheat sheet for Wifano.ai:

```shellscript
# Create a command cheat sheet
cat <<EOF > wifano-cheatsheet.md
# Wifano.ai Command Cheat Sheet

## Kubernetes Commands

### Cluster Management

```bash
# Get cluster status
kubectl cluster-info

# Get nodes
kubectl get nodes

# Get node details
kubectl describe node <node-name>

# Drain a node for maintenance
kubectl drain <node-name> --ignore-daemonsets

# Mark a node as unschedulable
kubectl cordon <node-name>

# Mark a node as schedulable
kubectl uncordon <node-name>
```

### Pod Management

```shellscript
# Get pods in wifano-system namespace
kubectl get pods -n wifano-system

# Get pod details
kubectl describe pod <pod-name> -n wifano-system

# Get pod logs
kubectl logs <pod-name> -n wifano-system

# Get logs from a specific container in a pod
kubectl logs <pod-name> -c <container-name> -n wifano-system

# Execute a command in a pod
kubectl exec -it <pod-name> -n wifano-system -- <command>

# Delete a pod
kubectl delete pod <pod-name> -n wifano-system
```

### Deployment Management

```shellscript
# Get deployments
kubectl get deployments -n wifano-system

# Scale a deployment
kubectl scale deployment <deployment-name> --replicas=<count> -n wifano-system

# Restart a deployment
kubectl rollout restart deployment <deployment-name> -n wifano-system

# Check deployment status
kubectl rollout status deployment <deployment-name> -n wifano-system

# Rollback a deployment
kubectl rollout undo deployment <deployment-name> -n wifano-system
```

### ConfigMap and Secret Management

```shellscript
# Get ConfigMaps
kubectl get configmaps -n wifano-system

# Get ConfigMap details
kubectl describe configmap <configmap-name> -n wifano-system

# Edit a ConfigMap
kubectl edit configmap <configmap-name> -n wifano-system

# Get Secrets
kubectl get secrets -n wifano-system

# Get Secret details
kubectl describe secret <secret-name> -n wifano-system

# Create a Secret
kubectl create secret generic <secret-name> --from-literal=key=value -n wifano-system
```

### Service Management

```shellscript
# Get services
kubectl get services -n wifano-system

# Get service details
kubectl describe service <service-name> -n wifano-system

# Port forward to a service
kubectl port-forward service/<service-name> <local-port>:<service-port> -n wifano-system
```

### Persistent Volume Management

```shellscript
# Get persistent volumes
kubectl get pv

# Get persistent volume claims
kubectl get pvc -n wifano-system

# Get persistent volume details
kubectl describe pv <pv-name>

# Get persistent volume claim details
kubectl describe pvc <pvc-name> -n wifano-system
```

## Helm Commands

### Chart Management

```shellscript
# List Helm releases
helm list -n wifano-system

# Get release details
helm status wifano -n wifano-system

# Get release values
helm get values wifano -n wifano-system

# Upgrade a release
helm upgrade wifano wifano/wifano-core -n wifano-system --reuse-values --set version=<version>

# Rollback a release
helm rollback wifano <revision> -n wifano-system

# Uninstall a release
helm uninstall wifano -n wifano-system
```

## Wifano.ai CLI Commands

### System Management

```shellscript
# Get system status
wifano-cli status

# Get system health
wifano-cli system health

# Get detailed system diagnostics
wifano-cli diagnostics --full

# Update system configuration
wifano-cli config update --file=config.yaml

# Restart a component
wifano-cli system restart --component=<component-name>
```

### Knowledge Management

```shellscript
# List knowledge sources
wifano-cli knowledge list-sources

# Add a knowledge source
wifano-cli knowledge add-source --name=<name> --url=<url>

# Update knowledge
wifano-cli knowledge update --source=<source-name>

# Update all knowledge
wifano-cli knowledge update --all

# Search knowledge
wifano-cli knowledge search --query="<query>"
```

### User Management

```shellscript
# List users
wifano-cli user list

# Add a user
wifano-cli user add --name=<name> --email=<email> --role=<role>

# Update a user
wifano-cli user update --id=<user-id> --role=<role>

# Delete a user
wifano-cli user delete --id=<user-id>
```

### API Key Management

```shellscript
# List API keys
wifano-cli auth list-keys

# Create an API key
wifano-cli auth create-key --name=<name> --role=<role>

# Revoke an API key
wifano-cli auth revoke-key <key-id>
```

### Tool Management

```shellscript
# List available tools
wifano-cli tool list

# Enable a tool
wifano-cli tool enable --name=<tool-name>

# Disable a tool
wifano-cli tool disable --name=<tool-name>

# Configure a tool
wifano-cli tool configure --name=<tool-name> --config=<config-file>
```

### Testing

```shellscript
# Run basic tests
wifano-cli test run --suite=basic

# Run performance tests
wifano-cli test run --suite=performance

# Run a specific test
wifano-cli test run --test=<test-name>
```

### Backup and Restore

```shellscript
# Create a backup
wifano-cli backup create --output=<output-dir>

# List backups
wifano-cli backup list

# Restore from a backup
wifano-cli backup restore --file=<backup-file>
```

## Docker Commands

### Image Management

```shellscript
# List Docker images
docker images | grep wifano

# Pull a Wifano.ai image
docker pull registry.wifano.ai/wifano/reasoning:<tag>

# Build a custom image
docker build -t wifano/custom:<tag> .

# Push an image to the registry
docker push registry.wifano.ai/wifano/custom:<tag>
```

### Container Management

```shellscript
# List running containers
docker ps | grep wifano

# Execute a command in a container
docker exec -it <container-id> <command>

# View container logs
docker logs <container-id>

# Stop a container
docker stop <container-id>
```

## GPU Commands

### NVIDIA Management

```shellscript
# Check GPU status
nvidia-smi

# Monitor GPU usage
watch -n 1 nvidia-smi

# Check GPU processes
nvidia-smi --query-compute-apps=pid,used_memory --format=csv

# Set GPU persistence mode
sudo nvidia-smi -pm 1

# Set GPU power limit
sudo nvidia-smi -pl <watts>

# Set GPU clock speeds
sudo nvidia-smi -ac <mem-clock>,<graphics-clock>
```

## Database Commands

### PostgreSQL

```shellscript
# Connect to the database
PGPASSWORD=<password> psql -h wifano-db -U wifano -d wifano

# Backup the database
PGPASSWORD=<password> pg_dump -h wifano-db -U wifano -d wifano > backup.sql

# Restore the database
PGPASSWORD=<password> psql -h wifano-db -U wifano -d wifano &lt; backup.sql

# Vacuum the database
PGPASSWORD=<password> psql -h wifano-db -U wifano -d wifano -c "VACUUM ANALYZE;"
```

### Vector Database

```shellscript
# Check vector database status
curl -s http://wifano-vector-db:6333/collections/wifano_embeddings

# Create a collection
curl -X POST http://wifano-vector-db:6333/collections \
  -H "Content-Type: application/json" \
  -d '{"name":"new_collection","vector_size":1536}'

# Create a snapshot
curl -X POST http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots \
  -H "Content-Type: application/json" \
  -d '{"snapshot_path":"/snapshots/wifano_embeddings_snapshot"}'

# Restore from a snapshot
curl -X PUT http://wifano-vector-db:6333/collections/wifano_embeddings/snapshots/restore \
  -H "Content-Type: application/json" \
  -d '{"snapshot_path":"/snapshots/wifano_embeddings_snapshot"}'
```

## Monitoring Commands

### Prometheus

```shellscript
# Query Prometheus
curl -s "http://wifano-monitoring-prometheus:9090/api/v1/query?query=up"

# Query for specific metrics
curl -s "http://wifano-monitoring-prometheus:9090/api/v1/query?query=wifano_requests_total"
```

### Grafana

```shellscript
# Get Grafana dashboards
curl -s http://admin:password@wifano-monitoring-grafana:3000/api/dashboards

# Export a dashboard
curl -s http://admin:password@wifano-monitoring-grafana:3000/api/dashboards/uid/<dashboard-uid> > dashboard.json
```

## Logging Commands

### Elasticsearch

```shellscript
# Search logs
curl -s "http://wifano-logging-elasticsearch:9200/wifano-*/_search?q=error"

# Get index information
curl -s "http://wifano-logging-elasticsearch:9200/wifano-*/_stats"
```

### Filebeat

```shellscript
# Check Filebeat status
kubectl exec -it <filebeat-pod> -n wifano-logging -- filebeat status

# Test Filebeat configuration
kubectl exec -it <filebeat-pod> -n wifano-logging -- filebeat test config
```

## Networking Commands

### Diagnostics

```shellscript
# Test connectivity
kubectl run -it --rm debug --image=curlimages/curl -- curl http://wifano-api.wifano-system:8080/health

# Test DNS resolution
kubectl run -it --rm debug --image=busybox -- nslookup wifano-api.wifano-system

# Check network policies
kubectl get networkpolicies -n wifano-system

# Test network latency
kubectl run -it --rm netutils --image=nicolaka/netshoot -- ping wifano-api.wifano-system
```

## Security Commands

### TLS Management

```shellscript
# Check certificate expiration
kubectl get secret wifano-tls -n wifano-system -o jsonpath='{.data.tls\.crt}' | base64 --decode | openssl x509 -noout -dates

# Renew certificate
kubectl delete certificate wifano-tls -n wifano-system
kubectl apply -f certificate.yaml
```

### RBAC Management

```shellscript
# Check service account permissions
kubectl auth can-i --list --as=system:serviceaccount:wifano-system:wifano-sa -n wifano-system

# Create a role
kubectl create role <role-name> --verb=get,list,watch --resource=pods -n wifano-system

# Create a role binding
kubectl create rolebinding <binding-name> --role=<role-name> --serviceaccount=wifano-system:wifano-sa -n wifano-system
```

EOF

# Create a ConfigMap for the command cheat sheet

kubectl create configmap wifano-cheatsheet --from-file=wifano-cheatsheet.md -n wifano-system

```plaintext

## Conclusion

This comprehensive guide has covered all aspects of deploying, configuring, and maintaining Wifano.ai in production environments. By following the instructions in this guide, you can set up a robust, scalable, and secure Wifano.ai deployment that meets the needs of your organization.

Key takeaways from this guide include:

1. **System Architecture**: Wifano.ai employs a microservices architecture with specialized components for reasoning, knowledge management, and tool integration.

2. **Installation Process**: The installation process involves setting up a Kubernetes cluster, configuring persistent storage, and deploying the core components using Helm.

3. **Configuration**: Proper configuration is essential for optimal performance, including system settings, database configuration, and GPU optimization.

4. **Performance Optimization**: Various techniques can be used to optimize performance, including Linux kernel tuning, GPU optimization, and network optimization.

5. **Monitoring and Logging**: Comprehensive monitoring and logging are essential for maintaining Wifano.ai in production, using tools like Prometheus, Grafana, and the ELK stack.

6. **Security Hardening**: Security measures include network policies, authentication and authorization, and data encryption.

7. **Scaling**: Wifano.ai can be scaled horizontally and vertically to handle increased load, using Kubernetes autoscaling features.

8. **High Availability**: Multi-zone deployment, database high availability, and fault tolerance ensure the system remains operational even during failures.

9. **Backup and Disaster Recovery**: Regular backups and a well-defined disaster recovery plan are essential for data protection.

10. **Maintenance and Updates**: Regular maintenance tasks and version upgrades keep the system running smoothly and up-to-date.

By implementing the best practices outlined in this guide, you can ensure that your Wifano.ai deployment is reliable, performant, and secure, providing PhD-level reasoning capabilities to your organization.

<Actions>
  <Action name="Create a Wifano AI architecture diagram" description="Generate a visual representation of the Wifano AI system architecture" />
  <Action name="Add a Wifano-specific command cheat sheet" description="Create a reference guide for common Wifano CLI commands" />
  <Action name="Implement a case study section" description="Add a real-w
```
